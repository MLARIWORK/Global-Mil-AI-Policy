{
  "countries": {
    "Algeria": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by Algeria at the 77th Session of the UNGA First Committee Thematic Discussion (Oct 2022)\n\nAlgeria supports the creation of a new legally binding instrument on LAWS \"for addressing the humanitarian and international security challenges posed by the emerging technologies in the area of LAWS\".",
            "url": "https://reachingcriticalwill.org/images/documents/Disarmament-fora/1com/1com22/statements/21Oct_Algeria.pdf"
          },
          {
            "text": "Algeria Statement at the First UNGA Meeting on Autonomous Weapons Systems (May 2025)\n\nAlgeria states that autonomous weapons systems \"fundamentally challenge the right to life by removing human judgement from lethal force decisions,\" which continues its stance on restricting such weapons.",
            "url": "https://www.hrw.org/news/2025/05/21/un-start-talks-treaty-ban-killer-robots"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nAlgeria voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nAlgeria voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nAlgeria voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      }
    },
    "Armenia": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by the Delegation of Armenia at the Vienna Conference \"Humanity at the Crossroads: Autonomous Weapons Systems and the Challenge of Regulation\" (Apr 2024)\n\nArmenia supports the creation of a new legally binding instrument and regulatory mechanism for addressing challenges posed by autonomoous weapons systems.\n\nThe document goes further and calls for joint efforts to be directed toward developing legal and ethical standards and accountability mechanisms for artificial intelligence, lethal autonomous weapons, and drones technologies.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Armenia_National_Statement.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nArmenia voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nArmenia voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\nArmenia endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\nThe declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by the Delegation of Armenia to the OSCE on Responsible Military Use of New and Emerging Technologies (Feb 2025)\n\nArmenia states that human responsibility and accountability in autonomous weapons are essential.",
            "url": "https://www.osce.org/sites/default/files/f/documents/7/6/586737.pdf"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nArmenia voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nArmenia signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "Australia": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Australia National Statement at the Vienna Conference \u201cHumanity at the Crossroads: Lethal Autonomous Weapon Systems\u201d (Apr 2024)\n\nAustralia states that the CCW GGE is the most appropriate avenue to discuss LAWS, and believes that humans are the responsible entity for \"effecting international humanitarian law (IHL) obligations - not machines.\" Australia also encourages other states to join initiatives that advance discussion on LAWS, including the REAIM  Summit and the Political Declaration on Responsible Use of Military AI and Autonomy.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Australia_National_Statement.pdf"
          },
          {
            "text": "Australia's Submission to the UN Secretary-General's Report on Lethal Autonomous Weapons Systems (May 2024)\n\nAustralia states that compliance with IHL is critical for the responsible development and use of LAWS and that the context in which LAWS is used is important to the laws that are applied to their development and use.\n\nAustralia also opposes the creation of a new legally binding instrument that would regulate or ban LAWS, and it supports the two-tier approach, which elaborates on LAWS that should be prohibited under IHL and those that should be regulated in accordance with IHL.\n\nThis document states human control as one and not the only means of ensuring compliance with IHL.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Australia-EN.pdf"
          },
          {
            "text": "Inquiry into the Department of Defence Annual Report 2022-23 (Oct 2024)\n\nChapter 5: Artificial Intelligence and Autonomous Weapons Related Issues; provides Australia's definition of AI and autonomy in weapons and Australian policy as it relates to AI regulation in general.\n\nAustralia foresees AI applications in human-machine teaming and requires a human in or on the loop for lethal capabilities, providing a tailored level of human control throughout the AI lifecycle.\n\nThis document reaffirms the commitment to applying IHL to lethal autonomous weapons.",
            "url": "https://www.aph.gov.au/Parliamentary_Business/Committees/Joint/Foreign_Affairs_Defence_and_Trade/DefenceAR2022-23/Inquiry_into_the_Defence_Annual_Report_2022-23/Chapter_5_-_Artificial_Intelligence_and_Autonomous_Weapons_related_issues"
          }
        ],
        "public_statements": [
          {
            "text": "\"Loyal Wingman\" Test Flight Announcement (Mar 2021)\n\nThe Head of Australian Air Force Capability announces the first successful flight test for the Loyal Wingman, which provides capability advantage by working with existing platforms to complement and extend air combat platforms.\n\nThis test signals Australia's commitment to developing unmanned aerial assets that are integrated into man-machine teams that use autonomous and AI-enabled systems, and improve the acquisition process to complement future force sructure.",
            "url": "https://www.defence.gov.au/news-events/releases/2021-03-02/first-flight-loyal-wingman"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nAustralia voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nAustralia voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Australian Army - Robotic & Autonomous Systems Strategy v2.0 (Aug 2022)\n\nThis strategy outlines the plan to generate a competitive advantage by systematically integrating robotic and autonomous systems (RAS) into land warfare.\n\nThe Army embeds a \"trust-by-design\" model, which includes a graduated autonomy level for different autonomous systems, testing and verification, and human override mechanisms to ensure human control over critical decisions.\n\nThe document presents lines of effort: innovation, coordination, and realisation; and it also assigns responsibilities to various authorities to enable the strategy as the Australian Army moves forward with this plan.",
            "url": "https://researchcentre.army.gov.au/sites/default/files/Robotic%20and%20Autonomous%20Systems%20Strategy%20V2.0.pdf"
          },
          {
            "text": "Royal Australian Navy \u2014 RAS-AI Campaign Plan 2025 (Feb 2024)\n\nThis plan outlines the Australian Navy's plan to operationalize the use of robotics, autonomous systems, and AI.\n\nThis document positions the following capabilities as mission-critical: undersea warfare, maritime ISR, mine countermeasures, fleet protection, and distributed lethality.\n\nThe Campaign Plan states that AI will support decisions, not replace human command authority, and the decision to use lethal force remains with the human.\n\nAs a whole, the document provides a step-by-step roadmap to integrating and establishing AI within the Navy.",
            "url": "https://www.navy.gov.au/sites/default/files/2024-02/RAS-AI-Campaign-Plan-2025.pdf"
          },
          {
            "text": "Royal Australian Navy - RAS-AI Strategy 2040 (Oct 2020)\n\nThis strategy document outlines the Australian Navy's long-term plan to integrate AI and autonomy into day-to-day operations and assets.\n\nThe RAS envisions using AI for force protection, a partnered and interoperable force, a common control system, maximization of force potential, and a substantial force projection as five main priorities for the future.\n\nThe strategy presents design principles and four lines of effort to which the RAS will invest resources to achieve the main priorities, presenting specific initiatives and projects that the Navy will begin or conduct in accordance with this plan.",
            "url": "https://www.navy.gov.au/about-navy/strategic-planning/robotics-autonomous-systems-artificial-intelligence-strategy"
          }
        ],
        "public_statements": [
          {
            "text": "Interview with Minister of Defense on ADF Activities (Feb 2024)\n\nThe Minister of Defence states that the Australian Navy is preparing 26 surface combatants that will be \"large optionally crewed surface vessels,\" signaling that these vehicles will have the capacity to operate with autonomous functions.",
            "url": "https://www.defenceconnect.com.au/joint-capabilities/13653-defence-minister-teases-secret-autonomous-systems-developed-by-australian-defence-force"
          },
          {
            "text": "Statement by Minister for Defence on the National Defence Strategy (Apr 2024)\n\nMinister Richard Marles states that additional investments toward autonomous systems, among other defense capabilities, and priority capabilities will be made for the next four years.",
            "url": "https://www.minister.defence.gov.au/media-releases/2024-04-17/2024-national-defence-strategy"
          },
          {
            "text": "Statement by Minister for Defence Industry on Integrated Investment Program (Apr 2024)\n\nMinister Pat Conroy addresses the Australian Defence Force's (ADF) efforts to build an integrated and focused force, and outlines the major investments that the country will make to achieve this goal.\n\nAutonomous capabilities and AI-enabled systems are a big focus of the investment program, and Conroy suggests a deliberate choice to invest in the chosen capabilities.",
            "url": "https://www.minister.defence.gov.au/media-releases/2024-04-17/2024-integrated-investment-program"
          },
          {
            "text": "Press Conference on Ghost Shark Capability (Sep 2025)\n\nDeputy Prime Minister Richard Marles and Defence Industry Minister Pat Conroy gave a press statement covering the Ghost Shark project, claiming that it is \"the best autonomous underwater military capability on the planet\".\n\nThe Ministers state that Ghost Shark will have the capability for autonomous ISR and strike from \"extremely long distances from the Australian continent\".\n\nThis press statement shows evidence of Australia's intent to continue developing autonomous capabilities with various functions in the maritime domain.",
            "url": "https://www.minister.defence.gov.au/transcripts/2025-09-10/press-conference-sydney"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "2024 Integrated Investment Program (2024) (2024)\n\nThis document outlines Australia's defense spending commitment for a decade, beginning in 2024.\n\nChapter 1: Investing in the National Defence Strategy; defines \"trusted autonomy\" as one of the six National Defence Strategy priorities and presents \"smaller, low-cost and expendable robotic and autonomous systems that could be deployed in larger groups across the maritime, land and air domains\" as a priority investment area.\n\nChapter 2: Undersea Warfare; commits considerable investment to uncrewed maritime systems as well as large uncrewed autonomous underwater vehicles.\n\nChapter 7: Amphibious Capable Combined-Arms Land Systems; commits to comntinued R&D of uncrewed aerial vehicles for intelligence, surveillance, and force protection, and uncrewed ground systems for combat missions and support roles.\n\nChapter 8: Expeditionary Air Operations; commits investments to uncrewed aerial systems to augment crewed Air Force capabilities.\n\nChapter 14: Enabling Capabilities; commits to the integration of automated processes for faster and more efficient data processing and dissemination.",
            "url": "https://www.defence.gov.au/about/strategic-planning/2024-national-defence-strategy-2024-integrated-investment-program"
          }
        ],
        "public_statements": [
          {
            "text": "Press Conference on AI Capabilities (Jul 2024)\n\nMinister for Defence Industry Pat Conroy states that the government is committing over $10 billion (AUD) to support autonomous systems and drones and their acquisition over the next ten years.\n\nMinister Conroy announces the government's commitment to acquire 110 small uncrewed aerial systems.",
            "url": "https://www.minister.defence.gov.au/transcripts/2024-07-15/press-conference-sypaq-systems-melbourne"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nAustralia voted in support of this resolution, which  calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nAustralia signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "Assistant Minister for Defence Statement on the Australian Industry Group (Nov 2025)\n\nAssistant Minister Peter Khalil states that AUKUS is developing and deploying advanced AI algorithms on the P-8A Maritime Patrol Aircraft, which process data from each nationa's sonobuoys and assists anti-submarine operators to detect submarines faster.\n\nAustralia is developing capabilities in conjunction with the UK and the US to accelerate defense innovation and achieve shared strategic goals.",
            "url": "https://www.minister.defence.gov.au/speeches/2025-11-27/australian-industry-group"
          }
        ]
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Foreign Minister Statement of AI Use in Nuclear Weapons (Sep 2025)\n\nForeign Minister Penny Wong states at the UN Security Council Open Debate that humans should not delegate responsibility over the use of lethal force to a machine. The decision to use nuclear weapons should also remain with humans.",
            "url": "https://www.foreignminister.gov.au/minister/penny-wong/speech/statement-un-security-council-open-debate"
          }
        ]
      }
    },
    "Azerbaijan": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nAzerbaijan voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "News Release \"The Contribution of Unmanned Aerial Vehicles to the Military and Modern Warfare\" (Dec 2024)\n\nThis Ministry of Defense (MOD) news release outlines Azerbaijan's use of unmanned aerial vehicles and the importance of AI in future warfare.\n\nThe release signals Azerbeijan's intent to integrate AI into UAV assets, stating potential use cases that \"automatically identify targets, analyze the terrain and predict enemy movements... analyzing them in real time, making autonomous decisions and improving adaptation to new conditions\".",
            "url": "https://mod.gov.az/az/pre/53548.html?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "Belgium": {
      "LAWS Employment/Deployment": {
        "legal_directives": [
          {
            "text": "Belgium Ban on Killer Robots (Jul 2018)\n\nThe Begian Parliament voted and passed a resolution to ban \"killer robots,\" calling on the Belgian government to forbid the development and use of lethal autonomous weapons ad to work toward an international treaty to ban such weapons.",
            "url": "https://paxforpeace.nl/news/belgium-votes-to-ban-killer-robots/?utm_source=chatgpt.com"
          }
        ],
        "policy_documents": [
          {
            "text": "Contribution by Belgium on Addresing the Challenges Posed by Lethal Autonomous Weapons Systems (Dec 2022)\n\nBelgium supports internationally agreed limits on LAWS and supports the prohibition of LAWS that cannot comply with IHL, including the regulation of other types of autonomous weapons systems.\n\nThis document outlines what Belgium considers to be \"sufficient human involvement\" in the execution of a complete tageting cycle of a weapons system.",
            "url": "https://dppa.un.org/sites/default/files/belgium.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nBelgium voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nBelgium voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Strategic Vision 2025 Belgian Defense (Jul 2025)\n\nThe Vision includes AI, robotics, and autonomous systems as key innovation drivers for the defense sector.\n\nThe Belgian Defense Ministry is investing in capabilities such as AI-integrated systems, smart logistics, and autonomous resupply.",
            "url": "https://inno4def.be/strategic-vision-2025/?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nBelgium signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians.\n\nEndorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nBelgium voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      }
    },
    "Brazil": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by Brazil at the Vienna Conference \"Humanity at the Crossroads: Autonomous Weapon Systems and the Challenge of Regulation\"(Apr 2024)\n\nBrazil supports the creation of a legally binding instrument that would establish norms across the globe.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Brazil_National_Statement.pdf"
          },
          {
            "text": "Brazil Submission Pursuant to Resolution 78/241 on Autonomous Weapons Systems (May 2024)\n\nBrazil stresses the need for meaningful human control in the discussion of LAWS, and advocates for the prohibition of autonomous weapons that cannot be: sufficiently understood, predicted, and explained by the user; be directed at a specific military objective; or cause disproportionate harm and suffering.\n\nThe document reiterates Brazil's support for a legally binding instrument and outlines the requirements demanded of the human operator of an autonomous weapon system.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Brazil-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nBrazil voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nBrazil voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "Bel\u00e9n Communiqu\u00e9 (Feb 2023)\n\nBrazil adopted this joint communiqu\u00e9 along with 32 other Latin American and Caribbean countries, which calls for the urgent negotiation of a binding international treaty to prohibit and regulate LAWS. The document is grounded in the concept of meaningful human control and international humanitarian law (IHL).",
            "url": "https://www.rree.go.cr/files/includes/files.php?id=2261&tipo=documentos"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Brazilian Army Strategic Guidelines for Artificial Intelligence (May 2024)\n\nThis document normalizes the implementation and use of AI within the Brazilian Army, establishing the principles, guidelines, and instruments for the implementation.\n\nBrazil emphasizes ethical principles andmoral values in the development of AI for military purposes.",
            "url": "https://www.sgex.eb.mil.br/sg8/006_outras_publicacoes/01_diretrizes/04_estado-maior_do_exercito/port_n_1318_eme_14mai2024.html?utm_source=chatgpt.com"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nBrazil voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      }
    },
    "Bulgaria": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Bulgaria Submission on Resolution 78/241 \"Lethal Autonomous Weapons Systems\" (May 2024)\n\nBulgaria supports the two-tier system to regulating LAWS, making a distinction between autonomous weapons that operate completely outside human control and weapons with autonomous functions requiring regulation and compliance with IHL.\n\nHuman control is central to the ethical acceptability of autonomous weapons systems, and Bulgaria outlines the necessary requirements for the use of force by an autonomous weapon to be authorized.\n\nBulgaria is committed to the development of a set of elements for an instrument to better regulate LAWS.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Bulgaria-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nBulgaria voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nBulgaria voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Bulgaria Statement at the UN Security Council (Sep 2025)\n\nBulgaria reaffirms its commitment to the responsible and ethical use of AI, stressing that AI must be developed and used in accordance with IHL.\n\nThis statement presents Bulgaria's active support for the REAIM Summit's Blueprint for Action and various other multilateral frameworks that discuss AI in the military domain.",
            "url": "https://www.mfa.bg/en/news/45855?utm_source=chatgpt.com"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\nBulgaria endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\nThe declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nBulgaria signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nBulgaria voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      }
    },
    "Canada": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "The Department of National Defence and Canadian Armed Forces (DND/CAF) Artificial Intelligence Strategy (Mar 2024)\n\nThe Guiding Principles explicitly state that applications of military-use AI involving lethal force must always retain human in the loop.",
            "url": "https://hkifoa.com/wp-content/uploads/2024/11/ai-strategy-cananda-defense.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \"Lethal Autonomous Weapons Systems\" (May 2024)\n\nCanada voted in support of this resolution and states that autonomy in weapons must be trustworthy, predictable, and used in accordance with IHL.\n\nCanada stresses reducing collateral harm and maintaining human responsibility.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-Canada-EN.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Dec 2023)\n\nCanada voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://documents.un.org/doc/undoc/ltd/n24/305/45/pdf/n2430545.pdf"
          },
          {
            "text": "Convention on Certain Conventional Weapons (CCW) Guiding Principles on Lethal Autonomous Weapons Systems (Sep 2019)\n\nCanada endorsed the CCW's Guiding Principles on LAWS in 2019, citing them as a baseline for future work in regulatory frameworks in AI and autonomy.",
            "url": "https://documents.unoda.org/wp-content/uploads/2020/09/CCW_GGE.1_2019_3_E.pdf"
          },
          {
            "text": "Minister of Foreign Affairs Mandate Letter (Dec 2019)\n\nPrime Minister Justin Trudeau explicitly instructs the new Foreign Minister to \"advance international efforts to ban the development and use of fully autonomous weapons systems\".",
            "url": "https://www.pm.gc.ca/en/mandate-letters/2019/12/13/archived-minister-foreign-affairs-mandate-letter"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "The Department of National Defence and Canadian Armed Forces (DND/CAF) Artificial Intelligence Strategy (Mar 2024)\n\nLine of Effort 1: Fielding and Employing AI Capabilities; directs the DND/CAF to develop an internal AI Center (DCAIC), which acts as a hub of AI expertise and a catalyst for R&D, standardization, and implementation of AI in the military.\n\nThe Core Principles state that DND/CAF will deploy AI to augment and not replace human action and decision-making.\n\nLine of Effort 4: Talent and Training; directs DND/CAF to review the workforce needs for AI, identify priorities for AI training and appropriate curricula, and identify processes for recruiting talent.",
            "url": "https://hkifoa.com/wp-content/uploads/2024/11/ai-strategy-cananda-defense.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Minister of Defence Blair Keynote at the Ottawa Conference on Security and Defence (Mar 2024)\n\nMinister Blair formally announces the DND/CAF Artificial Intelligence Strategy and emphasizes the need for Canada to responsibly harness emerging technologies such as AI. He states that the goal for Canadian defese is to become \"AI-enabled\" by 2030, claiming that the Strategy will guide the adoption of AI throughout the Defence Ministry.",
            "url": "https://www.canada.ca/en/department-national-defence/news/2024/03/keynote-address-by-minister-of-national-defence-bill-blair-to-the-cda-institute-ottawa-conference-on-security-and-defence.html"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [
          {
            "text": "Directive on Automated Decision-Making (ADM) (Apr 2019)\n\nThis directive applies to the Department of National Defence (DND) and is a policy that federal departments that use automated systems must adhere to. It centers around an Algorithmic Impact Assessment (AIA) that classifies the system's level of impact and drives safeguard requirement and compliance.",
            "url": "https://www.tbs-sct.canada.ca/pol/doc-eng.aspx?id=32592"
          }
        ],
        "policy_documents": [
          {
            "text": "The Department of National Defence and Canadian Armed Forces (DND/CAF) Artificial Intelligence Strategy (Mar 2024)\n\nLine of Effort 3: Ethics, Safety, and Trust; commits to developing ethics principles and frameworks. The strategy plans to incorporate both internal and external partners in developing ethical use of AI in the military.",
            "url": "https://hkifoa.com/wp-content/uploads/2024/11/ai-strategy-cananda-defense.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Minister of National Defence Remarks at the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\nCanada commits to developing a framework for the responsible use of AI in military contexts while addressing the challenges of unintended bias, and implementing such technologies in accordance with applicable laws, policies, and IHL.",
            "url": "https://www.canada.ca/en/department-national-defence/news/2024/09/minister-of-national-defence-remarks-at-the-responsible-ai-in-the-military-domain-reaim-summit-2024.html?utm_source=chatgpt.com"
          },
          {
            "text": "Canada's Stance in the Responsible Artificial Intelligence in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\nCanada supports the 'blueprint' for ethical and human-centric use of AI in the military, which emphasizes the importance of compliance with international law, human oversight, and risk assessment.",
            "url": "https://www.asiapacific.ca/publication/us-china-competition-looms-large-seoul-summit-use-ai?utm_source=chatgpt.com"
          },
          {
            "text": "US DoS Political Declaration on Responsible Use of Artificial Intelligence and Autonomy (Nov 2024)\n\nCanada signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.https://www.state.gov/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy-2/.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "Int'l Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "The Department of National Defence and Canadian Armed Forces (DND/CAF) Artificial Intelligence Strategy (Mar 2024)\n\nLine of Effort 5: Partnerships; addresses the need for cooperation and collaboration with trusted partners and allies. There are foci on secure data infrastructure sharing with partners, and a need for collaboration with the civilian industry to further develop capabilities.",
            "url": "https://hkifoa.com/wp-content/uploads/2024/11/ai-strategy-cananda-defense.pdf"
          }
        ],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "The Department of National Defence and Canadian Armed Forces (DND/CAF) Artificial Intelligence Strategy (Mar 2024)\n\nLine of Effort 3: Ethics, Safety, and Trust; the DND/CAF plan to conduct AI maturity assessments and develop metrics, supporting mechanisms, and governance to align resources and goals.\n\nThe DND/CAF state that they will implement any military-use AI in accordance with applicable laws, policies, and guidelines.",
            "url": "https://hkifoa.com/wp-content/uploads/2024/11/ai-strategy-cananda-defense.pdf"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \"Lethal Autonomous Weapons Systems\" (May 2024)\n\nCanada's formal submission to the United Nations (UNGA 78/241) states Canada conducts national legal reviews of new weapons to ensure compliance with International Humanitarian Law (IHL) throughout the lifecycle of the weapon. It states that LAWS that cannot be used in compliance with IHL are prohibited, and emerging weapons in the realm of LAWS must maintain appropriate human involvement.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-Canada-EN.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": []
      }
    },
    "China": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Working Paper of the PRC on Lethal Autonomous Weapons Systems (LAWS) to the UN GGE (Jul 2022)\n\nThe paper defines unacceptable conditions of LAWS, to include: lethality of payload, complete autonomy, impossibility of termination, indiscriminate killing, and self-evolution. It also outlines the acceptability of LAWS which comply with IHL and human control, for which China calls regulation and risk-mitigation.",
            "url": "https://documents.unoda.org/wp-content/uploads/2022/07/Working-Paper-of-the-Peoples-Republic-of-China-on-Lethal-Autonomous-Weapons-Systems%EF%BC%88English%EF%BC%89.pdf"
          },
          {
            "text": "Document Submitted by China to the UN Secretary-General on the Issue of \"Lethal Autonomous Weapons Systems\" (May 2024)\n\nChina views the Convention on Certain Conventional Weapons (CCW) as a suitable platform for discussing LAWS. It states that defining the characteristics of LAWS is necessary to develop control measures, and a \"classification and grading\" approach should be used to address LAWS.",
            "url": "https://www.mfa.gov.cn/web/wjb_673085/zzjg_673183/jks_674633/fywj_674643/202405/t20240523_11310587.shtml"
          }
        ],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nChina abstained from voting on this resolution.\n\nThe resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "Statement of the Chinese Delegation at the Thematic Discussion on Conventional Weapons at the First Committee of the 79th Sessions of the UNGA (Oct 2024)\n\nThis statement calls for the human control over AI-driven weapons and support for the continued discussion on the ethical, humanitarian, and legal considerations of lethal autonomous weapons.",
            "url": "https://www.mfa.gov.cn/eng/wjb/zzjg_663340/jks_665232/kjfywj_665252/202410/t20241025_11516326.html"
          },
          {
            "text": "China Executive Vice Minister for Foreign Affairs at the UNSC (Sep 2025)\n\nExecutive Vice Minister Ma states that it is \"essential to ensure that AI remains under human control and prevents the emergence of lethal autonomous weapons that operate without human intervention\" when highlighting the risks of military applications of AI.",
            "url": "https://www.aa.com.tr/en/asia-pacific/china-urges-global-solidarity-in-ai-governance-warns-about-lethal-autonomous-weapons/3698234"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "A New Generation Artificial Intelligence Development Plan (Jul 2017)\n\nThis plan sets out guiding ideology for China's AI development, to include civil-military fusion and intelligent national defense infrastructure.\n\nBy 2025: the goal is to achieve major breakthroughs in theory/technology and reach world-leading aspects of AI, including national defense construction.\n\nBy 2030: China aims to be the world leader in AI theory, technology, and application.\n\nChina advocates for an \"Open-Source and Open\" approach to AI innovation, with a coordinated development of national defense, and the two-way (dual-use) conversion and application of military and scientific resources.",
            "url": "https://www.newamerica.org/cybersecurity-initiative/digichina/blog/full-translation-chinas-new-generation-artificial-intelligence-development-plan-2017/"
          },
          {
            "text": "China's National Defense in the New Era White Paper (Jul 2019)\n\nThis white paper states that China will advance \"intelligent warfare\" by integrating development, mechanization, and informatization.\n\nBy 2035, China's goal is to have completed the modernization of national defense and the military.",
            "url": "https://english.www.gov.cn/archive/whitepaper/201907/24/content_WS5d3941ddc6d08408f502283d.html"
          },
          {
            "text": "Document Submitted by China in Accordance With UNGA Resolution 79/239 on the Opportunities and Challenges of Military Applications of AI (Mar 2024)\n\nThis document reiterates China's stance on avoiding military superiority by using AI and preventing an AI arms race.\n\nChina maintains that relevant weapons should remain under human control and respect human dignity and human rights, while emphasizing that military applications of artificial intelligence must be guided in the \u201cright direction\u201d and constrained to prevent unchecked growth.",
            "url": "https://www.mfa.gov.cn/web/wjb_673085/zzjg_673183/jks_674633/fywj_674643/202504/t20250421_11598980.shtml"
          }
        ],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "A New Generation Artificial Intelligence Development Plan (Jul 2017)\n\nThe plan explicitly calls for normalized mechanisms for communication and coordination between scientific research institutes, universities, enterprises, and military industry.",
            "url": "https://www.newamerica.org/cybersecurity-initiative/digichina/blog/full-translation-chinas-new-generation-artificial-intelligence-development-plan-2017/"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "CCW Conference Position Paper of the People's Republic of China on Regulating Military Application of Artificial Intelligence (AI) (Dec 2021)\n\nThe paper states that countries \"must bear in mind that military applications of AI shall never be used as a tool to start a war or pursue hegemony.\" It also states that new weapons and their methods of warfare must comply with IHL and other applicable international laws.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-SixthReview_Conference_(2021)/CCW-CONF.VI-WP.2.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "China's Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\nChina did not sign or endorse the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.reaim2024.kr/home/reaimeng/board/bbsDetail.do?encMenuId=4e57325766362f626e5179454e6d6e4d4a4d33507a773d3d&encBbsMngNo=366e794c7a644d756342425668444f393053755142673d3d&encBbsNo=6f784e4542386f7735767465766a6531556f4b6149413d3d&ctlPageNow=1&schKind=bbsTtlCn&schWord=%23this"
          },
          {
            "text": "US DoS Political Declaration on Responsible Use of Artificial Intelligence and Autonomy (Nov 2024)\n\nChina was a non-participant in this declaration.\n\nSignatory states must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "CCW Conference Position Paper of the People's Republic of China on Regulating Military Application of Artificial Intelligence (AI) (Dec 2021)\n\nThe paper states that relevant AI weapon systems must be under human control and \"efforts must be made to ensure human suspension at any time,\" suggesting a human in the loop minimum.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-SixthReview_Conference_(2021)/CCW-CONF.VI-WP.2.pdf"
          },
          {
            "text": "Opportunities and Challenges Posed to International Peace and Security by the Application of AI in the Military Domain - Document submitted by China in accordance with General Assembly resolution 79/239 (Apr 2025)\n\nChina reiterates its commitment to a \"people-centered\" approach in military applications of AI and proposes the establishment of a testing and assessment system based on AI risk levels. It also plans to implement an agile governance response framework.\n\nChina holds that the human must be the \"final subject of responsibility\" in use-of-force decisions.",
            "url": "https://www.mfa.gov.cn/eng/wjb/zzjg_663340/jks_665232/kjfywj_665252/202504/t20250421_11598983.html"
          }
        ],
        "public_statements": [
          {
            "text": "Remarks by China's Permanent Representative to the UN Ambassador Fu Cong at the UNSC Briefing on Artificial Intelligence (Jan 2024)\n\nChina advocates for human control in military applications of AI to \"oppose the misuse, abuse, and proliferation of such systems.\" China also calls for a \"prudent and responsible\" attitude in developing AI technology in the military field, and stresses the need to maintain human control over the decision to use nuclear weapons.",
            "url": "https://www.fmprc.gov.cn/mfa_eng/xw/zwbd/202412/t20241225_11517873.html?ref=blog.denic.de&utm_source=chatgpt.com"
          },
          {
            "text": "Biden-Xi Statement on Human Control over Nuclear Arms (Nov 2024)\n\nNews reports state that Presidents Biden and Xi affirmed the need to maintain human control over the decision to use nuclear weapons and not delegate the responsibility to artificial intelligence.",
            "url": "https://www.reuters.com/world/biden-xi-agreed-that-humans-not-ai-should-control-nuclear-weapons-white-house-2024-11-16/"
          }
        ]
      }
    },
    "Colombia": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Submission by Colombia and Other Countries for the UN Secretary General Report on Resolution 78/241 (May 2023)\n\nColombia expresses its joint views on lethal autonomous weapons systems by stating support for a legally binding instrument through a Draft Protocol VI to prohibit certain uses of LAWS and regulate other forms of autonomous weapons.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-G14__Draft_Protocol_VI-EN.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nColombia voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nColombia voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "Bel\u00e9n Communiqu\u00e9 (Feb 2023)\n\nColombia adopted this joint communiqu\u00e9 along with 32 other Latin American and Caribbean countries, which calls for the urgent negotiation of a binding international treaty to prohibit and regulate LAWS. The document is grounded in the concept of meaningful human control and international humanitarian law (IHL).",
            "url": "https://www.rree.go.cr/files/includes/files.php?id=2261&tipo=documentos"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "CONPES 4144 Natinonal Artificial Intelligence Policy 2025-2030 (Feb 2025)\n\nThis document is a whole-of-government strategy and applies to all state entities, including the Ministry of Defense, and explicitly includes national security and defense as key mission sectors requiring AI governance, capability development, and responsible use.\n\nThe strategy establishes mandatory governance structures for AI projects, requiring risk assessment, transparency measures, algorithmic accountability, and security-by-design for all systems.\n\nThe following are seen as national security missions in which AI is a critical enabler: threat detection, cyber-defense, criminal intelligence, border surveillance, and critical infrastucture protection.",
            "url": "https://colaboracion.dnp.gov.co/CDT/Conpes/Econ%C3%B3micos/4144.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Policy for Science, Technology and Innovation for the Defense and Security Sector (2024) (2024)\n\nThe Ministry of Defense establishes military intelligence modernization, cyberdefense and security, border and territorial defense, interoperable defense innovation ecosystems as high priority areas in which AI is central.\n\nThe document signals an acceleration of innovation and implementation of AI throughout various defense functions, such as workforce development, intelligence, and logistics.",
            "url": "https://www.trade.gov/market-intelligence/colombia-defense-and-security-innovation-initiative"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Croatia": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Croatia National Statement at the Vienna Conference \"Humanity at the Crossroads: Autonomous Weapons Systems and the Challenge of Regulation\" (Apr 2024)\n\nCroatia advocates for the two-tier approach to regulating LAWS, emphasizing human control over autonomous weapons systems and accountability over the use of force.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Croatia_Natioanl_Statement.pdf"
          },
          {
            "text": "Statement by Croatia at the 71st Session of General Assembly at the Thematic Discussion on Conventional Weapons (Oct 2016)\n\nWhile this statement is from an earlier discussion on LAWS, Croatia emphasizes the principle of \"meaningful human control\" as pivotally important and that \"ultimate responsibility\" should remain with humans.",
            "url": "https://s3.amazonaws.com/unoda-web/wp-content/uploads/2016/10/21-Oct-Croatia-CW.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nCroatia voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nCroatia voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Minister of Defense Statement on Investment on Security, Armed Forces, and Defense Industry (May 2025)\n\nMinister Ivan Anusic states highlights the importance of strengthening national security, military modernization, and the domestic defense industry.\n\nHe highlights Croatia's goals of developing systems based on AI to protect critical military infrastructure and strengthen resilience to cyber threats.",
            "url": "https://www.morh.hr/en/croatia-invests-in-security-the-armed-forces-and-the-defence-industry/"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\nCroatia endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\nThe declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nCroatia signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "Czechia": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nCzechia abstained from voting on Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nCzechia voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Czech Armed Forces Development Concept 2030 (Oct 2019)\n\nThis document acts as policy guidance for the Czech armed forces to be mission-ready and effective.\n\nCzechia commits to introducing and developing robotization and artificial intelligence in CIS and CIS security.\n\nThe cyber forces are expected to implement autonomous systems and AI to align with the modernization of assets, and \"unmanned systems with a high degree of autonomous control\" will be acquired for reconnaissance forces and assets.",
            "url": "https://www.mo.gov.cz/assets/en/ministry-of-defence/basic-documents/cafdc.pdf"
          },
          {
            "text": "Czech Armed Forces Development Concept 2035 (Dec 2023)\n\nSection 4.9 foresees the use of AI in effective communication and analytic tools for open source information gathering and deep web monitoring.\n\nSection 6.3 expects the Czech Armed Forces to develop an experimentation capability for the development, testing, and application of emerging and disruptive technologies, with priority given to AI (among other technologies)..",
            "url": "https://www.mo.gov.cz/assets/en/ministry-of-defence/basic-documents/cafdc_2035.pdf"
          },
          {
            "text": "Czech Armed Forces Vision of Future Warfare Beyond 2040 (2024) (2024)\n\nCzechia sees the integration of AI in \"the management of technology\" and \"soldiers' decision-making processes during planning, managing, and conducting combat operations\".\n\nAI will be used for analyzing large amounts of data and assessing the battlefield situation, but Czechia advocates for the independent decision-making of human operators and commanders.\n\nArtificial intelligence is also expected to be used in medical support, for use cases such as virtual reality, robotics, and bio-sensing.\n\nCzechia views AI as a crucial asset to modernizing and enhancing its Armed Forces in all aspects.",
            "url": "https://www.mo.gov.cz/assets/en/ministry-of-defence/basic-documents/vize_2040_en_final_tisk.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Speech by Minister of Defense at Command Meeting of the Chief of the General Staff (Feb 2025)\n\nMinister of Defense Jana Cernochova states that artificial intelligence, robotization, automation, and autonomy will never completely replace humans and that \"there will always be an elected representative of citizens who will make decisions\".",
            "url": "https://mocr.mo.gov.cz/informacni-servis/zpravodajstvi/projev-ministryne-obrany-na-velitelskem-shromazdeni-nacelnika-generalniho-stabu-acr-256564/?utm_source=chatgpt.com"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nCzechia signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "Denmark": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Denmark Submission to the CCW GGE on LAWS (Aug 2024)\n\nDenmark supports the two-tier approach to regulating LAWS, which pushes for the prohibition of autonomous weapons that cannot comply with IHL and the regulation of all other types of weapons that operate with autonomous functions.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-Group_of_Governmental_Experts_on_Lethal_Autonomous_Weapons_Systems_%282024%29/GGE_LAWS_session_August_2024._Danish_statement._General_Statement.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nDenmark voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nDenmark voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "National Defence Industrial Strategy of the Danish Government (Aug 2021)\n\nAutonomous and unmanned systems are explicitly listed as areas of technological priority, focusing on drone technologies (swarm and autonomous operations) and counter-drone/counter-UAS capabilities.\n\nThe Ministry of Defence is given a priority goal of advancing digital development in artificial intelligence, particularly \"technologies and systems capable of collecting and analysing vas amounts of data.\"\n\nTechnologies of interest include those that promote the \"interplay of autonomous systems and people\".",
            "url": "https://www.fmn.dk/globalassets/fmn/dokumenter/nyheder/engelske/-national-defence-industrial-strategy-of-the-danish-government-.pdf"
          },
          {
            "text": "Danish Security and Defence Toward 2035 (Sep 2022)\n\nDenmark views AI and autonomous systems as emerging disruptive technologies, and suggests the deployment of autonomous systems for long-reach defensive reasons, especially in Greenland.",
            "url": "https://www.fmn.dk/globalassets/fmn/dokumenter/strategi/rsa/-regeringens_security-policy-report_uk_web-.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Statement by Denmark at Arria-Formula Meeting on AI (Apr 2025)\n\nDenmark advocates for human responsibility in the development, deployment, and use of AI in the military domain and for continued dialogue to enhance the safety and potential benefits of AI in conflict situations.",
            "url": "https://dkonunsc.dk/statements/04-04-2025-statement-by-denmark-at-arria-formula-meeting-on-ai?utm_source=chatgpt.com"
          },
          {
            "text": "Denmark's Statement at the UNSC Open Debate on the Use of AI (Sep 2025)\n\nDenmark reiterates its commitment to safe and trustworthy AI that complies with IHL and international law, citing several use cases for military applications.",
            "url": "https://dkonunsc.dk/statements/24-09-2025-denmarks-statement-at-the-unsc-open-debate-on-the-use-of-ai?utm_source=chatgpt.com"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\nDenmark endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\nThe declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nDenmark signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "Egypt": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Egypt's Views on Lethal Autonomous Weapons Systems Resolution A/78/241 (May 2024)\n\nEgypt supports a two-tiered approach to regulating LAWS, combining a prohibition of fully autonomous weapons and the regulation of other military applications of AI.\n\nEgypt views human responsibility as central to the discussion on autonomy in weapons systems, stating that \"regardless of the type of weapon systems that deliver the force, delegating the decisions to take a human life to machines is unethical and represents a grave violation of IHL\".",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Egypt-EN.pdf"
          },
          {
            "text": "Egypt National Statement at the Vienna Conference: Humanity at the Crossroads \"Autonomous Weapons Systems and the Challenge of Regulation\" (Apr 2024)\n\nThis document reitarates Egypt's position that the two-tiered approach is most effective in regulating autonomous weapons systems.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Egypt_National_Statement.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nEgypt voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nEgypt voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Estonia": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Joint Paper to the CCW on Categorizing Lethal Autonomous Weapons Systems (Aug 2018)\n\nThis joint paper with Finland stresses the need to understand autonomy levels, targeting functions, and human involvement for compliance with IHL.\n\nThe document states that \"humans must retain ultimate control over decisions of life and death,\" but \"human control does not necessarily have to be exercised contemporaneously with the delivery of force\".",
            "url": "https://unoda-documents-library.s3.amazonaws.com/Convention_on_Certain_Conventional_Weapons_-_Group_of_Governmental_Experts_%282018%29/2018_GGE%2BLAWS_August_Working%2BPaper_Estonia%2Band%2BFinland.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Group of Governmental Experts (GGE) on LAWS - Statement by Estonia (Mar 2019)\n\nEstonia declares that humans must exercise control over a weapon system to ensure that the system operates in accordance with IHL, and that autonomous functions may be permissible if they are used consistently with the law.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-_Group_of_Governmental_Experts_%282019%29/LAWS%2BGGE%2B2019%2BI%2B-%2BEstonia%2B-%2BAgenda%2Bitem%2B5%28c%29.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Defence Artificial Intelligence Strategy for Estonia (2025) (2025)\n\nSection 3.4 explicitly address the use of AI in autonomous weapons, including Estonia's support for such weapons. However, the document states a need for human control over the final decision on the use of lethal force.\n\nThe Strategy requires a weapons analysis in accordance with Article 36 of Protocol 1 of the Geneva Convention.",
            "url": "https://kaitseministeerium.ee/sites/default/files/defence_artificial_intelligence_strategy_for_estonia.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \"Lethal Autonomous Weapons Systems\" (Dec 2023)\n\nEstonia voted in support of this Resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS.",
            "url": "https://automatedresearch.org/news/state_position/estonia/"
          },
          {
            "text": "UNGA Draft Resolution L.77 (Oct 2024)\n\nEstonia abstained from voting on this draft resolution.\n\nThe resolution repeatedly calls for a binding legislation on a legally binding instrument with prohibitions and restrictions on.\n\nThis resolution also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://automatedresearch.org/news/state_position/estonia/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Defence Artificial Intelligence Strategy for Estonia (2025) (2025)\n\nSection 3.2 mandates the appointment of a Chief Innovation Officer and/or Chief Digitalization Officer, who is responsible for a new unit guiding digital and technological developments for AI. The section outlines responsibilities for this position and presents expected frameworks regarding data and AI concepts for the Ministry of Defence to produce.\n\nSection 3.2 calls for an update to the Estonian Military Academy curriculum, increasing funding for AI studies, and leveraging civilian STEM capacity to address workforce gaps within the Ministry of Defence.",
            "url": "https://kaitseministeerium.ee/sites/default/files/defence_artificial_intelligence_strategy_for_estonia.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Estonian Ministry of Defense Joint Statement on AI-Driven Defence Cooperation (Aug 2024)\n\nThis statement announces the advancement of Estonia's defense capabilities through the development and application of AI technologies.\n\nEstonia will explore software-defined reconnaissance and strike capabilities using AI.",
            "url": "https://www.kaitseministeerium.ee/en/news/estonian-ministry-defence-and-helsing-ou-sign-joint-statement-ai-driven-defence-cooperation?utm_source=chatgpt.com"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Defence Artificial Intelligence Strategy for Estonia (2025) (2025)\n\nSection 3.4 commits to developing and deploying defense AI in accordance with international law, NATO's six Principles of Responsible Use (PRUs), and national ethical values. It explicitly references compliance with international humanitarian law as a requirement.",
            "url": "https://kaitseministeerium.ee/sites/default/files/defence_artificial_intelligence_strategy_for_estonia.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "US DoD Political Declaration on Responsible Use of Artificial Intelligence and Autonomy (Nov 2024)\n\nEstonia signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "Estonia's Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (May 2025)\n\nEstonia supports the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.eeas.europa.eu/delegations/un-geneva/eu-statement-conference-disarmament-developments-science-and-technology-related-disarmament-and_en"
          }
        ]
      },
      "Int'l Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Finland": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Submission by Finland Concerning UNGA Resolution 78/241 on LAWS (May 2024)\n\nFinland pursues an international instrument that provides principles or regulations on the development and deployment of LAWS.\n\nHumans must always retain the decision on the use of force.\n\nFinland supports the two-tier system, which would outlaw autonomous weapons systems that operate without any form of human involvement and outside a responsible chain of command, and regulate the development and use of all other weapons with autonomous functions.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-Finland-EN_0.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nFinland voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nFinland voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Finnish Defence Forces Data and Artificial Intelligence Strategy (Nov 2025)\n\n(Disclaimer - document is not publicly available)\n\nThe strategy presents the FDF's objectives for data-centric operations: ability to lead the operations of the FDF in a data-centric manner, safe use of information, effective information exchange, creating a situational picture, automation of routine tasks, and ensuring unified information management.",
            "url": "https://puolustusvoimat.fi/-/puolustusvoimien-data-ja-tekoalystrategia-on-julkaistu?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Opening Remarks by Minister for Foreign Affairs at Helsinki Roundtable on AI and National Security (Mar 2025)\n\nMinister Elina Valtonen frames AI as central for international security, stressing the urgency to master AI's role in defense and security while respecting IHL and international law.",
            "url": "https://valtioneuvosto.fi/en/-/opening-remarks-by-minister-elina-valtonen-at-the-helsinki-roundtable-on-ai-and-international-security?utm_source=chatgpt.com"
          },
          {
            "text": "Finnish Defence Forces Press Release on Indigenous AI Development (Oct 2025)\n\nThe Finnish Defence Forces (FDF) will begin to cooperate with NestAI, a Finnish AI group, to accelerate the development of AI capabilities.\n\nFinland pursues a data-centric approach to \"enhance operational processes and analytics-supported decision-making\".\n\nThe FDF also intends to establish the AI Agency Centre of Excellence in 2026, which will \"bring together expertise, development capacity and cooperation networks to apply AI to FDF needs.\".\n\nNestAI is one of many private sector companies the FDF currently does or plans to engage with to develop AI capabilities.",
            "url": "https://puolustusvoimat.fi/en/-/finnish-defence-forces-to-accelerate-indigenous-ai-development-with-nestai?utm_source=chatgpt.com"
          },
          {
            "text": "Press Release on Joining Political Declaration on Responsible Military Use of Artificial Intelligence in the Military Domain (Oct 2023)\n\nMinister of Defence Antti Hakkanen approved the proposal for Finland to endorse the political declaration led by the US.\n\nFinland views the regulation of AI and autonomous weapons as ethical matters as well as defense industry and trade policy opportunities.",
            "url": "https://valtioneuvosto.fi/en/-/236553176/finland-joins-the-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Submission by Finland Concerning UNGA Resolution 79/239 Artificial Intelligence in the Military Domain and its Implications for International Security (Apr 2025)\n\nFinland states that it is committed to developing, deploying, and using AI capabilities in the military domain in a manner which complies with IHL and international law.\n\nThe document outlines FInland's recognition of the challenges and potential benefits of AI in the future of warfare, and emphasizes responsible development and use.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Finland-en.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\nFinland endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\nThe declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nFinland signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "France": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Artificial Intelligence in Support of Defence (Sep 2019)\n\nSection 2: Armed Forces Ministry Roadmap; states that \"France has no plans to develop fully autonomous systems where human operators have no control over the definition and performance of their missions.\" Furthermore, the development of AI for military use will systematically retain commander's responsibility for the use of such weapons.",
            "url": "https://www.defense.gouv.fr/sites/default/files/aid/Report%20of%20the%20AI%20Task%20Force%20September%202019.pdf"
          },
          {
            "text": "France Submission Pursuant to UNGA Resolution A/RES/78/241 on Lethal Autonomous Weapons Systems (May 2024)\n\nFrance supports the two-tier approach to regulating LAWS. France calls for the prohibition of LAWS that cannot be developed and used in accordance with IHL and the regulation of other types of autonomous weapons by implementing appropriate measures throughout the lifecycle of the system to mitigate legal, ethical, and security challenges.\n\nThe document reaffirms the necessity of the human to retain command and control over decisions to use lethal force.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-France-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Armed Forces Minister Statement on \"Killer Robots\" (Apr 2019)\n\nFormer Minister Florence Parly states that France will not delegate life-and-death decisions to any fully autonomous machine or system. She emphasizes that France will develop military AI only in accordance with international law, with sufficient human control and permanent command responsibility.",
            "url": "https://cd-geneve.delegfrance.org/La-France-ne-developpera-pas-de-robots-tueurs-Discours-de-la-Ministre-des?utm_source=chatgpt.com"
          },
          {
            "text": "Defense Ethics Committee Opinion on the Integration of Autonomy Into Lethal Autonomous Weapon Systems (Apr 2021)\n\nThe Committee distinguishes between Lethal Autonomous Weapon Systems (LAWS) and Partially Autonomous Lethal Weapon Systems (PALWS) and confirms France's decision to never develop or use fully autonomous systems.",
            "url": "https://www.defense.gouv.fr/sites/default/files/ministere-armees/20210429_Comite_Ethique_Defense_avis_autonomie_EN.pdf"
          },
          {
            "text": "General Statement by France to the UN GGE on LAWS (Jul 2022)\n\nFrance states that the two-tier approach is most appropriate to regulating LAWS, stressing IHL compliance, human control, and promoting the CCW as an appropriate forum for additional discussion on this topic.",
            "url": "https://cd-geneve.delegfrance.org/General-statement-of-France-to-the-Group-of-Governmental-Experts-GGE-on-lethal"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nFrance voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UNGA Draft Resolution L.77 (Oct 2024)\n\nFrance voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\nFrance led and endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\nThe declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [
          {
            "text": "Military Programming Law (MPL) 2024-2030 (Aug 2023)\n\nThis law sets milestones for the desired number of personnel working under the Ministerial Agency for Defence Artificial Intelligence (AMIAD), with a goal of a 700 personnel growth from 2024-2026.",
            "url": "https://www.defense.gouv.fr/sites/default/files/cde_1/Livret%20de%20pr%C3%A9sentation%20de%20la%20Loi%20de%20programmation%20militaire%202024-2030%20%286%20avril%202023%29.pdf"
          }
        ],
        "policy_documents": [
          {
            "text": "Defense Innovation Orientation Document (2019) (2019)\n\nSections 3.8 and 3.9 outline the challenges that the Ministry of Armed Forces must address in regard to artificial intelligence and the direction the Ministry will take to advance capabilities and technological prowess.\n\nAI and autonomy are identified as \"priority capability axes, and presents plans to accelerate acquisition of AI-enabled systems, stressing interoperability and security.",
            "url": "https://www.defense.gouv.fr/sites/default/files/aid/Document-dorientation-de-linnovation-de-Defense-DOID-2019.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Artificial Intelligence in Support of Defence (Sep 2019)\n\nSection 2.4.1 creates a Defence Artificial Intelligence Coordination Unit (CCIAD) attached to the Defence Innovation Agency (AID) and describes three governance levels and the model for implementation within the Armed Forces Ministry.\n\nSection 2.2: Data and Hardware; addresses the governance of data, creates a data architecture with three phases of implementation into the development of AI.",
            "url": "https://www.defense.gouv.fr/sites/default/files/aid/Report%20of%20the%20AI%20Task%20Force%20September%202019.pdf"
          },
          {
            "text": "Ministry of the Armed Forces Combined Arms Center of Concepts, Doctrine, and Experiments (CICDE) \"Operational Employment of Artificial Intelligence\" (Dec 2020)\n\nThis document acts as a joint exploratory concept on the use of AI in the military, outlining the role of AI in C2, ISR, decision support, and man-machine teaming.\n\nChapter 4 Section VI: emphasizes human supervision and control and states that AI systems should be usable, understandable, and subject to appropriate regulations.",
            "url": "https://www.defense.gouv.fr/sites/default/files/cicde/20201202-NP-CEIA-3.0.1_EMPLOI-SYST-ARMES-LETAUX-AUTONOMES.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nFrance voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle. It encourages global efforts to pursue action, participate in multilateral dialogue and knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Artificial Intelligence in Support of Defence (Sep 2019)\n\nSection 2.5.1 aims to set up key partnerships between the Armed Forces Ministry and academic research organizations that have significant AI skills.\n\nSection 2.5.3 dedicates \u20ac430 million to upstream AI-related studies from 2019-2025.",
            "url": "https://www.defense.gouv.fr/sites/default/files/aid/Report%20of%20the%20AI%20Task%20Force%20September%202019.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "French Defence Procurement Agency (DGA) Contract with Airbus (Dec 2025)\n\nThe French Defence Procurement Agency awarded Airbus Defence and Space a contract of \u20ac50 million to integrate AI components into weapons, information, communications, and cybersecurity systems used by the French armed forces. The first stage aims to increase France's maritime surveillance system with AI elements, with future collaboration expected in real-time assistance in managing and optimizing military telecommunications networks.",
            "url": "https://www.airbus.com/en/newsroom/press-releases/2025-12-airbus-to-onboard-artificial-intelligence-in-french-armed-forces"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Artificial Intelligence in Support of Defence (Sep 2019)\n\nSection 2.1: A Robust Ethical Legal Framework for the Armed Forces Ministry; establishes the creation of a ministerial ethics committee, takes steps to raise awareness on the use of AI from an ethical standpoint, and implements the standardization of norms within France and the international community.",
            "url": "https://www.defense.gouv.fr/sites/default/files/aid/Report%20of%20the%20AI%20Task%20Force%20September%202019.pdf"
          },
          {
            "text": "Ministry of the Armed Forces Combined Arms Center of Concepts, Doctrine, and Experiments (CICDE) \"Operational Employment of Artificial Intelligence\" (Dec 2020)\n\nChapter 4 Section I covers the ethics and legality of using AI in military applications, including compliance with IHL, sufficient human control, and the permanent and necessary responsability of command.",
            "url": "https://www.defense.gouv.fr/sites/default/files/cicde/20201202-NP-CEIA-3.0.1_EMP-OPS-IA2020-VF.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Defense Ethics Committee Opinion on the Use of AI Technologies by the French Armed Forces (Jan 2025)\n\nThis document presents 9 Principles and 12 Recommendations covering all aspects of military AI and calls for: proportionate use of force in line with the Law of Armed Conflict, command responsibility, transparency to avoid the \"black box\" effect, and rigorous benefit-risk evaluation.\n\nFrance reiterates the need for clear human responsibility and control across the AI life cycle.",
            "url": "https://www.defense.gouv.fr/sites/default/files/ministere-armees/20250114_Opinion%20on%20the%20use%20of%20artificial%20intelligence%20technologies%20by%20the%20French%20armed%20forces.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Defense Ethics Committee Opinion on the Integration of Autonomy Into Lethal Autonomous Weapon Systems (Apr 2021)\n\nSection II.D.a covers the moral acceptability of using force without human intervention, stating that the moral acceptability of using force will vary based in different operational situations.",
            "url": "https://cd-geneve.delegfrance.org/IMG/pdf/defence_ethics_committee_-_opinion_on_the_integration_of_autonomy_into_lethal_weapon_systems.pdf?2423/17d8f6beb2f5c9caa9c9168c53c24a91d9d32513"
          },
          {
            "text": "France's Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\nFrance supports the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.carnegiecouncil.org/media/article/principles-action-military-ai-governance"
          },
          {
            "text": "US DoS Political Declaration on Responsible Use of Artificial Intelligence and Autonomy (Nov 2024)\n\nFrance signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "Int'l Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Artificial Intelligence in Support of Defence (Sep 2019)\n\nSection 2.6: International Cooperation and Export Strategy; presents different circles of potential cooperation, which are categorized as structural partnerships, scoping partners, and occasional partners.",
            "url": "https://www.defense.gouv.fr/sites/default/files/aid/Report%20of%20the%20AI%20Task%20Force%20September%202019.pdf"
          }
        ],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Artificial Intelligence in Support of Defence (2019) (2019)\n\nSection 2.1.3: Technical Measures to Ensure Trustworthy AI; ensures that the \"right level\" of trustworthiness and robustness is assessed for each AI application, commensurate with the criticality of the functions performed. It also includes a figure outlining risk level of AI-based algorithmic technology according to criticality.\n\nSection 1.2.2: Assurance of Trustworthy, Controlled, and Responsible AI; states that systems containing AI must have robust and secure frameworks to avoid \"black-box\" effects, and must retain human responsibility for action.",
            "url": "https://www.defense.gouv.fr/sites/default/files/aid/Report%20of%20the%20AI%20Task%20Force%20September%202019.pdf"
          }
        ],
        "public_statements": []
      }
    },
    "Germany": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "German Commentary on \"Operationalizing All Eleven Guiding Principles at a National Level as Requested by the Chair of the 2020 GGE on LAWS within the CCW\" (2020) (2020)\n\nGermany states that as \"machines cannot be held liable for the actions they effect - neither morally, politically not legally... humans remain responsible for the actions they effect throughout the entire life cycle\".\n\nHumans must have assurance that a relevant weapon system, once activated, conform to the applicable laws, rules, of engagement, and intentions of its operator.\n\nThe document also offers a commentary on how Germany does or plans to implement the guiding principles.",
            "url": "https://documents.unoda.org/wp-content/uploads/2020/07/20200626-Germany.pdf"
          },
          {
            "text": "Germany National Statement at the Vienna Conference \"Humanity at the Crossroads: Autonomous Weapons Systems and the Challenge of Regulation\" (Apr 2024)\n\nGermany states that LAWS that cannot comply with IHL should be prohibited, supporting a legally binding instrument consented by the GGE on LAWS to ban such weapons.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Germany_National_Statement.pdf"
          },
          {
            "text": "Germany's Submission to the UN Secretary General's Report on Lethal Autonomous Weapons Systems (May 2024)\n\nHuman control is seen as a key requirement when assessing the admissability of weapons that contain autonomous functions and supports an additional legally binding instrument to prohibit the development, use, and acquisition of LAWS  \"operating outside of human control and a responsible chain of command\".\n\nGermany states that the decision over life and death must be made by humans.\n\nThe document states that Germany supports a two-tier approach to regulating LAWS, where a prohibition on LAWS that do not comply with IHL is in place, and a regulation of weapons systems that do have autonomous functions and are within the bounds of IHL.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Germany-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Foreign Minister Statement on Agreement to Guiding Principles Relating to LAWS (Feb 2020)\n\nMinister Haas states that \"Killer robots must never become a reality\" and reiterates Germany's goal of creating a worldwide ban on fully autonomous lethal weapons systems (2019).\n\nHe states that \"letting machines decide over life and death of human beings runs against all of our ethical standards\" (2020).",
            "url": "https://www.auswaertiges-amt.de/en/newsroom/news/maas-autonomous-weapons-systems-2277194?utm_source=chatgpt.com"
          },
          {
            "text": "Foreign Minister Statement on the Use of Fully Autonomous Weapons Systems (Mar 2019)\n\nForeign Minister Heiko Maas states that Germany supports a worldwide ban on fully autonomous weapons systems (LAWS).",
            "url": "https://www.auswaertiges-amt.de/en/newsroom/news/maas-autonomous-weapons-systems-2277194"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nGermany voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nGermany voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\nGermany endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\nThe declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Germany's National Contribution to the UN Secretary General's Report on the Opportunities and Challenges Posed to Int'l Peace and Security by the Application of AI in the Military Domain (Apr 2025)\n\nThis document states that Germany is aligned with NATO's Principles of Responsible Use (PRUs) and endorses various multilateral frameworks.\n\nGermany states that it is committed to addressing risks associated with the use of AI in the military domain and reaffirms its view on maintaining human control as a necessary condition for military AI.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Germany-en.pdf"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nGermany signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "Greece": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Submission by Greece Pursuant to the UN Secretary General Report on LAWS (May 2024)\n\nGreece supports a two-tier approach to regulating LAWS and advocates that military AI must fully comply IHL.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Greece-EN.pdf"
          },
          {
            "text": "Statement by Greece to the GGE on LAWS (Mar 2019)\n\nGreece states that it is \"important that commanders and operators will remain on the loop of the decision-making process in order to apply the appropriate human judgement over the use of force\".\n\nThe document provides Greece's definition of a fully autonomous weapon system, and calls for the testing of critical functions in highly autonomous systems during development stage.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-_Group_of_Governmental_Experts_%282019%29/GGE%2BLAWS%2BSTATEMENT%2Bby%2BGREECE-%2BChallenges%2Bto%2BIHL.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nGreece voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nGreece voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Greece's Contribution to the UN Secretary General on Resolution 79/239 (2025) (2025)\n\nThis document frames Greece's efforts to implement and lead in safe and responsible use of AI in the military and defense.\n\nGreece addresses the challenges that arise from applying AI in military contexts and commits to continued engagement in developing international standards.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Greece-en.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Prime Minister Speech at a UN Security Council Event (Sep 2025)\n\nPrime Minister Kyriakos Mitsotakis aligns Greece with various multilateral frameworks on the safe and responsible use of AI in the military domain and commits Greece to always implementing human oversight in the development and use of AI for military use.",
            "url": "https://www.primeminister.gr/en/2025/09/25/37026?utm_source=chatgpt.com"
          },
          {
            "text": "Minister of National Defence Inauguration of International Defence Exhibition (May 2025)\n\nMinister of Defense Nikos Dendias states that Greece \"pursues a presence in the developments in crucial area, in artificial intelligence, in unmanned autonomous systems, cyber operations, and space applications\".",
            "url": "https://www.mod.mil.gr/en/the-minister-of-national-defence-nikos-dendias-inaugurates-the-international/?utm_source=chatgpt.com"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Hellenic Centre for Defence Innovation (HCDI) Call for Proposals (Mar 2025)\n\nThe HCDI, the contracting authority for defense and security programs, called for the development of \"dual-mode multi-configuration Unmanned Surface Vehicles, capable of operating with autonomous or semi-autonomous navigation\" among other military capabilities.",
            "url": "https://www.elkak.gr/en/hcdi-issues-calls-proposals-unmanned-systems-and-command-control-and-information-systems?utm_source=chatgpt.com"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\nGreece endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\nThe declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nGreece signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "Hungary": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nHunary voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nHungary voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "National Military Strategy of Hungary (Oct 2021)\n\nThe Hungarian armed forces commits to developing artificial intelligence to \"enhance soldiers' preparedness, survivability, and operational efficiency.\".\n\nAI is also expected to be used in decision support systems with the ability to \"support operations with real-time updates across all operational domains\".",
            "url": "https://defence.hu/news/national-military-strategy-of-hungary.html"
          }
        ],
        "public_statements": [
          {
            "text": "Defense Minister at AI Summit 2024 (Sep 2024)\n\nMinister Kristof Szalay-Bobrovniczky states that the human factor is \"indispensable\" in the use of artificial intelligence in defense.\n\nThere are also calls for cooperation between the defense industry and civilian businesses.",
            "url": "https://abouthungary.hu/news-in-brief/defense-minister-at-ai-summit-2024-human-factor-is-indispensable-in-defense"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nHungary signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "India": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "India Submission to the UN Secretary General Pursuant to Resolution 78/241 on LAWS (May 2024)\n\nIHL should apply to all aspects of lethal autonomous weapons, and India supports the view that emerging technologies, in general, have the potential to improve compliance with IHL.\n\nThe document states India's view that states should limit the types of targets LAWS can engage, limit the duration, geographical scope, and scale of operations, and provide appropriate training to operators of LAWS. This signals India's stance that it does not oppose toe development or use of autonomous weapons systems.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-India-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nIndia voted against this resolution.\n\nThe resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nIndia abstained from the vote on Draft Resolution L.77 on lethal autonomous weapons systems.\n\nThe resolution signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [
          {
            "text": "Executive Order Creating the Defence AI Council (DAIC) and the Defence AI Project Agency (DAIPA) (Feb 2019)\n\nThis executive order creates the DAIC and DAIPA, which provide necessary guidance to enable and develop operating frameworks, policy level changes, and structural support for AI adoption.",
            "url": "https://www.pib.gov.in/PressReleaseIframePage.aspx?PRID=1810442&reg=3&lang=2"
          }
        ],
        "policy_documents": [
          {
            "text": "Defence Minister Statement on Employing AI in the Armed Forces (Aug 2018)\n\nThe Defence Minister presents \"thrust areas\" identified for employing AI to enhance future capabilities, some of which include: object identification and image classification, intelligence & autonomous unmanned systems, defense, offense, and command information warfare, autonomous underwater vehicles, etc.",
            "url": "https://sansad.in/getFile/loksabhaquestions/annex/15/AU3471.pdf?source=pqals&utm_source=chatgpt.com"
          },
          {
            "text": "Strategic Implementation of AI for National Security and Defense (Feb 2019)\n\nThis document adopts and mandates several provisions recommended by the Ministry of Defence Task Force.\n\nThe High Level Defence AI Council (DAIC) is established, which provides necessary guidance to enable and effect the development of operational frameworks, policy changes, and structural support.\n\nThe Ministry of Defence (MOD) is ordered to allocate funds to the Defence AI Project Agency (DAIPA) and other AI-specific application development.\n\nThe document mandates AI capacity building frameworks, which includes AI-specific training for defense personnel.",
            "url": "https://www.ddpmod.gov.in/sites/default/files/123b4638d3f145463b3e40614e9e78c3dd74f1c39351594bb4bd9c545e0de04d/82b14144040372c3f831243d48de3cdad873fcbce7be33a1269dfc58e96b0692."
          },
          {
            "text": "Ministry of Defence Development of Advanced Technologies for Military (Mar 2022)\n\nThis document responds to an inquiry into details of government progress on developing advanced technologies.\n\nThe Defence Research Development Organisation (DRDO) has two dedicated AI laboratories for application oriented research in AI, both of which have AI technology groups to introduce AI features into products under development.",
            "url": "https://sansad.in/getFile/loksabhaquestions/annex/178/AU3904.pdf?source=pqals"
          }
        ],
        "public_statements": [
          {
            "text": "Press Release on Task Force for Implementation of AI (Mar 2022)\n\nThis press release announces the establishment of the AI Sub Committee and Joint Working Group on AI in Tri-Services.\n\nEach service has also formulated data policy and appointed Data Management Officers, engaged in the development of AI projects through iDEX, and have implemented training frameworks for defense personnel.",
            "url": "https://www.pib.gov.in/PressReleasePage.aspx?PRID=1810442&reg=3&lang=2"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Ministry of Defence Innovation in Defence Production Projects (Mar 2023)\n\nThis document presents the list of government-approved projects under the Innovations for Defence Excellence (iDEX) framework, which aims to foster innovation and technology development in Defence by engaging with industry.\n\nProjects include AI-based satellite image analysis, autonomous underwater swarm drones and weaponized boat swarms, AI-based intelligence capabilities, and others.",
            "url": "https://sansad.in/getFile/annex/259/AU1329.pdf?source=pqars&utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Defence Minister Launches 75 AI Products/Technologies at \"AI in Defence\" Symposium (Jul 2022)\n\nDefence Minister Shri Rajnath Singh launched 75 newly-developed AI products and technologies during the New Delhi Symposium, which included domains regarding AI platform automation, autonomous/unmanned/robotic systems, LAWS, and ISR (among other topics).\n\nMinister Singh asserted that India has begun to incorporate AI into remote piloted, unmanned aerial vehicles.\n\nIndia's Ministry of Defence is working closely with academic insitutions and industry, and three dual-use application products were screened to potentially open new avenues for defense innovation.",
            "url": "https://www.pib.gov.in/PressReleasePage.aspx?PRID=1840740&reg=3&lang=2"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nIndia voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and to submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Iran": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Iran Statement on Lethal Autonomous Weapons Systems (2023) (2023)\n\nThe representative from Iran to the UN stated that Iran will abstain from voting on the draft resolution titled \"Lethal Autonomous Weapons Systems\" due to a lack of a clear definition and scope of the terminology \"lethal autonomous weapons\".",
            "url": "https://press.un.org/en/2023/gadis3731.doc.htm"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nIran abstained from voting on this resolution.\n\nThe resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nIran abstained from voting on this resolution.\n\nThe resolution signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Iraq": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by the Delegation of the Republic of Iraq at the UNGA on Conventional Weapons (Oct 2025)\n\nIraq calls for legally binding provisions that are consistent with IHL and the UN Charter to regulate lethal autonomous weapons systems.",
            "url": "https://reachingcriticalwill.org/images/documents/Disarmament-fora/1com/1com24/statements/24Oct_Iraq.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nIraq voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nIraq voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "Statement at the CCW GGE on LAWS (Aug 2021)\n\nIraq states that the responsibility of the decision to take life and death should never be delegated to machines and that doing so is a violation of international humanitarian law.",
            "url": "https://conf.unog.ch/digitalrecordings/en/clients/61.0500/sessions/5EBAAABD-DD16-458E-A2C9-FEA476FCE99B"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Israel": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Israel's Submission Pursuant to Resolution 78/241 \"Lethal Autonomous Weapons Systems\" (May 2024)\n\nIsrael views human control as a potentially relevant concept in the implementation of IHL obligations in different circumstances.\n\nIt acknowledges the importance of dialogue on LAWS in forums such as CCW and finds CCW the most suitable avenue for addressing the challenges and opportunities presented by LAWS.\n\nIHL is a sufficient legal framework for any future use of LAWS in armed conflicts and stresses that the focus of the application of relevant laws should include the operational context in which the weapon system is used.\n\nThe paper states that \"discussion of the implementation of IHL rules that are context-dependent should not be conflated with discussion of the per se legality of weapons\"..",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Israel-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 on Lethal Autonomous Weapons Systems (Dec 2023)\n\nIsrael abstained from voting on this resolution.\n\nThe resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "Israel's Vote on UN Draft Resolution L.77 on Lethal Autonomous Weapons Systems (Oct 2024)\n\nIsrael abstained from voting on this draft resolution.\n\nThe resolution raises concerns about the \u2018negative consequences and impact of autonomous weapon systems on global security and regional and international stability\u2019 and stresses \u2018the importance of the role of humans in the use of force to ensure responsibility and accountability and for States to comply with international law\u2019.",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "Israel's Vote on UNGA Resolution 79/239 \"Artificial Intelligence in the Military Domain and Its Implications for International Peace and Security\" (Dec 2024)\n\nIsrael voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Israeli Defense Force (IDF) Information & AI Strategy\n\nDISCLAIMER - document not publicly available.\n\nSecondary sources outline the IDF's plan to harness big data and integrate AI into all branches with a multi-level command framework.\n\nThe goal of the strategy is to make the IDF more effective, adaptable, and more efficient by harnessing AI capabilities.",
            "url": "https://www.c4isrnet.com/artificial-intelligence/2022/02/11/israel-unveils-artificial-intelligence-strategy-for-armed-forces/#:~:text=The%20IDF%20strategy%20spells%20out,Frantzman"
          },
          {
            "text": "National Program for Artificial Intelligence (Apr 2025)\n\nSection 6.4.4 outlines the IDF's plan to increase the number of AI experts in the defense organizations and launch an integrated program to train young graduates to be incorporated into relevant units.",
            "url": "https://innovationisrael.org.il/wp-content/uploads/2025/05/AI-National-Program-en-14.5.25.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "IDF Director of Digital Transformation Administration Statement (Feb 2022)\n\nBrigadier General Dagan, the Director of Digital Transformation Administration, states that the IDF is remodernizing by way of digital networking across branches and command ranks. This means that the IDF will build \"mini-clouds, or networks, for each of its arms and sometimes smaller subdivisions so that they can process and receive data even faster than in the current network\".",
            "url": "https://www.jpost.com/business-and-innovation/tech-and-start-ups/article-695843"
          },
          {
            "text": "Statement by the Israeli Ministry of Defense (IMOD) Director General on the AI and Autonomy Administration (Jan 2025)\n\nDirector General Major General Zamir states that the new AI and Autonomy Administration aims to centralize and advance AI and autonomous capabilities within IMOD.\n\nHe states that the \"future battlefield will see integrated teams of soldiers and autonomous systems working in concert\" in all braches of IMOD.",
            "url": "https://mod.gov.il/en/press-releases/press-room/israel-mod-establishes-ai-and-autonomy-administration"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Press Release on the IDF's Use of Data Technologies in Intelligence Processing (Jun 2024)\n\nThis statement by the IDF states that the identification of targets for attacks is always done by an analyst and the process for such processes is subject to international law. Furthermore, the IDF stresses that AI systems cannot be the sole basis for identifying, selecting, or generating targets autonomously.\n\nThe IDF addresses claims of its employment of AI systems that autonomously select targets for attack and refutes these claims by stating that military and intelligence processes utilize AI-enabled tools to complete mission objectives in accordance with IDF standard operating procedures (SOPs).",
            "url": "https://www.idf.il/en/mini-sites/idf-press-releases-israel-at-war/june-24-pr/the-idfs-use-of-data-technologies-in-intelligence-processing-published-june-18-2024/"
          },
          {
            "text": "US DoS Political Declaration on Responsible MIlitary Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nIsrael signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "Italy": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by Italy to the CCW GGE on LAWS (Mar 2019)\n\nAmbassador Giancarto Incarnato states that the decision to use lethal force and to produce lethal effects should remain in human hands to guarantee accountability in the case of IHL violations and because only human judgement can adequately assess the application of IHL principles.\n\nThe document states that for Italy, human operators are responsible for the validation of selection of objectives and for the \"activation/deactivation of the autonomous mode of the relevant system\".",
            "url": "https://italiarappdisarmo.esteri.it/wp-content/uploads/2024/02/IURMIMD.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Italy's Contribution Pursuant to UNGA Resolution 78/241 \"Lethal Autonomous Weapons Systems\" (May 2024)\n\nItaly supports the creation of a new legally binding instrument to prohibit the development and use of LAWS.\n\nItaly supports the \"two-tier\" approach to regulating LAWS, which includes an outright prohibition of LAWS that cannot comply with IHL and a regulation of other \"systems featuring decision-making autonomy in critical functions\".\n\nThis document reiterates the criticality of human responsibility and command and control of autonomous weapons systems.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-Italy-EN.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nItaly voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nItaly voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "National Report Regarding UNGA Resolution 79/239 \"Artificial Intelligence in the Military Domain and its Implications for International Peace and Security\" (2025) (2025)\n\nItaly reiterates support for various multilateral functions that further the adoption of safe and responsible use of AI in the military.\n\nThis report includes Italy's support for an instrument with a clear set of prohibitions and regulations to be adopted as an Additional Protocol to the CCW, emphasizing the role of human control and responsibility.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Italy-en.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Act of Guidance for the Launch of the Integrated Cycle of Performance Programming and Budget Formation for the 2024 Financial Year and the 2025-2026 Multi-Annual Programming (2023) (2023)\n\nSection 2.18 lists artificial intelligence as a field in which the military will direct, guide, and control technological research.\n\nSection 3.6 suggests activities to bolster training systems and modules that \"combine traditional resources with innovative methodologies and \"narrow artificial intelligence\" algorithms.",
            "url": "https://www.difesa.it/assets/allegati/26763/atto_di_indirizzo_ed._2023_-_final.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Multi-Annual Programming Document 2025-2027 (2025) (2025)\n\nThis annual document highlights artificial intelligence as an emerging disruptive technology which the Italian military intends to develop.\n\nData infrastructure is listed as a top priority to invest into, including artificial intelligence.\n\nPrevious versions of the document also address the need to focus on AI for various functions within the military, such as predictive analysis and decision support.",
            "url": "https://www.difesa.it/assets/allegati/3756/documento_programmatico_pluriennale_2025-2027_pdfa.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Under Secretary of Defense on the Challenges and Opportunities of Advanced Technologies (Dec 2025)\n\nUnder Secretary of Defense Isabella Rauti hints at Italy's plan for adopting AI in the military in predictive analysis, decision-making, and support of the chain of command and control.\n\nShe states that humans must always validate and verify the output of artificial intelligence.",
            "url": "https://www.fortuneita.com/2025/12/03/difesa-il-sottosegretario-rauti-la-mutua-assistenza-e-fondamento-di-ogni-strategia/"
          },
          {
            "text": "Defense Minister on AI as a Government Priority (Mar 2024)\n\nDefense Minister Guido Crosetto states that AI is a priority for the Italian givernment in countering misuse by organizations with hostile objectives, and positions Italy as supporting full human control \"without compromising development opportunities\".",
            "url": "https://www.ansa.it/ansacom/notizie/economia/cybersec/2024/02/29/crosetto-intelligenza-artificiale-priorita-del-governo_d1f2244c-3539-4c3c-b32e-fefe4aa5f566.html"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nItaly voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nItaly signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "Japan": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Guideline for Responsible AI Application in Research and Development of AI-Equipped Defense Systems (June 2025)\n\nThis document states that autonomous weapons that operate completely outside of human involvement should be prohibited.",
            "url": "https://www.mod.go.jp/atla/soubiseisaku/ai_guideline/ai_guideline_ver.01_eng_202506.pdf"
          },
          {
            "text": "Working Paper Submitted by Japan to the UN on Emerging Technologies in the Area of Lethal Autonomous Weapon Systems (May 2024)\n\nJapan explicitly states that it will \"not conduct research, development, or operation of weapon systems whose use is not permitted under domestic or international law, including IHL.\"\n\nJapan reiterates that it does not intend to develop autonomous systems with lethal force that operate completely without human involvement and those with autonomous functions must have the ability to attribute responsibility to humans.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Japan-rev-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nJapan voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nJapan voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Defense of Japan White Paper (2025) (2025)\n\nA defense target for the MOD is accelerated decision-making through the use of AI and an overall push toward enhanced capabilities through unmanned assets in the aerial, land, and maritime domains.\n\nThis white paper is an annual publication that builds upon previous versions and outlines Japan's assessment of the current national security environment and plans to bolster the Self-Defense Force (SDF).\n\nPrevious DOJ documents include goals of improving AI-enabled intelligence functions, unmanned asset control, and automatic identification systems.",
            "url": "https://www.mod.go.jp/j/press/wp/wp2025/pdf/DOJ2025_EN_Full.pdf"
          },
          {
            "text": "Defense Buildup Program (Dec 2022)\n\nThis document presents Japan's plans to bolster its defense capabilities and mentions the Defense Intelligence Headquarters' (DIH) responsibility of developing \"automatic collection and analysis of open-source information using artificial intelligence.\" Use cases examples include social networking site information collection, authenticity analysis of international communication, and forecasting functions for security situation estimates.",
            "url": "https://www.mod.go.jp/j/policy/agenda/guideline/plan/pdf/program_en.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "National Defense Strategy (2022) (2022)\n\nThe strategy emphasizes the relevance and impact of AI on security, and commits to strengthening \"unmanned defense capabilities\" through early production and deployment or leasing by FY2027.\n\nJapan commits to further materializing unmanned assets and reinforcing \"the ability to simultaneously control multiple unmanned assets using systems such as AI\".",
            "url": "https://japan.kantei.go.jp/content/000120033.pdf"
          },
          {
            "text": "Ministry of Defense Basic Policy on Promoting the Utilization of AI (Jul 2024)\n\nThe MOD identifies seven fields in which to focus AI applications: detection and identification of targets, intelligence collection and analysis, command and control, logistics support operations, unmanned assets, cyber security, efficient administrative works.\n\nThe policy indicates that AI is applied to support human decision-making, not replace it.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Japan-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Japan Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\nJapan supports the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://asianews.network/seoul-summit-charts-framework-on-responsible-ai-military-use/"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "National Defense Strategy (2022) (2022)\n\nSection: Immediate Objectives; outlines procurement priorities for advanced standoff missiles, wide area defense capabilities, and an enhanced ability to simultaneously control unmanned assets.",
            "url": "https://japan.kantei.go.jp/content/000120033.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Automated Asset Procurement (Aug 2024)\n\nJapan's MOD announces a budget allocation for an Aisurveillance system for military base security, as well as the procurement of unmanned drones and three \"highly-automated air defense warships\" that require \"less than half the cew o current ships\".",
            "url": "https://www.reuters.com/world/japan/japans-military-spend-ai-automation-perks-combat-recruitment-crisis-2024-08-30/?utm_source=chatgpt.com"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [
          {
            "text": "Guideline for Responsible AI Application in Research and Development of AI-Equipped Defense Systems (June 2025)\n\nThis document presents classification definitions of AI-equipped systems, as well as the compliance measures that autonomous or AI-enabled weapons systems must meet.\n\nEach requirement outlined in the document provides \"confirmation item\" questions to ensure that the compliance measures are met.",
            "url": "https://www.mod.go.jp/atla/soubiseisaku/ai_guideline/ai_guideline_ver.01_eng_202506.pdf"
          }
        ],
        "policy_documents": [
          {
            "text": "Working Paper Submitted by Japan to the UN on AI in the Military Domain and its Implications for International Peace and Security (Apr 2025)\n\nThe Japanese MOD commits reducing the risks posed by AI, implementing the following concepts: human-centric, safety, fairness, privacy protection, ensuring security, transparency, and accountability.\n\nJapan views AI as having the potential to bring benefits to the military domain, such as improvements in precision, accuracy and efficiency, enhanced situational awareness, rapid information analysis, reduction of human errors, etc.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Japan-rev-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nJapan signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians.\n\nEndorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nJapan voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "Int'l Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US-Japan Joint Agreement for AI UAS Research (Dec 2023)\n\nThe US and Japan sign an agreement to conduct joint research on \"Overwhelming Response Through Collaborative Autonomy\".\n\nThis inititative aims to \"revolutionize airborne combat by merging state-of-the-art AI and machine learning with advanced unmanned air vehicles\".\n\nThe research is to be implemented in UAVs operating alongside Japan's next fighter aircraft.",
            "url": "https://www.af.mil/News/Article-Display/Article/3624158/japan-mod-us-dod-sign-joint-agreement-for-ai-uas-research/"
          },
          {
            "text": "Japan-South Korea Defense Upgrade Cooperation (Dec 2025)\n\nThe defense ministers of Japan and South Korea agreed to upgrade defense cooperation in incorporating artificial intelligence and unmanned weapon systems.",
            "url": "https://www.reuters.com/world/asia-pacific/south-korea-japan-defence-ministers-agree-upgrade-cooperation-2026-01-30/"
          }
        ]
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Latvia": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by Latvia at the Thmatic Debate on Conventional Weapons at the UNGA (Oct 2024)\n\nLatvia reiterates the need for human control and responsibility in the development and use of LAWS, and states that the GGE on LAWS is the most appropriate forum for continued discussion on regulating such weapons.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/Statement_by_Latvia.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nLatvia abstained from voting on Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nLatvia voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Guidelines for the Involvement of the Defence and Security Industry in Strengthening Defence Capabilities (2025) (2025)\n\nThis document outlines the targeted investments in innovation, technology development, and R&D for the period 2025-2028 in: Robotics and Autonomous Systems for the purposes of ISR, target identification, communications, kinetic effects, and logistics; AI and Machine Learning in processing data, supporting decision-making, and cyber defense.\n\nLatvia commits near term research efforts to focus on unmanned systems, artificial intelligence, and electronic warfare.",
            "url": "https://www.mod.gov.lv/sites/mod/files/document/Guidelines%20For%20The%20Involvement%20Of%20The%20Defence%20And%20Security%20Industry%20In%20Strengthening%20Defence%20Capabilities.pdf"
          },
          {
            "text": "Long-Term Development of the National Armed Forces 2025-2036 White Paper (Mar 2025)\n\nThis white paper sets the long term strategic goals for the National Armed Forces, including autonomous systems, machine learning, and artificial intelligence as key R&D priorities and capability development objectives for the defense sector.",
            "url": "https://www.mod.gov.lv/sites/mod/files/document/LONG-TERM%20DEVELOPMENT%20OF%20NAF.pdf"
          },
          {
            "text": "Defence Industry and Innovation Strategy 2025-2036 (2025) (2025)\n\nThis document addresses Latvia's relevant defense technology priorities for the next decade.\n\nRobotics, remotely controlled and autonomous systems are a development priority for use cases in unmanned aerial vehicles, remotely-controlled land vehicles, drone boats and underwater drones for ISR, target location, signal transmission, kinetic effects, and logistical support.\n\nArtificial intelligence and machine learning are another priority for use cases such as data processing, information landscape monitoring, and autonomous decission-making.",
            "url": "https://www.mod.gov.lv/sites/mod/files/document/Atbalsta_strate%CC%84g%CC%A7ija_ENG.pdf"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nLatvia signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "Latvia's Stance in the Responsible Artificial Intelligence in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\nLatvia supports the 'blueprint' for ethical and human-centric use of AI in the military, which emphasizes the importance of compliance with international law, human oversight, and risk assessment.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/Statement_by_Latvia.pdf"
          }
        ]
      }
    },
    "Lithuania": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nLithuania abstained from voting on Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nLithuania voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Lithuania's Arms Control and Nonproliferation Policy (Jun 2025)\n\nLithuania follows NATO's Principles of Responsible Use for artificial intelligence.\n\nLithuania also supports a two-tier approach to regulating autonomous weapons, combining a prohibition on weapons systems that cannot comply with IHL and a regulation of other types of weapons with autonomous functions.",
            "url": "https://www.urm.lt/en/lithuania-in-the-region-and-the-world/lithuanias-security-policy/arms-control-and-nonproliferation/998"
          },
          {
            "text": "Lithuania's Submission to the UN Secretary General on Resolution 79/239 (Apr 2025)\n\nLithuania supports various multilateral frameworks that discuss principles and good practice on AI in the military domain.\n\nLithuania also sees benefits in AI applications in the defense space, and is opposed to unnecessary and excessive restrictions that hinder AI innovation.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Lithuania-EN.pdf"
          }
        ],
        "public_statements": []
      }
    },
    "Morocco": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by the Kingdom of Morocco at the Vienna Conference \"Humanity at the Crossroads: Autonomous Weapons Systems and the Challenge of Regulation\" (Apr 2024)\n\nMorocco supports an international instrument regulating the use of autonomous weapons systems and calls for continued discussion on the subject of LAWS through multilateral fora.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Morocco_National_Statement.pdf"
          },
          {
            "text": "Morocco's Declaration on LAWS at the CCW (Nov 2018)\n\nMorocco advocates for a legally binding instrument to prohibit the development and deployment of all LAWS and advocates for human control to always be present and in compliance with IHL.",
            "url": "https://reachingcriticalwill.org/images/documents/Disarmament-fora/ccw/2018/hcp-meeting/statements/22Nov_Morocco2.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nMorocco voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nMorocco voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Morocco Contribution \"Application of AI in the Military Domain: Opportunities and Challenges (Excluding LAWS) in a Context of International Peace and Security\" (2025) (2025)\n\nThis document explains in detail the military use case opportunities for which AI can be applied, and also acknowledges the challenges that AI can bring when used in the military domain.\n\nThis signals an awareness of the use cases of military AI as well as the ethical challenges that must be considered.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Morocco-EN.pdf"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nMorocco signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "North Korea": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nNorth Korea abstained from voting on this resolution.\n\nThe resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nNorth Korea voted against Draft Resolution L.77 on lethal autonomous weapons systems.\n\nThe resolution signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Netherlands": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Kingdom of the Netherlands Submission in Accordance with Resolution 78/241 on Autonomous Weapons Systems (May 2024)\n\nThe Netherlands states that autonomous weapons systems that cannot be designed, developed, or used in accordance with international law and IHL should be prohibited through a legally binding instrument.\n\nThe document presents the Netherlands' definition of what constitutes an autonomous weapon system and what conditions warrant a prohibition of a certain system.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-Netherlands-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nThe Netherlands voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nThe Netherlands voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Kingdom of the Netherlands National Contribution to the UN Secretary General Report on Resolution 79/239 (Apr 2025)\n\nThe Netherlands recognizes the potential benefits of AI in the military domain, such as better insight, improved connectivity, enhanced civilian protection, and reduced risks in operations.\n\nThe document states the Netherlands' view that human control should be context-dependent, R&D efforts must implement testing, evaluation, verification and validation (TEVV) procedures, and that international governance should be \"flexible, inclusive, and realistic\".",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79_239-Netherlands-EN.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Defence White Paper 2024 (Sep 2024)\n\nSection 3.5 Digital Transformation; sets a goal of harnessing the potential of AI, data analysis, and data use for operational readiness and deployment.\n\nThis signals a data-centric focus on AI applications in the military.",
            "url": "https://english.defensie.nl/downloads/publications/2024/09/05/defence-white-paper-2024"
          },
          {
            "text": "Letter From the Ministers of Foreign Affairs and of Defense (Jun 2023)\n\nThis letter states the Netherlands' intent to \"fund several regional training courses on the military use of AI\".\n\nThe Netherlands holds that autonomous weapons that cannot comply with IHL must be banned through an international legal framework.",
            "url": "https://zoek.officielebekendmakingen.nl/kst-33694-68.html?utm_source=chatgpt.com"
          },
          {
            "text": "Defence White Paper 2022 (Jul 2022)\n\nThis document states the Dutch Army's plan to commit joint investments with commercial partners to develop \"autonomous systems, robots and other forms of advanced combat technology in order to ensure that\u2026automation is optimised\".",
            "url": "https://english.defensie.nl/downloads/publications/2022/07/19/defence-white-paper-2022"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Cabinet's Response to Advisory Report \"Autonomous Weapon Systems: The Importance of Regulation and Investment\" (Jun 2022)\n\nThe document fully adopts the pursuit of a ban on fully autonomous weapon systems with the goal of preserving human judgement when deploying a weapon system.\n\nThe Dutch government's position on meaningful human control \"concerns the human capacity for judgement in the deployment of a weapon system\" and surrounds the ability to assess and apply principles of international law and IHL.",
            "url": "https://www.tweedekamer.nl/kamerstukken/brieven_regering/detail?did=2022D25679&id=2022Z12434&utm"
          }
        ],
        "public_statements": [
          {
            "text": "The Netherlands' Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\nThe Netherlands co-led the resolution (with S. Korea and Singapore) on the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.reaim2024.kr/home/reaimeng/board/bbsDetail.do?encMenuId=4e57325766362f626e5179454e6d6e4d4a4d33507a773d3d&encBbsMngNo=366e794c7a644d756342425668444f393053755142673d3d&encBbsNo=6f784e4542386f7735767465766a6531556f4b6149413d3d&ctlPageNow=1&schKind=bbsTtlCn&schWord=%23this"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nThe Netherlands voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nThe Netherlands signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "Int'l Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Cabinet's Response to Advisory Report \"Autonomous Weapon Systems: The Importance of Regulation and Investment\" (Jun 2022)\n\nThe document states that the Netherlands will make contributions to the NATO Science & Technology Organisation (STO) Joint Work Programme to help develop technologies in the areas of AI and autonomous weapons.\n\nThe Netherlands supports interoperability and standardization particularly in the field of partially autonomous systems.",
            "url": "https://www.tweedekamer.nl/kamerstukken/brieven_regering/detail?did=2022D25679&id=2022Z12434&utm"
          },
          {
            "text": "Adoption of the Budget Statements of the Ministry of Defence for the Year 2022 (Jun 2022)\n\nRecommendation 8 calls for a framework that makes explainable AI the starting point for Dutch policy on the development, acquisition, and use of partially autonomous weapon systems.\n\nThe section recommends a clear accountability of human responsibility throughout the entire decision-making chain.",
            "url": "https://zoek.officielebekendmakingen.nl/kst-35925-X-90.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": []
      }
    },
    "New Zealand": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Autonomous Weapon Systems: New Zealand Submission to the Secretary-General of the UN (May 2024)\n\nNew Zealand supports the creation of a legally binding instrument to regulate autonomous weapon systems (AWS), with a range of controls applied across the spectrum of autonomy. New Zealand also believes that AWS lower the threshold for the use of force and increase the risk for conflict.",
            "url": "chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://www.mfat.govt.nz/assets/Peace-Rights-and-Security/Disarmament/New-Zealand-submission-to-the-UN-Secretary-General-on-autonomous-weapon-systems.pdf"
          },
          {
            "text": "Autonomous Weapon Systems: New Zealand Policy Position and Approach for International Engagement (Nov 2021)\n\nThis document discusses New Zealand's concerns over the ethical and legal concerns amidst the global development of autonomy in weapon systems, and stresses the need to establish international norms around AWS and support steps to ensure safe development of such capabilities.",
            "url": "chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://www.mfat.govt.nz/assets/Peace-Rights-and-Security/Disarmament/Autonomous-Weapons-Systems-Cabinet-paper.pdf"
          },
          {
            "text": "New Zealand Submission on Artificial Intelligence in the Military Domain (Apr 2025)\n\nNew Zealand acknowledges the potential benefits of autonomous weapon systems, but calls for strict adherence to IHL and the development of norms and common understanding of autonomy in weapons.",
            "url": "https://www.mfat.govt.nz/assets/Peace-Rights-and-Security/Disarmament/New-Zealand-Submission-AI-in-the-military-domain-April-2025.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nNew Zealand voted in support of this resolution, which it also co-sponsored. The resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nNew Zealand co-sponsored and voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [
          {
            "text": "2025 Defence Capability Plan (Apr 2025)\n\nThis document is the New Zealand Defence Force (NZDF) plan to develop its capabilities for the future, addressing several autonomous capabilities, including uncrewed autonomous vessels to conduct persistent surveillance and monitoring. While AI is a small focus of this defense budget, New Zealand is actively modernizing capabilities to integrate more advance capabilities.",
            "url": "chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://www.defence.govt.nz/assets/publications/Defence-Capability-Plan-25.pdf"
          }
        ],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nNew Zealand voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      }
    },
    "Norway": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Submission by Norway on Lethal Autonomous Weapons Systems (May 2024)\n\nNorway supports a two-tier approach consisting of a combination of a prohibition on certain autonomous weapons systems and the regulation of the use of other such systems and explicitly supports a legally binding instrument to prohibit certain autonomous weapon systems.\n\nThis document extensively presents what should constitute as \"meaningful human control\" as it pertains to autonomous weapons.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-Norway-EN.pdf"
          },
          {
            "text": "Statement by Norway to the GGE on Emerging Technologies in the Area of LAWS (Aug 2024)\n\nNorway supports a legally binding instrument to clarify the application of IHL to lethal autonomous weapons.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-Group_of_Governmental_Experts_on_Lethal_Autonomous_Weapons_Systems_%282024%29/2024-08-26_Norway_CCW_GGE_LAWS_2nd_session_general_statement.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nNorway supports this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nNorway voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [
          {
            "text": "Award Letter for Defence Equipment 2024 (Jan 2024)\n\nSection 5.2: Strategy for Artificial Intelligence and Innovation; mandates a half year and annual report on developing a follow-up plan for the defense sector in regards to the Strategy for AI in the Defence Sector\n\nThe letter also mandates an action plan for specific areas where AI can be applied.",
            "url": "https://www.regjeringen.no/contentassets/d88b9ee605634445a3165501cc0f8d12/ugradert-~-b23_00676-7-tildelingsbrev-for-forsvaret-2024-214503_10_0.pdf"
          }
        ],
        "policy_documents": [
          {
            "text": "Norway Submission to the UN Secretary General Pursuant to UNGA Resolution 79/239 (Apr 2025)\n\nThis document effectively summarizes the Norwegian Strategy for AI in the Defence Sector (2023) and the key areas and principles in the development of responsible AI in the military domain.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Norway-EN.pdf?utm"
          },
          {
            "text": "Strategy for Artificial Intelligence in the Defence Sector (Oct 2023)\n\nThe strategy highlights key application areas for AI in the military, including: enhanced situational awareness & decision support, cyber defense, logistics, and support activities.\n\nNorway emphasizes the responsible development, acquisition, and use of artificial intelligence.",
            "url": "https://www.regjeringen.no/contentassets/a36197a7d69c45e68186b10117e76b5b/forsvarsdepartementet-kunstig-intelligens.pdf"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Strategy for Artificial Intelligence in the Defence Sector (Oct 2023)\n\nThis strategy contains the government's plan to use AI to promote Norway's security and defense goals.\n\nThe key principles for responsible development and use of AI are: lawfulness, responsibility & accountability, explainability & understandability & traceability, training, reliability & safety & security, and control.",
            "url": "https://www.regjeringen.no/contentassets/a36197a7d69c45e68186b10117e76b5b/forsvarsdepartementet-kunstig-intelligens.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nNorway voted in support of this resoluton, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Pakistan": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Submission by Pakistan at the First Session of the CCW GGE on LAWS (Apr 2018)\n\nPakistan states that LAWS, by nature, are unethical because there is no longer a human in the loop and the decision over life and death is delegated to a machine.\n\nThis submission states the inherent ethical implications of LAWS and the necessity for human control and responsibility at all times for the use of autonomous weapons systems.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-_Group_of_Governmental_Experts_%282018%29/2018_LAWS6b_Pakistan.pdf"
          },
          {
            "text": "Pakistan National Statement at the Vienna Conference \"Humanity at the Crossroads: Autonomous Weapons Systems and the Challenges of Regulation\" (Apr 2024)\n\nPakistan advocates for the establishment of an international legal framework through the CCW that clearly delineates the boundaries for LAWS and supports a two-tier approach: \"outright prohibition of systems that function outside human control and fail to conform to IHL standards,\" and restrictions for other types of weapons.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Pakistan_National_Statement.pdf"
          },
          {
            "text": "Submission of Views by Pakistan to the UN Secretary General Pursuant to Resolution 78/241 \"Lethal Autonomous Weapons Systems\" (May 2024)\n\nThis document offers Pakistan's views regarding the humanitarian, legal, ethical, and security perspectives that must be considered when addressing the issue of LAWS.\n\nPakistan calls for a new international legal instrument to prohibit and restrict LAWS which cannot comply with IHL at all points in the life cycle.\n\nThe document presents Pakistan's opinion on what conditions warrant an absolute prohibition of LAWS and what restrictions should be placed on autonomous weapons that are not prohibited.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Pakistan-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nPakistan voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nPakistan voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nPakistan voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Pakistan Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\nPakistan endorses the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI, and the future governance of AI in the military domain.",
            "url": "https://asianews.network/seoul-summit-charts-framework-on-responsible-ai-military-use/"
          }
        ]
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Submission of Views by Pakistan in Accordance with UNGA Resolution 79/239 \"Artificial Intelligence in the Military Domain and its Implications for International Peace and Security\" (2025) (2025)\n\nThis submission presents Pakistan's views on the role of AI in nuclear weapon decisions, operational risks, technical risks, legal, ethical, and global security risks.\n\nPakistan advocates for normative dialogue across multiple multilateral frameworks to discuss concerns, risk mitigation efforts, and peaceful progress that military AI presents.\n\nPakistan also supports negotiations on a legally binding instrument to prohibit fully autonomous weapons incapable of complying with IHL.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Pakistan-EN.pdf"
          }
        ],
        "public_statements": []
      }
    },
    "Poland": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Republic of Poland Contribution to the GGE on Normative and Operational Framework on Emerging Technologies in the Area of LAWS (Apr 2021)\n\nPoland emphasizes the principles of distinction, proportionality, and precaution in attack in regard to LAWS.\n\nState authorities will keep humans accountable and in control of the use of LAWS regardless of the degree of autonomy.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-Group_of_Governmental_Experts_on_Lethal_Autonomous_Weapons_Systems_%282021%29/GGE_LAWS_-_June_2021_-_Poland_-_written_contribution.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Working Paper to the CCW GGE on LAWS (Mar 2018)\n\nPoland outlines specific examples of weapons systems that would be deemed unlawful under IHL, including those that are indiscriminate and those that disproportionately cause more harm than the intended objective.\n\nHowever, Poland is not averse to the use of lethal autonomous weapons in combat and holds that the context in which LAWS are used is an important consideration.",
            "url": "https://www.reachingcriticalwill.org/images/documents/Disarmament-fora/ccw/2018/gge/documents/GGE.1-WP3.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nPoland abstained from voting on Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nPoland voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Policy for the Development of Artificial Intelligence in Poland From 2020 (Dec 2020)\n\nWhile this policy document does not cover activities in the areas of national security and defence, it \"assumes the cooperation of the civilian sector with the military sector in all areas considered useful for the needs of national defence in accordance with the priorities set out in the National Security Strategy of the Republic of Poland\".\n\nThis signals an open posture to innovation and a desire to take advantage of civilian-military colaboration.",
            "url": "https://wp.oecd.ai/app/uploads/2021/12/Poland_Policy_for_Artificial_Intelligence_Development_in_Poland_from_2020_2020.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Ministry's Artificial Intelligence Strategy Until 2039 (Aug 2024)\n\nThe document is explicit in the future use of AI systems in military operations: autonomous combat systems that can operate without direct human intervention or support human actions, intelligence and reconnaissance analysis, logistics optimization, cyberspace defense, simulation and training, decision support, and training data analysis.\n\nThe Polish Armed Forces is directed to create conditions to ensure accountability of decisions, balance the risks and possible benefits at an acceptable level, and minimize bias and unpredictable behavior of AI systems used.\n\nThe strategy defines human-machine teaming as the default approach to implementing AI in the Ministry of Defense.\n\nThe MOD plans to create defined pathways for AI-trained staff, with specific plans for recruitment and retention, as well as plans to establish a strategy and processes for data utilization and verification.\n\nThe Polish MOD will also implement a force restructuring to include dedicated AI units and centers.",
            "url": "https://www.gov.pl/web/obrona-narodowa/resortowa-strategia-sztucznej-inteligencji-do-roku-2039?utm_source=chatgpt.com"
          },
          {
            "text": "Poland's Contribution to the Reflection on Opportunities and Challenges Posed to International Peace and Security by AI in the Military Domain (Mar 2025)\n\nPoland advocates for AI applications in the military domain to be human-centric, accountable, safe, secure, and trustworthy, and sees compliance with IHL is seen as a \"crucial aspect\".",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_(2025)/79-239-Poland-EN.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Deputy Prime Minister and Minister of National Defense, Secretary of State Briefing on the Implementation of AI in the Polish Armed Forces (Mar 2025)\n\nThe ministers announce the establishment of an Artificial Intelligence Implementation Center within the Cyberspace Defense Forces Component Command.\n\nThe briefing covers the goals of scaling AI rapidly and delivering timely AI projects \"to ensure strategic advantage\".\n\nOperational activities expected to implement AI are: cyber defense support, intelligence and reconnaissance analysis, modernizing autonomous combat systems, decision-making support, and logistics optimization.",
            "url": "https://www.wojsko-polskie.pl/articles/tym-zyjemy-v/2025-03-045-nowe-kompetencje-i-mozliwosci-dla-wojsk-obrony-cyberprzestrzeni/?utm_source=chatgpt.com"
          },
          {
            "text": "President Statement at UN Security Council Debate on AI (Sep 2025)\n\nPresident Karol Nawrocki supports the development of AI in the security and defense sectors that is \"based on transparent principles, consistent with human ethics and international regulations\".",
            "url": "https://www.prezydent.pl/aktualnosci/wizyty-zagraniczne/debata-rady-bezpieczenstwa-onz-ws-sztucznej-inteligencji,107789"
          },
          {
            "text": "Drone Revolution Conference with Secretary of State of the Ministry of National Defense (Jul 2025)\n\nSecretary Cezary Tomczyk announced the signing of agreements to \"develop technical solutions, tactics, and procedures for the use of drones for the Polish Army\".\n\nThe announcement includes the involvement of the Cyberspace Defense Forces Component Command in ensuring security measures for UAV control software and the implementation of AI.",
            "url": "https://www.swiatdronow.pl/cezary-tomczyk-mon-dzis-zaczyna-sie-rewolucja-dronowa-w-polskich-silach-zbrojnych-konferencja-22-07-2025-r?utm_source=chatgpt.com"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nPoland voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nPoland signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "Russia": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Document of the Russian Federation Pursuant to UNGA Resolution 78/241 \"Lethal Autonomous Weapons Systems\"  (May 2024)\n\nThe document states that Russia does not support a ban on the development or use of LAWS.\n\nRussia provides a suggestion for the requirements for a working definition of LAWS and states that existing highly automated military systems should not be subject to immediate restrictions and bans, and LAWS should not be defined purely through functions alone.\n\nLAWS should not be indiscriminate nor disproportionate and should comply with the \"principle of proportionality between military necessity and damage caused,\" and Russia emphasizes that human control over the operation of LAWS is an important constrainer.\n\nRussia outlines various means of control and methods to minimize risks with regard to LAWS.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Russian-Federation-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Russian Statement at the CCW GGE on LAWS (2021) (2021)\n\nRussia states that a ban or limitation on the possibility of developing LAWS could have a negative influence on both the development of high technology in the civilian sphere and on the achievement of the aims of societal security.",
            "url": "https://conf.unog.ch/digitalrecordings/en/clients/61.0500/sessions/A1ACCA66-1B3F-4FC3-BC64-3915EEACA9EF"
          },
          {
            "text": "Russian Statement at the Sixth Review Conference of the CCW (Dec 2021)\n\nRussia states that it is \"against the elaboration of any legally binding instrument\" on autonomous weapons systems, as well as being against \"a position of a moratorium on the development and use of such systems, and as well as the technologies used for making these systems\".",
            "url": "https://conf.unog.ch/digitalrecordings/en/clients/61.0500/sessions/AE782C82-C5CF-4D53-AC4F-A3D162685B62"
          },
          {
            "text": "Russia's Vote on UNGA Resolution A/RES/78/241 \"Lethal Autonomous Weapons Systems\" (Dec 2023)\n\nRussia voted against this resolution.\n\nThe resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.\n\nExplaining it\u2019s vote, Russia said that it \"opposes the development  of any internationally legally binding instrument with regard to lethal autonomous weapons systems, and the introduction of a moratorium on development and the use of systems and the technology used to create them\".",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [
          {
            "text": "Concept of Activities of the Armed Forces in Development and Use of Weapons Systems with AI (Jul 2022)\n\nDISCLAIMER: framework is internal to the Russian MOD and is not publicly accessible.\n\nThe document outlines how the Russian Armed Forces will apply weapons systems and military equipment with AI technologies. Secondary sources mention review systems, human control, and AI lifecycle management.\n\nThe Concept reaffirms that IHL fully apply to all weapons and it presents a roadmap for AI integration into the Russian Armed Forces.",
            "url": "https://www.cnas.org/publications/reports/the-role-of-ai-in-russias-confrontation-with-the-west"
          }
        ],
        "policy_documents": [
          {
            "text": "National Strategy for AI Development Through 2030, Presidential Decree No. 490 (Oct 2019)\n\nArticle 6 mandates that the President's Security Council, the Ministry of Defense, and other federal bodies are responsible for implementing, monitoring, and reporting on AI applications in defense and security.",
            "url": "https://cset.georgetown.edu/wp-content/uploads/Decree-of-the-President-of-the-Russian-Federation-on-the-Development-of-Artificial-Intelligence-in-the-Russian-Federation-.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Presidential Address to the Federal Assembly (Mar 2018)\n\nPresident Vladimir Putin states that Russia has developed unmanned submersible vehicles that are both conventional- and nuclear-capable, while also stating that Russia must eliminate all barriers for development and wide use robotic equipment, artificial intelligence, unmanned vehicles, among other capabilities.",
            "url": "http://en.kremlin.ru/events/president/news/56957"
          },
          {
            "text": "Defense Minister Statement at New Knowledge Lecture (May 2021)\n\nDefense Minister Sergei Shoigu states that Russia has begun to produce \"robots that can be really shown in science-fiction films as they are capable of fighting on their own,\" singaling Russia's commitment to autonomy in weapons systems.",
            "url": "https://tass.com/science/1292483"
          },
          {
            "text": "Statement by Deputy Head of the Delegation of the Russian Federation at the Thematic Discussion on Conventional Arms in the First Committee of the 77th Session of the UN General Assembly (Oct 2022)\n\nThis statement stresses that measures to control LAWS and military AI are sufficient under international humanitarian law.\n\nThe Deputy Head also warns against rapid bans or restrictions on AI and autonomy to prevent undermining deterrence stability and broader arms control architecture.",
            "url": "https://reachingcriticalwill.org/images/documents/Disarmament-fora/1com/1com22/statements/20Oct_Russia.pdf"
          },
          {
            "text": "Presidential Speech at the Meeting of the Board of the Ministry of Defense (Dec 2022)\n\nPresident Vladimir Putin calls for the integration of AI technology at all levels of decision-making in the armed forces.",
            "url": "http://kremlin.ru/events/president/news/70159"
          },
          {
            "text": "Deputy Prime Minister Statement on Military AI Developments (Aug 2024)\n\nRussian Deputy Prime Minister Chernyshenko states that a specialized department for the development of AI is now in place within the Russian Ministry of Defense.",
            "url": "https://www.defensenews.com/global/europe/2024/08/16/russian-defense-plan-kicks-off-separate-ai-development-push/"
          },
          {
            "text": "Russia's Vote on UNGA Resolution A/RES/79/239 \"Artificial Intelligence in the Military Domain and Its Implications for International Peace and Security (Dec 2024)\n\nRussia voted against this resolution.\n\nThe resolution calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "Defense Minister Announcement at Russian MOD Collegium (Aug 2025)\n\nDefense Minister Belousov outlines 10 priority objectives for the Defense Ministry, the second being the rearmament of strategic nuclear forces, air defense, EW, signals, and unmanned and robotic artificial intelligence systems by 2036.",
            "url": "https://understandingwar.org/research/russia-ukraine/russian-force-generation-and-technological-adaptations-update-september-24-2025/"
          },
          {
            "text": "Statement by Deputy Head of the Delegation of the Russian Federation at the Thematic Debate on Cluster V \"Other disarmament measures and international security\" in the First Committee of the 80th Session of the UNGA (Oct 2025)\n\nRussia sees a clear link between international security and disarmament and warns against the discussion of these topics (development of definitions, standards, or applications) outside of UN fora.\n\nSpecific forms and methods of human control over AI-enabled weapons systems and military equipment should be left to individual states, and \"direct control should not be the only option\".",
            "url": "https://russiaun.ru/en/news/427102025"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "National Strategy for AI Development Through 2030, Presidential Decree No. 490 (Oct 2019)\n\nThe strategy recognizes autonomy as a pillar of defense modernization and mandates sovereign, independent development and priority acquisition of autonomous military systems.",
            "url": "https://cset.georgetown.edu/wp-content/uploads/Decree-of-the-President-of-the-Russian-Federation-on-the-Development-of-Artificial-Intelligence-in-the-Russian-Federation-.pdf"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "National Strategy for AI Development Through 2030, Presidential Decree No. 490 (Oct 2019)\n\nArticle 2 states that the realization of AI must account for the moral, ethical, and legal norms, including the traditions and values of the people of the Russian Federation.",
            "url": "https://cset.georgetown.edu/wp-content/uploads/Decree-of-the-President-of-the-Russian-Federation-on-the-Development-of-Artificial-Intelligence-in-the-Russian-Federation-.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Statement by the Representative of the Delegation of the Russian Federation on Draft Resolution \"Artificial Intelligence in the Military Domain and Its Implications for International Peace and Security\" L.43 at the UNGA (Nov 2024)\n\nThis statement begins by outlining Russia's vote against the draft resolution, emphasizing the resolution's premature approach and reiterating the lack of necessity for new instruments and bans on military AI.\n\nRussia criticizes the discussion outside of UN and CCW avenues on topics relating to military AI, its development, safeguards, and applications.",
            "url": "https://mid.ru/en/foreign_policy/news/1979934/"
          }
        ]
      }
    },
    "South Africa": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "South Africa Statement to the Sixth Review Conference at the CCW (Dec 2021)\n\nSouth Africa supports the creation of a new legally binding instrument to regulate LAWS.",
            "url": "https://documents.unoda.org/wp-content/uploads/2022/02/South-Africa-CCW-RevCon-General-Statement-.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nSouth Africa voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nSouth Africa voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "South Korea": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Republic of Korea National Statement at the Vienna Conference \"Humanity at the Crossroads: Lethal Autonomous Weapon Systems\" (Apr 2024)\n\nThis statement expresses the ROK's views on the approach to addressing concerns on LAWS. ROK recommends the \"three boxes\" approach, which centers on how existing IHL applies, how practical measures can be implemented to ensure IHL compliance, and whether new laws would be needed.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Republic_of_Korea_National_Statement.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "The Republic of Korea\u2019s Contribution to the Resolution on \u201cLethal Autonomous Weapons Systems\u201d A/RES/78/241 (May 2024)\n\nThis position paper defines LAWS as systems that, once activated, can identify, select and engage targets without further human intervention. South Korea reaffirms CCW GGE as \u201ccentral and unique forum\u201d and endorses a two-tier approach: (1) prohibition of LAWS inherently incompatible with IHL, and (2) regulation and risk-mitigation measures for other LAWS.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-ROK-EN.pdf"
          },
          {
            "text": "Foreign Minister Opening Remark at REAIM Summit 2024 in Seoul (Sep 2024)\n\nForeign Minister Cho Tae-yul states that discussions at the summit would cover legal reviews to ensure compliance with IHL and mechanisms to prevent autonomous weapons from making life-and-death decisions without appropriate human oversight.",
            "url": "https://www.reuters.com/world/asia-pacific/south-korea-summit-target-blueprint-using-ai-military-2024-09-09/?utm_source=chatgpt.com"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "TIGER 4.0 Concept (Sep 2021)\n\n(DISCLAIMER - extremely limited public information)\n\nThe modernization plan includes a focus area on AI-based decision support systems (DSS) and the development of autonomous \"dronebot combat systems.\" It also emphasizes integration of AI into man-machine teams.",
            "url": "https://www.koreaherald.com/article/2694958"
          },
          {
            "text": "Defense Innovation 4.0 (Mar 2023)\n\n(DISCLAIMER - limited public information)\n\nThis strategy covers a phased approach to AI deployment with risk management protocols, safety evaluations, and performance standards for AI systems.\n\nThe initiative plans to integrate AI into surveillance, combat, command and control (C2) systems, manned-unmanned combat systems, and Joint All-Domain C2 Systems.\n\nMilitary pilots are designated to enhance human expertise in defense AI application in an effort to advance digital proficiency within the Ministry of National Defense.",
            "url": "https://link.springer.com/chapter/10.1007/978-3-031-58649-1_23?utm_source=chatgpt.com"
          },
          {
            "text": "Minister of Science and Minister of Defense Memorandum of Understanding on Cooperation in Science, Technology, and Defense (Apr 2024)\n\nThis statement announces the plan to increase civilian-military cooperation in the technology, science, and defense sectors to create an elite and advanced military.",
            "url": "https://doc.msit.go.kr/SynapDocViewServer/viewer/doc.html?key=045a6f22883a49c296b601f4a261cf23&convType=html&convLocale=ko_KR&contextPath=/SynapDocViewServer/"
          }
        ],
        "public_statements": [
          {
            "text": "Establishment of the Defense AI Center (Apr 2024)\n\nThe MND established this center as part of the Defense Innovation 4.0 plan to oversee AI development in the defense sector, which employs 110 full-time staff and will focus on developing technologies in AI-based manned-unmanned teaming systems and battlefield situational awareness.",
            "url": "https://www.koreaherald.com/article/3360368"
          },
          {
            "text": "Vice Minister of National Defense Meeting (Aug 2025)\n\nDefense Vice Minister Lee Do-hee chaired a meeting where the ministry discussed expanding AI use to aid decision-making in combat and ministerial policy decisions.",
            "url": "https://en.yna.co.kr/view/AEN20250829006300315"
          },
          {
            "text": "Minister of National Defense Statement at the 2025 Defense AI Implementation Review Meeting (Nov 2025)\n\nMinister Ahn Gyu-baek states that the Ministry of National Defense (MND) plans to use AI to increase administrative efficiency, build an \"AI policy aide\" that supports the Minister's policy decisions, and an \"AI combat aide\" that supports commanders' decisions on the battlefield.",
            "url": "https://biz.chosun.com/en/en-policy/2025/11/18/ZD524MVDGJF65MTFZRYFBO6D3M/"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "South Korea's Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\nSouth Korea co-led the resolution (with the Netherlands and Singapore) on the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.reaim2024.kr/home/reaimeng/board/bbsDetail.do?encMenuId=4e57325766362f626e5179454e6d6e4d4a4d33507a773d3d&encBbsMngNo=366e794c7a644d756342425668444f393053755142673d3d&encBbsNo=6f784e4542386f7735767465766a6531556f4b6149413d3d&ctlPageNow=1&schKind=bbsTtlCn&schWord=%23this"
          }
        ]
      },
      "Int'l Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "South Korea-Japan Defense Upgrade Cooperation (Dec 2025)\n\nThe defense ministers of Japan and South Korea agreed to upgrade defense cooperation in incorporating artificial intelligence and unmanned weapon systems.",
            "url": "https://www.reuters.com/world/asia-pacific/south-korea-japan-defence-ministers-agree-upgrade-cooperation-2026-01-30/"
          }
        ]
      }
    },
    "Singapore": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Singapore's National Submission on the Topic of LAWS (May 2024)\n\nSingapore supports a two-tier approach to regulating laws, which would prohibit LAWS that are incapable of conforming to IHL and regulates other cases of autonomous weapons systems.\n\nSingapore also supports a \"concept of limits\" to clarify the scope of LAWS and to ensure that LAWS can be used in accordance with IHL.\n\nThe document reiterates Singapore's commitment to upholding the following principles for AI in the military realm: Responsible, Reliable, Robust, and Safe.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Singapore-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nSingapore voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nSingapore voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Singapore's National Submission on the Topic of Artificial Intelligence in the Military Domain and its Implications for International Peace and Security (Apr 2025)\n\nSingapore acknowledges the potential benefits of AI in the military domain, advocates for the responsible and safe use of AI, reiterating the national principles of responsibility reliability, robustness, and safety.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Singapore-en.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Creation of Digital Intelligence Service (2022) (2022)\n\nThe Digital Intelligence Service (DIS) is responsible for optimizing the application of new technologies, particularly AI, across the armed forces.",
            "url": "https://www.mindef.gov.sg/news-and-events/latest-releases/15feb25_speech2/?utm_source=chatgpt.com"
          },
          {
            "text": "Singapore Armed Forces (SAF) AI Centre Establishment (2024) (2024)\n\nThe SAF established the AI Centre to accelerate AI adoption, grow expertise, and operationalize AI capabilities.\n\nUse case examples include natural langauge processing, computer vision, generative AI, and AI for cybersecurity.",
            "url": "https://www.linkedin.com/posts/dis-safc4dc_guardiansofnewfrontier-thesingaporedis-activity-7311240070479446016-JGwu/"
          },
          {
            "text": "Singapore Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\nSingapore endorses the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.\n\nSingapore co-hosted the REAIM summit in Seoul, South Korea alongside South Korea, the Netherlands, Kenya, and the UK.",
            "url": "https://www.mindef.gov.sg/news-and-events/latest-releases/10sep24_nr/"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Deputy Prime Minister at Singapore Defence Technology Summit 2025 (Mar 2025)\n\nDeputy PM Swee Keat states that Singapore has committed funds to \"develop innovative AI solutions in self-driving vehicles\u2026for military and commecial applications\".\n\nThe Defense Science and Technology Agency (DSTA) is working with technology start-up companies to enhance the defense ecosystem by way of autonomous vehicles and underwater autonomous capabilities.",
            "url": "https://www.pmo.gov.sg/newsroom/dpm-heng-swee-keat-at-the-singapore-defence-technology-summit-2025/?utm_source=chatgpt.com"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Statement of Intent on Data Analytics and Artificial Intelligence (Jul 2024)\n\nThe US DoD's CDAO and Singapore's deputy secretary for technology signed a statement of intent to strengthen interoperability and advance cutting-edge technology in the realm of data and AI.",
            "url": "https://www.war.gov/News/News-Stories/Article/Article/3839335/us-singapore-cooperate-on-data-analytics-artificial-intelligence/"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nSingapore signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nSingapore voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          },
          {
            "text": "Statement by Minister for Foreign Affairs at the UNSC Open Debate (Sep 2025)\n\nMinister Vivian Balakrishan states that Singapore supports multilateral frameworks that implement guardrails for AI in military applications.\n\nThe Minister reiterates Singapore's adherence to its national principles for AI in the military domain, which which are responsibility, reliability, robustness, and safety.",
            "url": "https://www.mfa.gov.sg/newsroom/press-statements-transcripts-and-photos/unsc-open-debate-on-ai-and-international-peace-and-security/"
          }
        ]
      }
    },
    "Spain": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Spain's Submission to the UNGA Resolution 78/241 on Lethal Autonomous Weapons Systems (May 2024)\n\nSpain supports a two-tier approach to regulating LAWS, combining a prohibition of autonomous weapons that cannot be developed or used in compliance with IHL and a regulation of all other autonomous weapons.\n\nThe document reiterates Spain's commitment to clear human oversight and accountability in regards to artificial intelligence in the military.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Spain-SP.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nSpain voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nSpain voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Ministry of Defense \"Military Uses of Artificial Intelligence, Automation, and Robotics\" (Jul 2020)\n\nThis document comprises military applicatiuons of AI, automation, and robotics, including operational uses, risks, and ethical/legal challenges.\n\nChapter 1 covers use cases of AI in the Spanish military.\n\nChapter 2 outlines data integration to obtain a common picture at the operational and strategic level, including applications of machine learning techniques and deep learning methodologies in various conditions.\n\nChapter 3 addresses threats of AI in misinformation and disinformation.\n\nChapter 4 outlines various use cases for AI applications in cybersecurity and defense.",
            "url": "https://emad.defensa.gob.es/Galerias/CCDC/files/USOS_MILITARES_DE_LA_INTELIGENCIA_ARTIFICIALx_LA_AUTOMATIZACION_Y_LA_ROBOTICA_xIAAxRx.-_VV.AA.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Official Bulletin of the Ministry of Defense Number 131 (Jul 2023)\n\nThis document frames AI as one of the main catalysts for digital transformation and resource optimization within the Spanish Ministry of Defense.\n\nSpain commits to using AI to augment and not replace humans, and commits to comply with the principles of lawfulness, fairness, transparency, integrity and confidentiality, and proactive accountability.\n\nThe document outlines the strategic and operational visions for the implementation and integration of AI into the Ministry of Defense.",
            "url": "https://elconfidencialdigital.opennemas.com/media/elconfidencialdigital/files/2023/07/12/estrategia%20ia.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Joint Development of the Future Combat Air System (FCAS) (Sep 2025)\n\nSpain is jointly developing a sixth generation aircraft with France and Germany with an interconnected defense ecosystem that is expected to heavily incorporate AI capabilities.",
            "url": "https://as.com/actualidad/politica/espana-relanza-su-estrategia-militar-de-defensa-asi-sera-el-superavion-de-combate-europeo-con-fecha-limite-2040-n/?utm_source=chatgpt.com"
          },
          {
            "text": "Spain's Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\nSpain endorsed the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.reaim2024.kr/home/reaimeng/board/bbsDetail.do?encMenuId=4e57325766362f626e5179454e6d6e4d4a4d33507a773d3d&encBbsMngNo=366e794c7a644d756342425668444f393053755142673d3d&encBbsNo=6f784e4542386f7735767465766a6531556f4b6149413d3d&ctlPageNow=1&schKind=bbsTtlCn&schWord=%23this"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Ministry of Defense Statement on Human Control (Jun 2023)\n\nThe Spanish Ministry of Defense states that the military use of artificial intelligence will always be under human control.\n\nThe Ministry states that AI will be extensively integrated into military activities, but states that the development of AI \"must allow for clear supervision in order to guarantee due accountabilityand the attribution of responsibilities\".\n\nThe Ministry also designates the following authorities as responsible for resolving ethical matters: Chief of Defence Staff for applications in the field of military operations; head of the State Secretariat of the National Intelligence Centre for intelligence matters; and the head of the State Secretariat for Defence for all other matters.",
            "url": "https://www.elconfidencialdigital.com/articulo/defensa/defensa-garantiza-que-uso-militar-inteligencia-artificial-tendra-siempre-control-humano/20230712171647607253.html?utm_source=chatgpt.com"
          },
          {
            "text": "Spain's Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\nSpain endorsed the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.reaim2024.kr/home/reaimeng/board/bbsDetail.do?encMenuId=4e57325766362f626e5179454e6d6e4d4a4d33507a773d3d&encBbsMngNo=366e794c7a644d756342425668444f393053755142673d3d&encBbsNo=6f784e4542386f7735767465766a6531556f4b6149413d3d&ctlPageNow=1&schKind=bbsTtlCn&schWord=%23this"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nSpain voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "Int'l Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nSpain signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "Sweden": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Swedish Input to the Report of the UN Secretary General on Resolution 78/241 on LAWS (May 2024)\n\nSweden supports the two-tier approach to regulating LAWS; prohibiting those systems which cannot comply with international law and IHL and regulating other systems which contain some form of autonomous function.\n\nThe document states that human responsibility for decisions must be retained and that preserving meaningful human control over the use of force is a key objective, included throughout the entire lifecycle of a weapon system.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-Sweden-EN.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nSweden voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nSweden voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Speech by Minister for Defence at Annual National Conference (Jan 2024)\n\nMinister for Defence Pal Jonson states that Sweden must strengthen its defense capabilities, including through the use of unmanned systems in all areas and \"AI technology for planning and decision support\".",
            "url": "https://www.government.se/speeches/2024/01/speech-by-minister-for-defence-pal-jonson-at-folk-och-forsvars-annual-national-conference-in-salen-on-the-8th-of-january-2024/?utm"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\nSweden endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\nThe declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nSweden signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "Sweden's Stance in the Responsible Artificial Intelligence in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\nSweden supports the 'blueprint' for ethical and human-centric use of AI in the military, which emphasizes the importance of compliance with international law, human oversight, and risk assessment.",
            "url": "https://www.asiapacific.ca/publication/us-china-competition-looms-large-seoul-summit-use-ai?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "Turkey": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by Turkiye at the Thematic Discussion on \"Conventional Weapons\" (Oct 2022)\n\nTurkiye states that the development and use of autonomous weapons which do not have meaningful human control are \"undesirable\" and do not align with IHL.\n\nThe position is that humans must be involved in the decision loop and bear responsibility in the cases of life and death.",
            "url": "https://reachingcriticalwill.org/images/documents/Disarmament-fora/1com/1com22/statements/21Oct_Turkiye.pdf"
          },
          {
            "text": "Statement by Turkiye at the GGE Meeting on LAWS (Mar 2024)\n\nDeveloping a new legally binding instrument that prohibits LAWS would not serve a purpose in the absence of a universally agreed definition.\n\nSystems that perform all steps of a targeting cycle outside human control or supervision are \"not technically feasible, militarily desirable, or legally permissible in terms of IHL\".",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-Group_of_Governmental_Experts_on_Lethal_Autonomous_Weapons_Systems_(2024)/T%C3%BCrkiye-CCW_LAWS_GGE-04032024.pdf"
          },
          {
            "text": "Turkiye National Statement at the Vienna Conference \"Humanity at the Crossroads: Autonomous Weapons Systems\" (Apr 2024)\n\nTurkiye supports the progress and access to civilian research development due to the dual-use nature of emerging technologies such as LAWS.\n\nTurkiye holds that all parties to armed conflict must act in accordance with the basic principles of IHL.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Tuerkiye_National_Statement.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nTurkiye abstained from the vote on this resolution.\n\nThe resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nTurkiye abstained from voting on Draft Resolution L.77 on lethal autonomous weapons systems.\n\nThe resolution signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "National Artificial Intelligence Strategy 2021-2025 (Aug 2021)\n\nWhile not a military-specific strategy, this document contains goals of creating \"a competency repository in certain software development areas that are critical for defense needs, especially AI\".\n\nThe strategy announces areas of R&D projects that use AI technologies for defense and security, including: classification and identification of surface targets detected by radar, autonomous reconnaissance with collaborative robots, AI-assisted fire control and autonomous driving for land vehicles, etc.",
            "url": "https://cdn-assets.inwink.com/b0269dea-af7b-4460-b29a-c40b9941c4c5/d32fa511-ac43-49ef-b5b2-d90034d2af03"
          },
          {
            "text": "Defense Industry Sectoral Strategy 2023-2027 SSB (Jan 2024)\n\nThis strategy document sets goals for defence industry R&D capability, including increasing autonomy levels of UAV systems through AI applications, enabling swarm and manned-unmanned teaming in drones, and bolstering naval unmanned systems.\n\nAI is framed as a core enabling technology in ISR and targeting and outlines the Turkish military's plans to reorganize its talent and focus areas to better implement and deploy AI.",
            "url": "https://www.scribd.com/document/805331508/F-20231106165507582242?language_settings_changed=English&utm_source=chatgpt.com"
          },
          {
            "text": "2024-2028 Defence Industry Sectoral Strategy SSB Update (2025) (2025)\n\nThis document builds on the 2023-2027 version, but expands on the activities the military will undertake.\n\nThis document outlines goals to maintain a shared infrastructure that the defence, academic, and private sectors can all use.\n\nThe strategy places emphasis on developing AI talent and working with the academic sector to develop capabilities within the defense focus areas.",
            "url": "https://www.manisatso.org.tr/tr/haber/6345/2024_2028_savunma_sanayi_sektorel_strateji_dokumani.html?utm"
          },
          {
            "text": "Future of Artificial Intelligence Technologies Report (Oct 2025)\n\nThis report contains a multi-stakeholder approach and an R&D technology roadmap for near and long-term goals.\n\nThe document assess the current level of AI integration, challenges encountered, goals achieved, and future growth areas that have been identified which inform the roadmap.\n\nThere are five main focus groups categorized within this report: AI technologies with image, video, and 3D data; voice/speech and text data; time series and tabular data; hybrid AI; and regulations and data policies for military AI applications.",
            "url": "https://envantermedya.com/ssb-gelecegin-yapay-zeka-teknolojileri-raporunu-yayinladi/?utm_source=chatgpt.com"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nTurkiye signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      }
    },
    "UAE": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nThe UAE abstained from voting on this resolution.\n\nThe resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nThe UAE voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "UAE Export Control Regime (2020) (2020)\n\nIn July 2020, the updated Control List, which prohibits the delivery, transfer, publication, leaking, or sharing of information, included equipment facilitating autonomous capabilities.",
            "url": "https://www.morganlewis.com/pubs/2025/08/overview-of-the-uaes-export-control-regime"
          }
        ],
        "public_statements": [
          {
            "text": "UAE- USA Joint Venture for Autonomous Defense Systems (Nov 2025)\n\nUAE-based company EDGE and US-based Anduril announced a government-backed venture to co-develop and locally produce a hover-to-cruise Autonomous Air Vehicle (AAV).\n\nThe UAE has finalized the acquisition of 50 \"Omen\" systems, which combines the \"endurance, payload, and autonomy of larger systems with the flexibility of a compact, runway-independent airframe\".\n\nThis joint venture signals the UAE's goal of domestically produced autonomous dual-use aircraft, to include R&D and simulation centers for future expansion.",
            "url": "https://uasweekly.com/2025/11/13/edge-anduril-form-uae-us-jv-for-autonomous-defense-systems/"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "UK": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Ambitious, Safe, Responsible: Our Approach to the Delivery of AI-Enabled Capability in Defence (Jun 2022)\n\nAnnex C: The British government defines fully lethal autonomous weapons systems as those that \u201cidentify, select, and engage targets without context-appropriate human involvement.\u201d It deems such systems unacceptable and has stated that the UK will not develop them. For other autonomous systems, the UK will establish clear human responsibility and accountability.",
            "url": "https://assets.publishing.service.gov.uk/media/62a9b1d1e90e07039e31b8cb/20220614-Ambitious_Safe_and_Responsible.pdf"
          },
          {
            "text": "United Kingdom National Statement at the Vienna Conference on Lethal Autonomous Weapon Systems (Apr 2024)\n\nThis statement expresses the UK's declaration that it will not develop fully autonomous weapons and that IHL applis to all technology that is AI-enabled.\n\nHuman judgement is always necessary throughout the development and use of weapon systems with autonomous functions.\n\nHowever, the UK holds that IHL already constrains states in respect to their development ad procurement of weapons, and new legally binding rules are unnecessary beyond the application of IHL.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Republic_of_Korea_National_Statement.pdf"
          },
          {
            "text": "UK Submission Pursuant to UNGA Resolution A/RES/78/241 on Lethal Autonomous Weapons Systems (May 2024)\n\nThe UK states that it does not possess fully autonomous weapon systems and has no intention of developing them, and that no states should develop or deploy such weapons.\n\nThe document reaffirms the necessity of the human to retain command and control over autonomous systems and states that accountability cannot be transferred to a machine.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-UK-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Ministry of Defence Letter to the UN on Lethal Autonomous Weapons Systems (Jan 2021)\n\nThis letter in response to international discussions on LAWS states that \"the operation of [UK] weapon sysems will always be under human control and no UK weapons ystems will be capable of attacking targets without [it]\".\n\nThe UK affirms that the GGE remains the right forum to discuss and progress the work on LAWS and states that a \"legally binding instrument which hampers the legitimate development and use of such technologies would be counterproductive\"..",
            "url": "https://article36.org/wp-content/uploads/2021/01/UK-govt-reply-2020-LAWS.pdf"
          },
          {
            "text": "UK Written Contribution to the CCW on LAWS (Jun 2021)\n\nThis document presents the UK's views on the legal framework that should guide all aspects of LAWS, to include compliance with IHL and legal reviews of new weapons.\n\nThe UK holds that human responsibility and accountability for military outcomes is fundamental, and asserts that human control should be present across all stages of the AI life cycle.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-Group_of_Governmental_Experts_on_Lethal_Autonomous_Weapons_Systems_(2021)/GGE_LAWS_-_June_2021_-_United_Kingdom_-_written_contribution.pdf"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nThe UK voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nThe UK voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\nThe UK endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\nThe declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Joint Concept Note (JCN) 1/18  \"Human-Machine Teaming\" (May 2018)\n\nThis concept note by the British MOD introduces the idea that trust in machines that have autonomous functions is necessary.\n\nThe document frames human-machine teaming as central to future UK defense, with humans retaining judgment over critical decisions.",
            "url": "https://assets.publishing.service.gov.uk/media/5b02f398e5274a0d7fa9a7c0/20180517-concepts_uk_human_machine_teaming_jcn_1_18.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Defence Artificial Intelligence Strategy (Jun 2022)\n\nOverview Section; defines roles for the MOD Head Office, Business Units and Functional Leads, and Strategic Command.\n\nSection 1.3: establishes Human-Machine teaming as the default approach to AI adoption, and mandates appropriate human involvement, supervision, or operational control parameters.\n\nSection 2: Transform into an AI Ready Organisation; covers workforce changes within the UK MOD, to include an AI skills framework, the establishment of a Head of AI Profession, creates AI career paths, and mandates AI leadership training.\n\nSection 3.3: Promoting Pace, Innovation, and Experimentation; mandates a \"systematic roll-out\" of mature data science and Machine Learning (ML) techniques. It also presents priority Capability Challenges which direct the  focus of R&D efforts.\n\nSection 6.2: Leadership and Governance; outlines responsibilities for the Defence AI Unit (DAU), Defence AI Centre (DAIC), and describes a decentralized governance model with no single owner of AI within the MOD.",
            "url": "https://assets.publishing.service.gov.uk/media/62a7543ee90e070396c9f7d2/Defence_Artificial_Intelligence_Strategy.pdf"
          },
          {
            "text": "British Army Approach to Artificial Intelligence (Dec 2023)\n\nThis strategy document focuses on AI for decision advantage, emphasizing decision support rather than autonomous decision-making.\n\nThe Army AI Centre (AAIC) is established, which acts as the primary point of contact with DAIC to ensure compliance with defence AI regulation and best practice.",
            "url": "https://www.army.mod.uk/media/24745/20231001-british_army_approach_to_artificial_intelligence.pdf"
          },
          {
            "text": "Defence AI Centre (DAIC) Defence AI Playbook (Jan 2024)\n\nThis document was released to accelerate the adoption of AI within the British MOD and drive the transformation of Defence into an AI-ready organization.\n\nThe playbook covers various use case studies and solutions for the MOD to integrate, apply, and enhance AI-enabled capabilities for the given challenges in the battlespace.",
            "url": "https://assets.publishing.service.gov.uk/media/65bb75fa21f73f0014e0ba51/Defence_AI_Playbook.pdf"
          },
          {
            "text": "Government Response to House of Common Second Report of Session 2024-2025 Developing AI Capacity and Expertise in UK Defence (Apr 2025)\n\nThis document responds to the recommendations made by the House of Commons on developing AI capacity and expertise within the MOD.\n\nRecommendation 1 addresses the need for benchmarks to track and compare AI sector strength.\n\nRecommendation 5 provides a summary of the actions the MOD has taken to advance the UK to become an AI-ready nation, and it outlines the duties of the newly created Responsible AI Senior Officer in accordance with JSP 936 \"Dependable Artificial Intelligence in Defence\".\n\nRecommendation 7 commits the MOD to developing  an interoperable AI framework across the MOD.\n\nRecommendation 13 commits the MOD to a mapping exercise to identify gaps, duplication, and areas that need further investment of development within the defense AI infrastructure.\n\nRecommendation 15 presents updated Strategic Outcomes in the Digital Strategy that guide the development and deployment of defense AI.\n\nRecommendations 17-19 address the need for the MOD to investigate avenues for workforce enhancement, training, and retention as it pertains to AI in the MOD.",
            "url": "https://www.documentcloud.org/documents/25973602-government-response-developing-ai-capacity-and-expertise-in-uk-defence/?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Statement on Defence AI Strategy Launch (Jun 2022)\n\nThis statement by Minister of State for Defence Procurement Jeremy Quin announced the launch of the Defence AI Strategy and outlined the goals for the British government as it relates to defense AI and the adherence to ethical standards.",
            "url": "https://questions-statements.parliament.uk/written-statements/detail/2022-06-15/hcws101"
          },
          {
            "text": "The UK's Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\nThe UK supports the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.carnegiecouncil.org/media/article/principles-action-military-ai-governance"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nThe UK voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [
          {
            "text": "JSP 936 V1.1 Dependable Artificial Intelligence (AI) in Defence (Nov 2024)\n\nSection 8: Suppliers; details requirements for external AI acquisition, including competence demonstrations and intellectual property considerations that must be taken into account for authorized procurement.",
            "url": "https://assets.publishing.service.gov.uk/media/6735fc89f6920bfb5abc7b62/JSP936_Part1.pdf"
          }
        ],
        "policy_documents": [
          {
            "text": "Defence Artificial Intelligence Strategy (Jun 2022)\n\nSection 4.4.1: Information Age Acquisition and Procurement Policy; outlines plans to streamline 'small' value digital purchases and enable agile methodologies for end-to-end acquisition of systems.\n\nThe MOD plans to work with both the Defence and National Security AI Network and the Defence Suppliers Forum SME Working Group to help reduce barriers that prevent viable industry partners from entering the supply chain.",
            "url": "https://assets.publishing.service.gov.uk/media/62a7543ee90e070396c9f7d2/Defence_Artificial_Intelligence_Strategy.pdf"
          },
          {
            "text": "Government Response to House of Common Second Report of Session 2024-2025 Developing AI Capacity and Expertise in UK Defence (Apr 2025)\n\nThis document responds to the recommendations made by the House of Commons on developing AI capacity and expertise within the MOD.\n\nRecommendation 8 outlines the MOD's plans to bring about more regular development and deployment of AI-enabled defense systems, and also urges the MOD to consider new procurement models to reach developers with software that has dual-use potential.",
            "url": "https://www.documentcloud.org/documents/25973602-government-response-developing-ai-capacity-and-expertise-in-uk-defence/?utm_source=chatgpt.com"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [
          {
            "text": "JSP 936 V1.1 Dependable Artificial Intelligence (AI) in Defence (Nov 2024)\n\nSection 3: Legal & Ethical Considerations of AI; establishes five binding ethical principles: Human-Centricity, Responsibility, Fairness, Security, and Explainability. These principles must be implemented across all Defence AI projects.",
            "url": "https://assets.publishing.service.gov.uk/media/6735fc89f6920bfb5abc7b62/JSP936_Part1.pdf"
          }
        ],
        "policy_documents": [
          {
            "text": "Ambitious, Safe, Responsible: Our Approach to the Delivery of AI-Enabled Capability in Defence (Jun 2022)\n\nAnnex A details the five ethical principles framework with reference to the MOD's existing obligations under UK law and international law.\n\nAnnex B outlines the responsibility of the Ministry of Defence AI Ethics Advisory Panel, which is to scrutinize the MOD's ongoing approach to responsible and ethical AI and provide guidance and feedback.",
            "url": "https://assets.publishing.service.gov.uk/media/62a9b1d1e90e07039e31b8cb/20220614-Ambitious_Safe_and_Responsible.pdf"
          },
          {
            "text": "Defence Artificial Intelligence Strategy (Jun 2022)\n\nSection 1.3 defers to the Ambitious, Safe, Responsible framework for AI ethics.\n\nChapter 3.5: International Capability Collaboration; outlines key efforts with various allies and alliances to enhance AI cooperation and increase mutual benefit.",
            "url": "https://assets.publishing.service.gov.uk/media/62a7543ee90e070396c9f7d2/Defence_Artificial_Intelligence_Strategy.pdf"
          },
          {
            "text": "British Army Approach to Artificial Intelligence (Dec 2023)\n\nThis strategy document commits the British Army to delivering capabilities that are interoperable with NATO allies and partners.",
            "url": "https://www.army.mod.uk/media/24745/20231001-british_army_approach_to_artificial_intelligence.pdf"
          },
          {
            "text": "The Government Response to the Report by the House of Lords AI in Weapons Systems Committee: 'Proceed With Caution: Artificial Intelligence in Weapons Systems' (Feb 2024)\n\nSection 2: Ethics, Legal, and Governance; addresses recommendations and conclusioons regarding the domestic and international implementation of the MOD's AI Ethical Principels in the context of legal and safety frameworks.",
            "url": "https://assets.publishing.service.gov.uk/media/65cb77caa7ded0000c79e526/Government_response_to_the_House_of_Lords_AI_in_Weapon_Systems_Committee_Report.pdf"
          },
          {
            "text": "Government Response to House of Common Second Report of Session 2024-2025 Developing AI Capacity and Expertise in UK Defence (Apr 2025)\n\nRecommendation 20 addresses cooperation with the UK's allies through AUKUS and NATO to reach a mutual understanding of AI objectives and strategies, focusing on shared approaches to ethics, data collection and labelling, and capacity-building.",
            "url": "https://www.documentcloud.org/documents/25973602-government-response-developing-ai-capacity-and-expertise-in-uk-defence/?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Use of Artificial Intelligence and Autonomy (Nov 2024)\n\nThe United Kingdom signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "Int'l Cooperation & Interoperability": {
        "legal_directives": [
          {
            "text": "JSP 936 V1.1 Dependable Artificial Intelligence (AI) in Defence (Nov 2024)\n\nSection 4: AI Ethics Governance (Governance of Non-Sovereign AI Development); details requirements for international AI sharing and alignment with NATO principles.",
            "url": "https://assets.publishing.service.gov.uk/media/6735fc89f6920bfb5abc7b62/JSP936_Part1.pdf"
          }
        ],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [
          {
            "text": "JSP 936 V1.1 Dependable Artificial Intelligence (AI) in Defence (Nov 2024)\n\nSection 2: AI in Defence Systems; clearly defines autonomous systems and the levels within such systems.\n\nSection 5: Human/AI Teams; mandates \"clearly defined means by which human control is exercised throughout their lifecycles.\" It directs human-centered AI design and training.\n\nSection 6: AI Lifecycles; mandates data integrity management, control frameworks for training/testing data, and bias mitigation. It covers requirements for all stages of the AI lifecycle.\n\nSection 7: Quality, Safety & Security; requires safety assurance through testing, evaluation, verification, and validation. It also requires compliance with UK Defence Standards 00-055 and 00-056.\n\nSection 7: Quality, Safety & Security; requires a \"secure by design\" approach with specific attention to security challenges, such as data poisoning and adverserial attacks.",
            "url": "https://assets.publishing.service.gov.uk/media/6735fc89f6920bfb5abc7b62/JSP936_Part1.pdf"
          }
        ],
        "policy_documents": [
          {
            "text": "Ambitious, Safe, Responsible: Our Approach to the Delivery of AI-Enabled Capability in Defence (Jun 2022)\n\nSection: Using AI Safely; describes the UK AI safety regime, and provides the responsibilities of the Defence Accident Investigation Branch (DAIB), and the role of the Defence Safety Authority (DSA). Strict compliance is a focus item for safe use of AI.\n\nSection: Our Approach and AI-Enabled Weapons; establishes that appropriate human control is necessary in autonomous AI systems.",
            "url": "https://assets.publishing.service.gov.uk/media/62a9b1d1e90e07039e31b8cb/20220614-Ambitious_Safe_and_Responsible.pdf"
          },
          {
            "text": "Defence Artificial Intelligence Strategy (Jun 2022)\n\nSection 5.3.1: AI, Strategic Systems and Deterrence; explicitly states that \"regardless of any use of AI in our strategic systems - human political control of our nuclear weapons is maintained at all times\".",
            "url": "https://assets.publishing.service.gov.uk/media/62a7543ee90e070396c9f7d2/Defence_Artificial_Intelligence_Strategy.pdf"
          }
        ],
        "public_statements": []
      }
    },
    "USA": {
      "LAWS Employment/Deployment": {
        "legal_directives": [
          {
            "text": "DoD Directive 3000.09 \"Autonomy in Weapons Systems\" (Jan 2023)\n\nThis directive establishes policy and assigns responsibilities for developing and using autonomous and semi-autonomous functions in weapons systems. It also establishes guidelines designed to minimize the probability of failures in such weapons systems that could lead to unintended consequences.\n\nThe following are required: rigorous hardware and software verification and validation (V&V) and realistic system developmental and operational testing and evaluation (T&E), including analysis of unanticipated emergent behavior in complex operational environments.",
            "url": "https://www.esd.whs.mil/portals/54/documents/dd/issuances/dodd/300009p.pdf"
          },
          {
            "text": "H.R.5009 - Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025 (Dec 2024)\n\nSection 1066 \u2013 requires the Secretary of Defense to submit annual comprehensive reports to congressional defense committees on the approval and deployment of lethal autonomous weapon systems by the United States through December 31, 2029.",
            "url": "https://www.congress.gov/bill/118th-congress/house-bill/5009/text"
          }
        ],
        "policy_documents": [
          {
            "text": "US Submission to the GGE at the Convention on Prohibitions or Restrictions on the Use of Certain Conventional Weapons (Nov 2017)\n\nThe US states that it complies with the law of war and a rigorous testing and evaluation (T&E), and verification and validation (V&V) for autonomous and semi-autonomous weapons.\n\nAutonomy in weapons systems can improve the implementation of the law of war in military operations, and legal accountability and legal reviews of the development and use of autonomous weapons.",
            "url": "https://ogc.osd.mil/Portals/99/Law%20of%20War/Practice%20Documents/US%20Working%20Paper%20-%20Autonomy%20in%20Weapon%20Systems%20-%20CCW_GGE.1_2017_WP.6_E.pdf?ver=Vh75581oFwDjfaDK0EE8MQ%3D%3D"
          },
          {
            "text": "US Paper to the CCW on the Humanitarian Benefits of Emerging Technologies in the Area of Lethal Autonomous Weapon Systems (Apr 2018)\n\nThe US acknowledges the potential benefits of autonomous lethal weapons and encourages the innovation of such technologies that further the \"objectives and purposes of the Convention,\" opposing a ban on LAWS.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-_Group_of_Governmental_Experts_%282018%29/CCW_GGE.1_2018_WP.4.pdf"
          },
          {
            "text": "US National Statement at the Vienna Conference \"Humanity at the Crossroads: Lethal Autonomous Weapon Systems\" (Apr 2024)\n\nThis statement emphasizes the GGE's work on the issues surounding LAWS, but states that the US is not in a position to align itself with the view that new measures to regulate LAWS are necessary.\n\nThe US reaffirms that all use of AI in armed conflict must be in accordance with states' obligations under IHL.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/United_States_National_Statement.pdf"
          },
          {
            "text": "US Submission to the UN Secretary General Pursuant to Resolution 78/241 on Lethal Autonomous Weapon Systems (May 2024)\n\nThe United States views the UN GGE to be the best forum to advance international effors on LAWS.\n\nIHL already provides the applicable framework of prohibitions and regulations on the use of LAWS in armed conflict.\n\nThe US states that it does not currently support a legally binding instrument on LAWS.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-US-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "US Statement at the Second Session in 2023 of the CCW GGE on LAWS (May 2023)\n\nThe US holds and reaffirms that IHL already governs LAWS and that autonomy in weapon systems is not unlawful. The US urges a reconsideration of the creation of a new legally binding prohibition or regulatory framework on LAWS.",
            "url": "https://geneva.usmission.gov/2023/05/15/second-session-in-2023-of-the-gge-on-emerging-technologies-in-the-area-of-laws/?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nThe US voted in support of this Resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nThe US voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [
          {
            "text": "John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Dec 2018)\n\nSection 238 \u2013 Joint Artificial Intelligence Research, Development, and Transition Activities; directs the DoD to establish activities for joint AI R&D . This requires a strategic plan, identification of priority AI missions, coordination with components, and a statutory definition for artificial intelligence.",
            "url": "https://www.congress.gov/115/plaws/publ232/PLAW-115publ232.pdf"
          },
          {
            "text": "National Defense Authorization Act for Fiscal Year 2020 (Dec 2019)\n\n-Section 256 \u2013 Artificial Intelligence Strategy; directs the DoD to develop an AI education strategy for military and civilian personnel, to include identifying required AI competencies, education programs, andopportunities for training.\n\nSection 260 \u2013 Biannual Reporting on the Joint Artificial Intelligence Center; requires the Secretary of Defense to submit a biannual report to Congress on JAIC activities, progress, resources, and integration into operations.",
            "url": "https://www.congress.gov/116/plaws/publ92/PLAW-116publ92.pdf"
          },
          {
            "text": "James M. Inhofe National Defense Authorization Act for Fiscal Year 2023 (Dec 2022)\n\nSection 1513: Establishing Projects for Data Management, AI, and Digital Solutions; establishes projects and builds infrastructure that leverage data, AI, and digital tools to support operations. It also mandates that the CDAO work with the Under Secretary of Defense to implement, track, and modify data and AI practices in accordance with the outlined policy.",
            "url": "https://www.congress.gov/bill/117th-congress/house-bill/7776/text"
          },
          {
            "text": "National Defense Authorization Act for Fiscal Year 2024 (Dec 2023)\n\nSection 346 \u2013 authorizes a pilot program to optimize aerial refueling and fuel management in contested environments through use of AI.",
            "url": "https://www.congress.gov/bill/118th-congress/house-bill/2670/text"
          },
          {
            "text": "NSM-25 Advancing the United States\u2019 Leadership in Artificial Intelligence; Harnessing Artificial Intelligence to Fulfill National Security Objectives; and Fostering the Safety, Security, and Trustworthiness of Artificial Intelligence (Oct 2024)\n\nWithin 270 days of the release of this document and yearly for the next 5 years, all departments, including the DoD, are mandated to provide a report of to the President that offers a detailed accounting of activities in response to the taskings in the memorandum.\n\nThe DoD is instructed to, when building computational infrastructure, design facilities capable of \"harnessing frontier AI for relevant scientific research domains and intelligence analysis\".",
            "url": "https://bidenwhitehouse.archives.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/"
          },
          {
            "text": "DoD Directive 5105.89 \"Chief Digital and Artificial Intelligence Officer (CDAO) (Nov 2024)\n\nThe CDAO is established as the senior DoD official for the adoption and integration of data, analytics, and AI capabilities.\n\nCDAO is also given policy oversight over the modernization process with authority over relevant acquisition activities.\n\nThe directive  pesents the CDAO's responsibilities and functions, as well as its relationship to other relevant authorities and actors such as DoD Component heads and principal staff assistants.",
            "url": "https://www.esd.whs.mil/Portals/54/Documents/DD/issuances/dodd/510589p.PDF?ver=Ikhn-60VR-GpxO78wiYQZA%3D%3D"
          },
          {
            "text": "H.R.5009 - Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025 (Dec 2024)\n\nSection 221 \u2013 requires the appointment of a Chief Digital Engineering Recruitment and Management Officer to identify and clarify roles and responsibilities of the DoD AI workforce, including creating qualification programs for the force.\n\nSection 222 \u2013 develops educational courses on responsible and ethical AI development and use.\n\nSection 236 \u2013 establishes a five-year pilot program for developing AI for national security biotechnology applications through public-private partnerships.\n\nSection 225 \u2013 expands CDAO Governing Council duties to identify AI models that could pose national security risks if accessed by adversaries, develop strategies to prevent unauthorized access, and make recommendations to Congress for legislative action.\n\nSection 1534 \u2013 directs the evaluation of establishing centers of excellence to support the development and maturation of AI-enabled weapons systems with collaboration between DoD and foreign partners.",
            "url": "https://www.congress.gov/bill/118th-congress/house-bill/5009/text"
          },
          {
            "text": "National Defense Authorization Act for Fiscal Year 2026 (Dec 2025)\n\nSection 224 \u2013 authorizes the DoD to establish one or more National Security and Defense Artificial Intelligence Institutes to focus on AI research in national security and defense challenges.\n\nSection 547 \u2013 authorizes a pilot program for generative AI and spatial computing for performance training, with the goal of assessing the feasibility and effectiveness of the use of these training methods\n\nSection 1007 \u2013 directs the use of artificial intelligence to improve DoD financial auditing\n\nSection 1515 \u2013 updates cybersecurity trainng to include AI-specific threat vectors\n\nSection 1534 \u2013 requires the establishment of sandbox environments necessary to support AI experimentation, training, familiarization, and development across the DoD\n\nSection 1535 \u2013 mandates the creation of an AI Futures Steering Committee, whose responsibility is to formulate policy for the evaluation, adoption, governance, and risk mitigation of advanced AI systems, and analyze forecasted trajectories of advanced and emerging models",
            "url": "https://www.congress.gov/bill/119th-congress/senate-bill/1071/text"
          }
        ],
        "policy_documents": [
          {
            "text": "DoD Responsible Artificial Intelligence Strategy & Implementation Pathway (Jun 2022)\n\nThis document operationalizes the DoD AI Ethical Principles and guides the implementation of Responsible AI (RAI) into the Department's existing framework.\n\nTenet 6: AI Workforce; aims to achieve a standard level of technological familiarity and proficiency for system operators to achieve justified confidence in AI capabilities and AI-enabled systems. It also ensure that all DoD AI Workforce members possess an appropriate understanding of the technology development process and the operational methods applicable to implementing RAI commensurate with their duties.",
            "url": "https://media.defense.gov/2024/Oct/26/2003571790/-1/-1/0/2024-06-RAI-STRATEGY-IMPLEMENTATION-PATHWAY.PDF"
          },
          {
            "text": "DoD 2023 Data, Analytics, and AI Adoption Strategy (Jun 2023)\n\nThe Strategy requires compliance with the DoD AI Ethical Principles and presents Key Outcomes, Strategic Goals, and an Implementation Pathway.\n\nThe DoD is mandated to identify and employ talent both within and ouside the defense workforce in addition to training nontechnical personnel to lead and oversee the developmental pathway for AI in the Department.\n\nA decentralized data ownership system that is managed using the VAULTIS framework (Visible, Accessible, Understandable, Linked, Trustworthy, Interoperable, Secure) is required.\n\nIncluded in this strategy are plans to reduce institutional barriers that inhibit collective R&D, planning, interoperability, intelligence, and information sharing . This is expected to be achieved by using iterative feedback and \"campaigns of learning\" to improve capability.",
            "url": "https://media.defense.gov/2023/Nov/02/2003333300/-1/-1/1/DOD_DATA_ANALYTICS_AI_ADOPTION_STRATEGY.PDF"
          }
        ],
        "public_statements": [
          {
            "text": "Deputy Secretary of Defense Remarks \"Unpacking the Replicator Initiative\" (Sep 2023)\n\nDeputy Secretary Kathleen Hicks states that the Replicator Inititative will be a strategic development of \"all-domain, attritable autonomy (ADA2)\" to counter the People's Republic of China's (PRC) advantage of more ships, missiles, and forces.\n\nHicks states that the DoD has invested in self-piloting ships, uncrewed aircraft across the services, DIU, and the combatant commands.\n\nThe goal is \"to field attritable autonomous systems at a scale of multiple thousands, in multuple domains, within the next 18-to-24 months\".\n\nThe US policy for autonomy in weapons remains that \"there is always a human responsible for the use of force\".",
            "url": "https://www.war.gov/News/Speeches/Speech/Article/3517213/deputy-secretary-of-defense-kathleen-hicks-remarks-unpacking-the-replicator-ini/"
          },
          {
            "text": "Remarks by Vice President Harris on the Future of Artificial Intelligence (Nov 2023)\n\nVice President Kamala Harris reiterates the principles for responsible development, deployment, and use of military AI and autonomous capabilities, and states that these principles include a \"rigorous legal review process for AI decision-making.\" This statement commits that US AI systems will always operate under IHL.",
            "url": "https://bidenwhitehouse.archives.gov/briefing-room/speeches-remarks/2023/11/01/remarks-by-vice-president-harris-on-the-future-of-artificial-intelligence-london-united-kingdom/?utm_source=chatgpt.com"
          },
          {
            "text": "Deputy Secretary of Defense on \"The State of AI in the Department of Defense\" (Nov 2023)\n\nDeputy Secretary Kathleen Hicks announces current progress on foundational efforts made in the data and AI fields.\n\nUS policy for autonomy in weapon systems remains unchanged in that a human will always be responsible for the use of force.\n\nHicks states that the DoD does not use \"AI to censor, constrain, repress, or disempower people,\" and that AI and its capabilities will be used only to deter aggression and defend the homeland, allies and partners, and interests.",
            "url": "https://www.war.gov/News/Speeches/Speech/Article/3578046/remarks-by-deputy-secretary-of-defense-kathleen-h-hicks-on-the-state-of-ai-in-t/"
          },
          {
            "text": "Deputy Secretary of Defense  Announcement of Additional Replicator ADA2 Capabilities (Nov 2024)\n\nDeputy Secretary Kathleen Hicks announces air and maritime domain systems will be selected for accelerated fielding as part of the Replicator 1.2 initiative.\n\nThe Department plans to invest in unmanned aircraft systems and loitering munitions, as well as classified systems involving \"low-cost long-range strike capabilities and maritime uncrewed systems\".\n\nHicks states that autonomy efforts strive to act as \"integrated enablers\" capable of autonomously coordinating vast numbers of unmanned assets.",
            "url": "https://www.war.gov/News/Releases/Release/article/3963289/deputy-secretary-of-defense-kathleen-hicks-announces-additional-replicator-all/"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nThe US voted in support of this Resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          },
          {
            "text": "DoW Under Secretary of War for Reseach and Engineering on AI Implementation (Sep 2025)\n\nUnder Secretary of Defense Emil Michael states that \"we want to have an AI capability on every desktop - 3 million desktops - in six to nine months\" to focus on applications for corporate use cases like efficiency in addition to intelligence and warfighting needs.",
            "url": "https://www.nextgov.com/artificial-intelligence/2025/09/pentagon-research-official-wants-have-ai-every-desktop-6-9-months/408152/"
          },
          {
            "text": "DoW Under Secretary of War for Research and Engineering Announcement of Six Critical Technology Areas (Nov 2025)\n\nUnder Secretary Emil Michael announces that Applied Artificial Intelligence is one of the six critical technology areas that the War Department will focus on to define the future of US military superiority.",
            "url": "https://www.war.gov/News/Releases/Release/Article/4333074/under-secretary-of-war-for-research-and-engineering-emil-michael-announces-six/"
          },
          {
            "text": "Department of War Adoption of Internal AI Platform (Dec 2025)\n\nThe Department of War announces Google Cloud's Gemini for Government as the first of several to be housed in the department's platform GenAI.mil. This capability is active on all desktops on military installations in the world, and aligns with the presidential mandate to \"achieve an unprecedented level of AI technological superiority.\"",
            "url": "https://www.war.gov/News/Releases/Release/Article/4354916/the-war-department-unleashes-ai-on-new-genaimil-platform/"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [
          {
            "text": "National Defense Authorization Act for Fiscal Year 2022 (Dec 2021)\n\nSection 227 \u2013 Modification of the Joint Common Program; mandates that the DoD modify the Joint Common Foundation program to ensure that the department's components can more easily contract with leading commercial AI companies.\n\nSection 232 \u2013 Pilot Program on Data Repositoriesto Facilitate the Development of AI Capabilities for the DoD; authorizes the DoD to create data repositories to support AI/ML development and includes requirements for categorization, annotation, and use in a common evaluation framework for AI models.",
            "url": "https://www.congress.gov/bill/117th-congress/senate-bill/1605"
          },
          {
            "text": "H.R.5009 - Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025 (Dec 2024)\n\nSection 125 \u2013 requires the Secretary of the Navy to designate an official responsible for developing and acquiring advanced autonomous vehicles with a dedicated program element in Navy budgets.\n\nSection 235 \u2013 requires the CDAO to develop venue and testing processes for comparing automated target recognition algorithms by June 1, 2025.\n\nSection 1620 \u2013 develops a plan to streamline the budgeting process for necessary data acquisition with annual evaluations and reporting to Armed Services Committees.",
            "url": "https://www.congress.gov/bill/118th-congress/house-bill/5009/text"
          },
          {
            "text": "National Defense Authorization Act for Fiscal Year 2026 (Dec 2025)\n\nSection 347 \u2013 forces the DoD to integrate suitable commercial AI into military logistics to assist with logistics tracking, planning, operations, and analytics into 2 DoD exercises to be conducted in 2026.\n\nSection 6602 \u2013 requires the intelligence community (IC) to share reusable AI components, standardize AI contract terms, track performance and safety metrics, and reduce vendor lock-in.",
            "url": "https://www.congress.gov/bill/119th-congress/senate-bill/1071/text"
          }
        ],
        "policy_documents": [
          {
            "text": "US DoD 2023 Data, Analytics, and AI Adoption Strategy (Jun 2023)\n\nThe strategy requires DoD Components to follow an \"adopt-buy-create\" approach to acquiring R&D capabilities, prioritize joint or DoD-sponsored solutions, then source commercial assets where viable.\n\nTenet 3: AI Product and Acquisition Life Cycle; develops RAI-related acquisition resources and tools, such as standardized langauge, best practices, and processes to align AI development with the National Defense Strategy.",
            "url": "https://media.defense.gov/2023/Nov/02/2003333300/-1/-1/1/DOD_DATA_ANALYTICS_AI_ADOPTION_STRATEGY.PDF"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [
          {
            "text": "DoD Memorandum on Implementing Responsible Artificial Intelligence in the Department of Defense (May 2021)\n\nThis memorandum issued by Deputy Secretary of Defense Kathleen Hicks outlines the DoD's adoption of the DoD AI Ethical Principles in accordance with the tenets that describe responsible AI (RAI): RAI Governance, Warfighter Trust, AI Product and Acquisition Lifeycle, Requirements Validation, Responsible AI Ecosystem, and AI Workforce.",
            "url": "https://www.war.gov/News/Releases/Release/Article/2091996/dod-adopts-ethical-principles-for-artificial-intelligence/"
          },
          {
            "text": "National Security Memorandum 25 (NSM-25) (Oct 2024)\n\nThe DoD (among other departments) is mandated to prioritize research on AI safety and trustworthiness and to improve the security, robustness, and reliability of AI systems and controls.",
            "url": "https://bidenwhitehouse.archives.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/"
          },
          {
            "text": "National Defense Authorization Act for Fiscal Year 2026 (Dec 2025)\n\nSection 1532 \u2013 explicitly limits and prohibits certain uses of covered AI inside the DoD, which includes models developed or operated by entities listed under the subsection of this NDAA section",
            "url": null
          }
        ],
        "policy_documents": [
          {
            "text": "DoD Ethical Principles for Artificial Intelligence (Feb 2020)\n\nThe principles build on the US military's existing ethics framework with a specific focus on artificial intelligence, mandating its development and deployment to be Responsible, Equitable, Traceable, Reliable, and Governable. These principles apply to both combat and non-combat applications across the DoD.",
            "url": "https://www.war.gov/News/Releases/Release/Article/2091996/dod-adopts-ethical-principles-for-artificial-intelligence/"
          },
          {
            "text": "DoD Responsible Artificial Intelligence Strategy & Implementation Pathway (Jun 2022)\n\nThe document creates a comprehensive framework for ensuring AI systems are developed and deployed ethically through clear accountability and oversight mechanisms, outlining the Office of Professional Responsibility (OPR) for each Line of Effort.",
            "url": "https://media.defense.gov/2024/Oct/26/2003571790/-1/-1/0/2024-06-RAI-STRATEGY-IMPLEMENTATION-PATHWAY.PDF"
          }
        ],
        "public_statements": [
          {
            "text": "Secretary of Defense Speech on AI Development (Jul 2021)\n\nSecretary of Defense Lloyd Austin III commits the DoD to developing AI responsibly and without sacrificing safety, security, and ethics while addressing the \"pacing challenge\" of China's AI development.",
            "url": "https://www.war.gov/News/News-Stories/Article/Article/2692297/ethics-key-to-ai-development-austin-says/"
          },
          {
            "text": "Keynote Remarks by Ambassador Jenkins to the Summit on Responsible Artificial Intelligence in the Military Domain (REAIM) Ministerial Segment (Feb 2023)\n\nUS Ambassador Bonnie Jenkins provides remarks at the 2023 REAIM Summit affirming the US approach to safely and securely harnessing AI capabilities and following all IHL provisions.\n\nAmbassador Jenkins also announces the Political Declaration on Responsible Military Use of Artificial Intelligence and Autonomy, urging states to join in implementing international norms.",
            "url": "https://2021-2025.state.gov/keynote-remarks-by-u-s-jenkins-t-to-the-summit-on-responsible-artificial-intelligence-in-the-military-domain-reaim-ministerial-segment/"
          },
          {
            "text": "The United States' Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\nThe US supports the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://asianews.network/seoul-summit-charts-framework-on-responsible-ai-military-use/"
          }
        ]
      },
      "Int'l Cooperation & Interoperability": {
        "legal_directives": [
          {
            "text": "H.R.5009 - Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025 (Dec 2024)\n\nSection 1087 \u2013 establishes a DoD working group for multilateral AI coordination to accelerate interoperability of systems used for intelligence sharing and battlespace awareness with several allies and partners.",
            "url": "https://www.congress.gov/bill/118th-congress/house-bill/5009/text"
          }
        ],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US-Singapore Statement of Interest Regarding Data, Analytics, and AI Cooperation (Jul 2024)\n\nThe Statement of Interest adopts a \"holistic approach\" to enable defense cooperation regarding best practices and future cooperation between the two countries.",
            "url": "https://www.war.gov/News/Releases/Release/Article/3839100/united-states-and-singapore-sign-soi-to-strengthen-data-analytics-and-artificia/"
          },
          {
            "text": "US DoD Political Declaration on Responsible Use of Artificial Intelligence and Autonomy (Nov 2024)\n\nThe United States spearheaded the effort and signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [
          {
            "text": "DoD Directive 3000.09 \"Autonomy in Weapons Systems\" (Jan 2023)\n\nSection 3: Verification amd Validation and Testing and Evaluation of Autonomous and Semi-Autonomous Weapons Systems; outlines the safety requirements that all autonomous and semi-autonomous weapon systems must adhere to and follow.\n\nThe Under Secretary of Defense for Research and Engineering oversees establishment of standards for developmental testing, safety certification, and reliability assessment with particular attention to the risk of unintended engagements.\n\nSystems must have clear procedures to activate and deactivate functions, provide transparent feedback on system status, and be designed to complete engagements within defined timeframes and geographic areas consistent with commander intentions.",
            "url": "https://www.esd.whs.mil/portals/54/documents/dd/issuances/dodd/300009p.pdf"
          },
          {
            "text": "NSM-25 Advancing the United States\u2019 Leadership in Artificial Intelligence; Harnessing Artificial Intelligence to Fulfill National Security Objectives; and Fostering the Safety, Security, and Trustworthiness of Artificial Intelligence (Oct 2024)\n\nThe AI Safety Institute (AISI) must issue guidance for AI developers, including the DoD, on testing, evaluating, and managing risks of dual-use foundation models, addressing how to measure capabilities relevant to biological and chemical weapons or automated offensive cyber operations and develop mitigation measures.\n\nThe Framework prohibits using AI to \"remove a human in the loop for actions critical to informing and executing decisions by the President to initiate or terminate nuclear weapons employment.\".",
            "url": "https://bidenwhitehouse.archives.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/?utm_source=chatgpt.com"
          },
          {
            "text": "H.R.5009 - Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025 (Dec 2024)\n\nSection 1638 \u2013 establishes a Statement of Policy regarding use of AI in nuclear weaponry systems requiring positive human action in executing decisions by the president to use such weapons.",
            "url": "https://www.congress.gov/bill/118th-congress/house-bill/5009/text"
          },
          {
            "text": "National Defense Authorization Act for Fiscal Year 2026 (Dec 2025)\n\nSection 1512 \u2013 mandates a DoD-wide policy to address AI and machine learning cybersecurity threats, to include adverserial attacks, tampering, data poisoning, and extraction, as well as reporting and mitigation plans for these threats\n\nSection 1513 \u2013 mandates the creation of a cybersecurity and physical security framework for the procurement AI systems\n\nSection 1533 \u2013 establishes a DoD-wide AI model testing and validation framework through a cross-functional team whose responsibility is to facilitate the \"evaluation of, collaboration on, and enablement of\" rapid development or procurement of AI models used by the DoD\n\nSection 6601/6603 \u2013 extends AI security policies to commercial and open models used in classified systems and make the intelligence community security controls follow the deployment environment",
            "url": "https://www.congress.gov/bill/119th-congress/senate-bill/1071/text"
          }
        ],
        "policy_documents": [
          {
            "text": "DoD Ethical Principles for Artificial Intelligence (Feb 2020)\n\nThe Reliable Principle requires that DoD AI capabilities have explicit, well-defined uses with safety, security and effectiveness subject to testing and assurance within those defined uses across their entire life cycle.\n\nThe framework states that the \"Department will design and engineer AI capabilities to fulfill their intended functions while possessing the ability to detect and avoid unintended consequences, and the ability to disengage or deactivate deployed systems that demonstrate unintended behavior\".",
            "url": "https://www.war.gov/News/Releases/Release/Article/2091996/dod-adopts-ethical-principles-for-artificial-intelligence/"
          }
        ],
        "public_statements": []
      }
    },
    "Ukraine": {
      "LAWS Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\nUkraine voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\nUkraine abstained from voting on Draft Resolution L.77 on lethal autonomous weapons systems.\n\nThe resolution signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Ukraine's Submission in Connection With Resolution 79/239 \"Artificial Intelligence in the Military Domain and its Implications for International Peace and Security\" (2025) (2025)\n\nUkraine states that it uses military AI' exclusively to strengthen its defence capabilities by exercising the right to self-defense provided by the UN Charter.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_(2025)/79-239-Ukraine-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Deputy Prime Minister Statement on the Future of Autonomous Warfare (Apr 2023)\n\nDeputy PM and Minister of Digital Transformation Mykhailo Fedorov states that AI can be and currently is used for target recognition and other tasks.\n\nMinister Fedorov answers ambiguously on whether Ukraine has developed any technology that can operate fully autonomously.",
            "url": "https://www.wired.com/story/fast-forward-ukraines-quest-for-homegrown-ai-drones-to-take-on-russia/?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\nUkraine voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          },
          {
            "text": "Ministry of Defence Event \"Decisive Innovations: Ukraine's Next Steps in the Technology War\" (Aug 2025)\n\nThis news release covers the Ministry of Defence's plan to launch new support tools for the Ukrainian military, including artificial intelligence.\n\nMinister of Defence Denys Shmyhal announces 70 technical areas across nine categories, some of which include: AI, drones, ground robotic systems, unmanned boats, and more.",
            "url": "https://mod.gov.ua/en/news/ministry-of-defence-and-ministry-of-digital-transformation-establish-a-unified-ecosystem-to-support-ukrainian-arms-manufacturers?utm_source=chatgpt.com"
          },
          {
            "text": "Ukraine Domestic LLM for Military and Civilian Applications (Dec 2025)\n\nDeputy Minister for Digitalization Oleksandr Bornyakov states that Ukraine's military plans to integrate AI into battlefield systems for troop coordination and enemy tracking. Future models will be based on Google's Gemma framework due to its \"multilingual capabilities and performance.\"",
            "url": "https://stratnewsglobal.com/world-news/ukraine-develops-national-ai-model-on-googles-gemma-framework/#:~:text=Ukraine%20is%20building%20a%20large,both%20military%20and%20civilian%20applications."
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Brave1 Grant Competition Initiative (Sep 2025)\n\nThe Ministry of Defence and the Ministry of Digital Transformation launched the Brave1 grant competition for companies to provide solutions to improve mission autonomy for the Ukrainian military.\n\nThe focus areas include: autonomous drones, autonomous guidance modules and thermal targeting systems for drone interceptors, AI-based solutions for the interception and neutralization of guided aerial bombs, and simulation environments for training and testing AI-enabled autonomous combat systems.\n\nThis initiative shows Ukraine's intent to invest in both offensive and defensive capabilities for AI-based weapons.",
            "url": "https://mod.gov.ua/en/news/up-to-uah-100-million-for-breakthrough-ai-solutions-ministry-of-defence-and-ministry-of-digital-transformation-launch-brave1-grant-competition?utm_source=chatgpt.com"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\nUkraine signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\nStates must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "Ukraine Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024\n\nUkraine endorses the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI, and the future governance of AI in the military domain.",
            "url": "https://asianews.network/seoul-summit-charts-framework-on-responsible-ai-military-use/"
          }
        ]
      }
    }
  },
  "summaries": {
    "Algeria": "Algeria strongly advocates for a legally binding international instrument to regulate lethal autonomous weapons systems, emphasizing that such weapons fundamentally challenge international humanitarian law and human dignity.",
    "Armenia": "Armenia supports international regulation of autonomous weapons and emphasizes the importance of meaningful human control, while also engaging in defense modernization efforts including AI-related capabilities.",
    "Australia": "Australia is actively developing military AI and autonomous systems capabilities while supporting international governance frameworks that ensure compliance with international humanitarian law and meaningful human control.",
    "Azerbaijan": "Azerbaijan is investing in unmanned aerial vehicle capabilities for defense modernization, while participating in international discussions on AI governance in the military domain.",
    "Belgium": "Belgium was among the first countries to pass a parliamentary resolution calling for a ban on fully autonomous weapons, and consistently advocates for internationally agreed legal standards on LAWS.",
    "Brazil": "Brazil stresses the need for meaningful human control over autonomous weapons systems and supports the development of new international legal instruments to regulate LAWS under the CCW framework.",
    "Bulgaria": "Bulgaria supports a two-tier regulatory approach to LAWS, combining prohibitions on systems incompatible with international humanitarian law with risk mitigation measures for other autonomous systems.",
    "Canada": "Canada has developed a comprehensive AI strategy for defense that explicitly emphasizes human control, ethical guidelines, and compliance with international humanitarian law across all military AI applications.",
    "China": "China actively develops military AI capabilities while advocating for international governance frameworks, supporting human control requirements and proposing specific definitions and risk assessments for autonomous weapons.",
    "Colombia": "Colombia supports international regulation of autonomous weapons systems and advocates for meaningful human control, emphasizing the importance of addressing LAWS within multilateral frameworks.",
    "Croatia": "Croatia supports the development of international regulations on autonomous weapons and emphasizes the importance of maintaining human control and accountability in military AI systems.",
    "Czechia": "Czechia is investing in defense modernization including AI capabilities while taking a cautious approach to international LAWS regulation, abstaining from some UN resolutions while supporting others.",
    "Denmark": "Denmark supports a two-tier approach to LAWS regulation and is actively developing national defense AI strategies while emphasizing compliance with international humanitarian law.",
    "Egypt": "Egypt strongly supports a two-tiered approach to regulating LAWS, calling for prohibitions on fully autonomous systems while allowing regulated use of semi-autonomous weapons under human control.",
    "Estonia": "Estonia is a leader in defense AI policy, having published a dedicated Defense AI Strategy and consistently advocating for meaningful human control while developing innovative military AI capabilities.",
    "Finland": "Finland pursues international instruments to govern autonomous weapons while developing national defense AI capabilities, emphasizing human oversight and compliance with international law.",
    "France": "France has developed comprehensive military AI policies explicitly rejecting fully autonomous lethal systems while actively investing in AI-enabled defense capabilities and supporting international governance frameworks.",
    "Germany": "Germany strongly supports international regulation of autonomous weapons, advocating for legally binding instruments and comprehensive operationalization of the CCW Guiding Principles at the national level.",
    "Greece": "Greece supports a two-tier approach to LAWS regulation and is investing in defense innovation including AI capabilities while emphasizing the importance of human control over critical decisions.",
    "Hungary": "Hungary supports international governance frameworks for autonomous weapons while developing national defense capabilities, voting in favor of UN resolutions promoting multilateral discussions on LAWS.",
    "India": "India is rapidly developing military AI capabilities and establishing dedicated AI centers within the defense establishment, while taking an independent stance on international LAWS regulation.",
    "Iran": "Iran takes a cautious approach to international LAWS discussions, abstaining from key UN resolutions while expressing concerns about the implications of autonomous weapons for international security.",
    "Iraq": "Iraq calls for clear international legal frameworks governing autonomous weapons, supporting UN resolutions that promote multilateral discussions and emphasizing the importance of human control.",
    "Israel": "Israel is a global leader in military AI and autonomous systems development, with extensive operational deployment of AI-enabled defense capabilities. The country views human control as one consideration among several, but this advanced operational posture contrasts with a limited public policy footprint, with few formal guidelines or governance frameworks addressing military AI use.",
    "Italy": "Italy supports a two-tier approach to LAWS regulation and is actively investing in military AI capabilities while emphasizing ethical guidelines and human oversight in autonomous systems.",
    "Japan": "Japan has established comprehensive guidelines for responsible AI in defense systems, explicitly maintaining human involvement in critical decisions while investing in AI-enabled military capabilities.",
    "Latvia": "Latvia emphasizes human control and responsibility in autonomous weapons discussions while developing national defense capabilities, taking a measured approach to international LAWS regulation.",
    "Lithuania": "Lithuania supports multilateral discussions on autonomous weapons governance and emphasizes the importance of maintaining human control, while developing national defense and security AI policies.",
    "Morocco": "Morocco advocates for a legally binding international instrument to regulate autonomous weapons, emphasizing the importance of human control and the potential risks of fully autonomous systems.",
    "Netherlands": "The Netherlands has comprehensive policies on autonomous weapons governance, supporting international regulation while actively developing defense AI capabilities with strong ethical frameworks.",
    "North Korea": "North Korea has limited public engagement on autonomous weapons governance, voting against or abstaining from key UN resolutions while maintaining opacity about military AI development.",
    "Norway": "Norway supports a legally binding instrument on autonomous weapons with a two-tier approach, while developing national defense AI strategies that emphasize human control and IHL compliance.",
    "Pakistan": "Pakistan strongly supports international regulation of LAWS, emphasizing that fully autonomous weapons pose fundamental challenges to international humanitarian law and human dignity.",
    "Poland": "Poland is actively developing military AI and autonomous systems capabilities, including drone warfare programs, while engaging in international discussions on LAWS governance frameworks.",
    "Russia": "Russia does not support bans on military AI development, emphasizing national discretion in implementing human control measures while actively developing advanced autonomous weapons capabilities.",
    "Singapore": "Singapore supports a two-tier approach to LAWS regulation and is establishing dedicated military AI centers, emphasizing governance frameworks while developing advanced defense AI capabilities.",
    "South Africa": "South Africa supports the creation of a legally binding instrument to regulate autonomous weapons, emphasizing the importance of maintaining meaningful human control over weapons systems.",
    "South Korea": "South Korea is a major developer of military AI and autonomous systems, establishing dedicated Defense AI Centers while supporting international governance frameworks and human control requirements.",
    "Spain": "Spain supports a two-tier approach to LAWS regulation and is participating in major international defense AI projects like FCAS while emphasizing ethical guidelines and human oversight.",
    "Sweden": "Sweden supports international regulation of autonomous weapons through legally binding instruments, emphasizing human control and accountability while developing national defense AI capabilities.",
    "Turkey": "Turkey is actively developing and deploying autonomous weapons capabilities while maintaining that binding international instruments would be premature, preferring existing IHL frameworks.",
    "UAE": "The United Arab Emirates is investing in autonomous defense systems through international partnerships while engaging in UN discussions on AI governance in the military domain.",
    "UK": "The United Kingdom has developed comprehensive defense AI strategies with detailed ethical frameworks, actively investing in AI capabilities while supporting international governance discussions.",
    "USA": "The United States has the most extensive military AI policy framework globally, with detailed directives on autonomous weapons, ethical principles, and significant investments in AI-enabled defense capabilities.",
    "Ukraine": "Ukraine is rapidly developing and deploying military AI and autonomous systems driven by wartime necessity, while engaging in international discussions on responsible AI use in defense.",
    "New Zealand": "New Zealand supports a legally binding international instrument to regulate lethal autonomous weapons systems. The country has co-sponsored UN resolutions calling for restrictions on LAWS and endorsed the Paris Declaration on maintaining human control in AI-enabled weapon systems. As a Five Eyes member, New Zealand maintains close defense intelligence cooperation with allies while advocating for responsible AI governance in military applications."
  },
  "alliances": {
    "NATO": {
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "NATO Artificial Intelligence Strategy (Revised Jul 2024) (Jul 2024)\n\nThe revised NATO AI Strategy outlines the alliance's approach to AI adoption across defense capabilities, establishing Principles of Responsible Use (PRU) including lawfulness, responsibility and accountability, explainability and traceability, reliability, governability, and bias mitigation.",
            "url": "https://www.nato.int/cps/en/natohq/official_texts_227237.htm"
          },
          {
            "text": "Washington Summit Declaration (Jul 2024)\n\nThe Washington Summit Declaration reaffirms NATO's commitment to responsible AI development and deployment, emphasizing the importance of maintaining technological superiority while adhering to international law and ethical principles.",
            "url": "https://www.nato.int/cps/en/natohq/official_texts_227678.htm"
          }
        ],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "NATO's Autonomy Implementation Plan (Oct 2022)\n\nThis implementation plan outlines technical requirements for autonomous systems within NATO forces, including safety standards, testing protocols, and interoperability requirements across member states.",
            "url": "https://www.nato.int/cps/en/natohq/topics_184303.htm"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "NATO Principles of Responsible Use of AI in Defence (Oct 2021)\n\nNATO established six core principles for responsible AI use: lawfulness, responsibility and accountability, explainability and traceability, reliability, governability, and bias mitigation. These principles guide all AI development and deployment across the alliance.",
            "url": "https://www.nato.int/cps/en/natohq/official_texts_187617.htm"
          }
        ],
        "public_statements": []
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "NATO AI Strategy - Interoperability Framework (Jul 2024)\n\nThe strategy establishes frameworks for AI interoperability among NATO members, ensuring that AI-enabled systems can operate effectively across alliance forces while maintaining shared standards for responsible use.",
            "url": "https://www.nato.int/cps/en/natohq/official_texts_227237.htm"
          },
          {
            "text": "NATO Defence Innovation Accelerator (DIANA) (Jun 2022)\n\nDIANA facilitates dual-use technology development including AI across NATO members, connecting innovators with allied defense establishments to accelerate responsible AI adoption throughout the alliance.",
            "url": "https://www.diana.nato.int/"
          }
        ],
        "public_statements": []
      }
    },
    "AUKUS": {
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "AUKUS Trilateral Security Partnership - Pillar II (Sep 2021)\n\nPillar II of AUKUS establishes cooperation on advanced capabilities including AI and autonomy. The partnership aims to accelerate responsible AI development and deployment across the three nations' defense establishments.",
            "url": "https://www.whitehouse.gov/briefing-room/statements-releases/2021/09/15/joint-leaders-statement-on-aukus/"
          }
        ],
        "public_statements": [
          {
            "text": "AUKUS Advanced Capabilities Trilateral Steering Group (Apr 2024)\n\nThe steering group announced prioritization of AI and autonomy as key capability areas, with trilateral working groups established to coordinate AI policy alignment, technology sharing, and joint development initiatives.",
            "url": "https://www.defense.gov/News/Releases/Release/Article/3746159/"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "AUKUS Leaders' Joint Statement (Dec 2023)\n\nThe joint statement reaffirmed commitment to Pillar II advanced capabilities cooperation, announcing progress on AI and autonomous systems integration across partner nations, with emphasis on interoperability and responsible development.",
            "url": "https://www.whitehouse.gov/briefing-room/statements-releases/2023/12/01/aukus-joint-leaders-statement/"
          },
          {
            "text": "AUKUS Defense Ministers Meeting Outcomes (Sep 2024)\n\nDefense ministers announced expanded AI cooperation under Pillar II, including joint AI testing frameworks, shared evaluation standards, and collaborative development of AI-enabled autonomous systems.",
            "url": "https://www.defense.gov/News/Releases/Release/Article/3910567/"
          }
        ],
        "public_statements": []
      }
    },
    "FVEY": {
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Deploying AI Systems Securely: Best Practices for Deploying Secure and Resilient AI Systems (Apr 2024)\n\nJoint guidance from Five Eyes cybersecurity agencies (CISA, NSA, FBI, ACSC, CCCS, NCSC-NZ, NCSC-UK) providing best practices for deploying secure and resilient AI systems, addressing threats from adversarial manipulation and ensuring AI system integrity.",
            "url": "https://www.cisa.gov/resources-tools/resources/deploying-ai-systems-securely"
          }
        ],
        "public_statements": []
      }
    }
  },
  "allianceSummaries": {
    "NATO": "Belgium, Bulgaria, Canada, Croatia, Czech Republic, Denmark, Estonia, Finland, France, Germany, Greece, Hungary, Iceland, Italy, Latvia, Lithuania, Luxembourg, Montenegro, Netherlands, North Macedonia, Norway, Poland, Portugal, Romania, Slovakia, Slovenia, Spain, Turkey, United Kingdom, United States",
    "AUKUS": "Australia, UK, USA",
    "FVEY": "Australia, Canada, New Zealand, UK, USA"
  },
  "similarityMatrix": {
    "Algeria": {
      "Algeria": 1.0,
      "Armenia": 0.845,
      "Australia": 0.331,
      "Azerbaijan": 0.576,
      "Belgium": 0.737,
      "Brazil": 0.777,
      "Bulgaria": 0.76,
      "Canada": 0.477,
      "China": 0.504,
      "Colombia": 0.744,
      "Croatia": 0.76,
      "Czechia": 0.614,
      "Denmark": 0.614,
      "Egypt": 0.817,
      "Estonia": 0.405,
      "Finland": 0.614,
      "France": 0.37,
      "Germany": 0.593,
      "Greece": 0.614,
      "Hungary": 0.654,
      "India": 0.512,
      "Iran": 0.666,
      "Iraq": 0.744,
      "Israel": 0.391,
      "Italy": 0.614,
      "Japan": 0.391,
      "Latvia": 0.614,
      "Lithuania": 0.654,
      "Morocco": 0.779,
      "Netherlands": 0.405,
      "New Zealand": 0.744,
      "North Korea": 0.592,
      "Norway": 0.649,
      "Pakistan": 0.779,
      "Poland": 0.614,
      "Russia": 0.52,
      "Singapore": 0.437,
      "South Africa": 0.918,
      "South Korea": 0.473,
      "Spain": 0.614,
      "Sweden": 0.654,
      "Turkey": 0.512,
      "UAE": 0.595,
      "UK": 0.254,
      "USA": 0.192,
      "Ukraine": 0.537
    },
    "Armenia": {
      "Algeria": 0.845,
      "Armenia": 1.0,
      "Australia": 0.453,
      "Azerbaijan": 0.586,
      "Belgium": 0.878,
      "Brazil": 0.859,
      "Bulgaria": 0.837,
      "Canada": 0.594,
      "China": 0.595,
      "Colombia": 0.817,
      "Croatia": 0.837,
      "Czechia": 0.729,
      "Denmark": 0.729,
      "Egypt": 0.777,
      "Estonia": 0.526,
      "Finland": 0.729,
      "France": 0.484,
      "Germany": 0.729,
      "Greece": 0.729,
      "Hungary": 0.769,
      "India": 0.604,
      "Iran": 0.729,
      "Iraq": 0.817,
      "Israel": 0.498,
      "Italy": 0.729,
      "Japan": 0.508,
      "Latvia": 0.729,
      "Lithuania": 0.769,
      "Morocco": 0.819,
      "Netherlands": 0.526,
      "New Zealand": 0.859,
      "North Korea": 0.568,
      "Norway": 0.777,
      "Pakistan": 0.819,
      "Poland": 0.729,
      "Russia": 0.595,
      "Singapore": 0.552,
      "South Africa": 0.819,
      "South Korea": 0.595,
      "Spain": 0.729,
      "Sweden": 0.769,
      "Turkey": 0.604,
      "UAE": 0.673,
      "UK": 0.377,
      "USA": 0.294,
      "Ukraine": 0.654
    },
    "Australia": {
      "Algeria": 0.331,
      "Armenia": 0.453,
      "Australia": 1.0,
      "Azerbaijan": 0.504,
      "Belgium": 0.532,
      "Brazil": 0.544,
      "Bulgaria": 0.484,
      "Canada": 0.837,
      "China": 0.575,
      "Colombia": 0.476,
      "Croatia": 0.484,
      "Czechia": 0.682,
      "Denmark": 0.682,
      "Egypt": 0.391,
      "Estonia": 0.859,
      "Finland": 0.682,
      "France": 0.885,
      "Germany": 0.709,
      "Greece": 0.682,
      "Hungary": 0.642,
      "India": 0.646,
      "Iran": 0.46,
      "Iraq": 0.476,
      "Israel": 0.74,
      "Italy": 0.682,
      "Japan": 0.859,
      "Latvia": 0.682,
      "Lithuania": 0.642,
      "Morocco": 0.457,
      "Netherlands": 0.859,
      "New Zealand": 0.563,
      "North Korea": 0.391,
      "Norway": 0.669,
      "Pakistan": 0.457,
      "Poland": 0.682,
      "Russia": 0.575,
      "Singapore": 0.858,
      "South Africa": 0.325,
      "South Korea": 0.825,
      "Spain": 0.682,
      "Sweden": 0.642,
      "Turkey": 0.646,
      "UAE": 0.594,
      "UK": 0.784,
      "USA": 0.755,
      "Ukraine": 0.74
    },
    "Azerbaijan": {
      "Algeria": 0.576,
      "Armenia": 0.586,
      "Australia": 0.504,
      "Azerbaijan": 1.0,
      "Belgium": 0.537,
      "Brazil": 0.654,
      "Bulgaria": 0.666,
      "Canada": 0.523,
      "China": 0.737,
      "Colombia": 0.702,
      "Croatia": 0.666,
      "Czechia": 0.675,
      "Denmark": 0.675,
      "Egypt": 0.694,
      "Estonia": 0.514,
      "Finland": 0.675,
      "France": 0.504,
      "Germany": 0.604,
      "Greece": 0.675,
      "Hungary": 0.715,
      "India": 0.805,
      "Iran": 0.797,
      "Iraq": 0.702,
      "Israel": 0.649,
      "Italy": 0.675,
      "Japan": 0.477,
      "Latvia": 0.675,
      "Lithuania": 0.715,
      "Morocco": 0.614,
      "Netherlands": 0.514,
      "New Zealand": 0.595,
      "North Korea": 0.837,
      "Norway": 0.637,
      "Pakistan": 0.555,
      "Poland": 0.675,
      "Russia": 0.779,
      "Singapore": 0.614,
      "South Africa": 0.6,
      "South Korea": 0.626,
      "Spain": 0.675,
      "Sweden": 0.715,
      "Turkey": 0.805,
      "UAE": 0.819,
      "UK": 0.344,
      "USA": 0.384,
      "Ukraine": 0.704
    },
    "Belgium": {
      "Algeria": 0.737,
      "Armenia": 0.878,
      "Australia": 0.532,
      "Azerbaijan": 0.537,
      "Belgium": 1.0,
      "Brazil": 0.797,
      "Bulgaria": 0.777,
      "Canada": 0.669,
      "China": 0.608,
      "Colombia": 0.76,
      "Croatia": 0.777,
      "Czechia": 0.784,
      "Denmark": 0.784,
      "Egypt": 0.689,
      "Estonia": 0.594,
      "Finland": 0.784,
      "France": 0.548,
      "Germany": 0.817,
      "Greece": 0.784,
      "Hungary": 0.744,
      "India": 0.635,
      "Iran": 0.654,
      "Iraq": 0.76,
      "Israel": 0.545,
      "Italy": 0.784,
      "Japan": 0.575,
      "Latvia": 0.784,
      "Lithuania": 0.744,
      "Morocco": 0.8,
      "Netherlands": 0.594,
      "New Zealand": 0.845,
      "North Korea": 0.504,
      "Norway": 0.837,
      "Pakistan": 0.8,
      "Poland": 0.784,
      "Russia": 0.608,
      "Singapore": 0.617,
      "South Africa": 0.72,
      "South Korea": 0.663,
      "Spain": 0.784,
      "Sweden": 0.744,
      "Turkey": 0.635,
      "UAE": 0.623,
      "UK": 0.45,
      "USA": 0.351,
      "Ukraine": 0.706
    },
    "Brazil": {
      "Algeria": 0.777,
      "Armenia": 0.859,
      "Australia": 0.544,
      "Azerbaijan": 0.654,
      "Belgium": 0.797,
      "Brazil": 1.0,
      "Bulgaria": 0.859,
      "Canada": 0.684,
      "China": 0.666,
      "Colombia": 0.837,
      "Croatia": 0.859,
      "Czechia": 0.819,
      "Denmark": 0.819,
      "Egypt": 0.797,
      "Estonia": 0.617,
      "Finland": 0.819,
      "France": 0.584,
      "Germany": 0.777,
      "Greece": 0.819,
      "Hungary": 0.859,
      "India": 0.702,
      "Iran": 0.769,
      "Iraq": 0.837,
      "Israel": 0.604,
      "Italy": 0.819,
      "Japan": 0.594,
      "Latvia": 0.819,
      "Lithuania": 0.859,
      "Morocco": 0.797,
      "Netherlands": 0.617,
      "New Zealand": 0.885,
      "North Korea": 0.633,
      "Norway": 0.845,
      "Pakistan": 0.797,
      "Poland": 0.819,
      "Russia": 0.689,
      "Singapore": 0.654,
      "South Africa": 0.76,
      "South Korea": 0.689,
      "Spain": 0.819,
      "Sweden": 0.859,
      "Turkey": 0.702,
      "UAE": 0.784,
      "UK": 0.453,
      "USA": 0.41,
      "Ukraine": 0.744
    },
    "Bulgaria": {
      "Algeria": 0.76,
      "Armenia": 0.837,
      "Australia": 0.484,
      "Azerbaijan": 0.666,
      "Belgium": 0.777,
      "Brazil": 0.859,
      "Bulgaria": 1.0,
      "Canada": 0.594,
      "China": 0.633,
      "Colombia": 0.918,
      "Croatia": 1.0,
      "Czechia": 0.797,
      "Denmark": 0.797,
      "Egypt": 0.878,
      "Estonia": 0.563,
      "Finland": 0.797,
      "France": 0.517,
      "Germany": 0.729,
      "Greece": 0.797,
      "Hungary": 0.837,
      "India": 0.689,
      "Iran": 0.784,
      "Iraq": 0.918,
      "Israel": 0.56,
      "Italy": 0.797,
      "Japan": 0.508,
      "Latvia": 0.797,
      "Lithuania": 0.837,
      "Morocco": 0.819,
      "Netherlands": 0.563,
      "New Zealand": 0.784,
      "North Korea": 0.689,
      "Norway": 0.777,
      "Pakistan": 0.744,
      "Poland": 0.797,
      "Russia": 0.677,
      "Singapore": 0.586,
      "South Africa": 0.744,
      "South Korea": 0.633,
      "Spain": 0.797,
      "Sweden": 0.837,
      "Turkey": 0.689,
      "UAE": 0.769,
      "UK": 0.377,
      "USA": 0.34,
      "Ukraine": 0.702
    },
    "Canada": {
      "Algeria": 0.477,
      "Armenia": 0.594,
      "Australia": 0.837,
      "Azerbaijan": 0.523,
      "Belgium": 0.669,
      "Brazil": 0.684,
      "Bulgaria": 0.594,
      "Canada": 1.0,
      "China": 0.613,
      "Colombia": 0.584,
      "Croatia": 0.594,
      "Czechia": 0.777,
      "Denmark": 0.777,
      "Egypt": 0.504,
      "Estonia": 0.859,
      "Finland": 0.777,
      "France": 0.837,
      "Germany": 0.825,
      "Greece": 0.777,
      "Hungary": 0.737,
      "India": 0.669,
      "Iran": 0.544,
      "Iraq": 0.584,
      "Israel": 0.682,
      "Italy": 0.777,
      "Japan": 0.859,
      "Latvia": 0.777,
      "Lithuania": 0.737,
      "Morocco": 0.584,
      "Netherlands": 0.859,
      "New Zealand": 0.717,
      "North Korea": 0.436,
      "Norway": 0.799,
      "Pakistan": 0.603,
      "Poland": 0.777,
      "Russia": 0.613,
      "Singapore": 0.799,
      "South Africa": 0.468,
      "South Korea": 0.825,
      "Spain": 0.777,
      "Sweden": 0.737,
      "Turkey": 0.669,
      "UAE": 0.642,
      "UK": 0.729,
      "USA": 0.663,
      "Ukraine": 0.777
    },
    "China": {
      "Algeria": 0.504,
      "Armenia": 0.595,
      "Australia": 0.575,
      "Azerbaijan": 0.737,
      "Belgium": 0.608,
      "Brazil": 0.666,
      "Bulgaria": 0.633,
      "Canada": 0.613,
      "China": 1.0,
      "Colombia": 0.644,
      "Croatia": 0.633,
      "Czechia": 0.742,
      "Denmark": 0.742,
      "Egypt": 0.604,
      "Estonia": 0.624,
      "Finland": 0.742,
      "France": 0.613,
      "Germany": 0.673,
      "Greece": 0.742,
      "Hungary": 0.702,
      "India": 0.859,
      "Iran": 0.744,
      "Iraq": 0.644,
      "Israel": 0.769,
      "Italy": 0.742,
      "Japan": 0.603,
      "Latvia": 0.742,
      "Lithuania": 0.702,
      "Morocco": 0.684,
      "Netherlands": 0.624,
      "New Zealand": 0.604,
      "North Korea": 0.649,
      "Norway": 0.729,
      "Pakistan": 0.663,
      "Poland": 0.742,
      "Russia": 0.885,
      "Singapore": 0.706,
      "South Africa": 0.512,
      "South Korea": 0.717,
      "Spain": 0.742,
      "Sweden": 0.702,
      "Turkey": 0.859,
      "UAE": 0.76,
      "UK": 0.485,
      "USA": 0.516,
      "Ukraine": 0.8
    },
    "Colombia": {
      "Algeria": 0.744,
      "Armenia": 0.817,
      "Australia": 0.476,
      "Azerbaijan": 0.702,
      "Belgium": 0.76,
      "Brazil": 0.837,
      "Bulgaria": 0.918,
      "Canada": 0.584,
      "China": 0.644,
      "Colombia": 1.0,
      "Croatia": 0.918,
      "Czechia": 0.777,
      "Denmark": 0.777,
      "Egypt": 0.845,
      "Estonia": 0.535,
      "Finland": 0.777,
      "France": 0.492,
      "Germany": 0.715,
      "Greece": 0.777,
      "Hungary": 0.817,
      "India": 0.702,
      "Iran": 0.837,
      "Iraq": 1.0,
      "Israel": 0.552,
      "Italy": 0.777,
      "Japan": 0.484,
      "Latvia": 0.777,
      "Lithuania": 0.817,
      "Morocco": 0.845,
      "Netherlands": 0.535,
      "New Zealand": 0.769,
      "North Korea": 0.729,
      "Norway": 0.76,
      "Pakistan": 0.76,
      "Poland": 0.777,
      "Russia": 0.689,
      "Singapore": 0.577,
      "South Africa": 0.76,
      "South Korea": 0.623,
      "Spain": 0.777,
      "Sweden": 0.817,
      "Turkey": 0.702,
      "UAE": 0.784,
      "UK": 0.346,
      "USA": 0.323,
      "Ukraine": 0.689
    },
    "Croatia": {
      "Algeria": 0.76,
      "Armenia": 0.837,
      "Australia": 0.484,
      "Azerbaijan": 0.666,
      "Belgium": 0.777,
      "Brazil": 0.859,
      "Bulgaria": 1.0,
      "Canada": 0.594,
      "China": 0.633,
      "Colombia": 0.918,
      "Croatia": 1.0,
      "Czechia": 0.797,
      "Denmark": 0.797,
      "Egypt": 0.878,
      "Estonia": 0.563,
      "Finland": 0.797,
      "France": 0.517,
      "Germany": 0.729,
      "Greece": 0.797,
      "Hungary": 0.837,
      "India": 0.689,
      "Iran": 0.784,
      "Iraq": 0.918,
      "Israel": 0.56,
      "Italy": 0.797,
      "Japan": 0.508,
      "Latvia": 0.797,
      "Lithuania": 0.837,
      "Morocco": 0.819,
      "Netherlands": 0.563,
      "New Zealand": 0.784,
      "North Korea": 0.689,
      "Norway": 0.777,
      "Pakistan": 0.744,
      "Poland": 0.797,
      "Russia": 0.677,
      "Singapore": 0.586,
      "South Africa": 0.744,
      "South Korea": 0.633,
      "Spain": 0.797,
      "Sweden": 0.837,
      "Turkey": 0.689,
      "UAE": 0.769,
      "UK": 0.377,
      "USA": 0.34,
      "Ukraine": 0.702
    },
    "Czechia": {
      "Algeria": 0.614,
      "Armenia": 0.729,
      "Australia": 0.682,
      "Azerbaijan": 0.675,
      "Belgium": 0.784,
      "Brazil": 0.819,
      "Bulgaria": 0.797,
      "Canada": 0.777,
      "China": 0.742,
      "Colombia": 0.777,
      "Croatia": 0.797,
      "Czechia": 1.0,
      "Denmark": 1.0,
      "Egypt": 0.704,
      "Estonia": 0.757,
      "Finland": 1.0,
      "France": 0.709,
      "Germany": 0.885,
      "Greece": 1.0,
      "Hungary": 0.96,
      "India": 0.817,
      "Iran": 0.715,
      "Iraq": 0.777,
      "Israel": 0.742,
      "Italy": 1.0,
      "Japan": 0.695,
      "Latvia": 1.0,
      "Lithuania": 0.96,
      "Morocco": 0.755,
      "Netherlands": 0.757,
      "New Zealand": 0.777,
      "North Korea": 0.626,
      "Norway": 0.918,
      "Pakistan": 0.729,
      "Poland": 1.0,
      "Russia": 0.769,
      "Singapore": 0.784,
      "South Africa": 0.604,
      "South Korea": 0.837,
      "Spain": 1.0,
      "Sweden": 0.96,
      "Turkey": 0.817,
      "UAE": 0.797,
      "UK": 0.566,
      "USA": 0.532,
      "Ukraine": 0.885
    },
    "Denmark": {
      "Algeria": 0.614,
      "Armenia": 0.729,
      "Australia": 0.682,
      "Azerbaijan": 0.675,
      "Belgium": 0.784,
      "Brazil": 0.819,
      "Bulgaria": 0.797,
      "Canada": 0.777,
      "China": 0.742,
      "Colombia": 0.777,
      "Croatia": 0.797,
      "Czechia": 1.0,
      "Denmark": 1.0,
      "Egypt": 0.704,
      "Estonia": 0.757,
      "Finland": 1.0,
      "France": 0.709,
      "Germany": 0.885,
      "Greece": 1.0,
      "Hungary": 0.96,
      "India": 0.817,
      "Iran": 0.715,
      "Iraq": 0.777,
      "Israel": 0.742,
      "Italy": 1.0,
      "Japan": 0.695,
      "Latvia": 1.0,
      "Lithuania": 0.96,
      "Morocco": 0.755,
      "Netherlands": 0.757,
      "New Zealand": 0.777,
      "North Korea": 0.626,
      "Norway": 0.918,
      "Pakistan": 0.729,
      "Poland": 1.0,
      "Russia": 0.769,
      "Singapore": 0.784,
      "South Africa": 0.604,
      "South Korea": 0.837,
      "Spain": 1.0,
      "Sweden": 0.96,
      "Turkey": 0.817,
      "UAE": 0.797,
      "UK": 0.566,
      "USA": 0.532,
      "Ukraine": 0.885
    },
    "Egypt": {
      "Algeria": 0.817,
      "Armenia": 0.777,
      "Australia": 0.391,
      "Azerbaijan": 0.694,
      "Belgium": 0.689,
      "Brazil": 0.797,
      "Bulgaria": 0.878,
      "Canada": 0.504,
      "China": 0.604,
      "Colombia": 0.845,
      "Croatia": 0.878,
      "Czechia": 0.704,
      "Denmark": 0.704,
      "Egypt": 1.0,
      "Estonia": 0.477,
      "Finland": 0.704,
      "France": 0.436,
      "Germany": 0.626,
      "Greece": 0.704,
      "Hungary": 0.744,
      "India": 0.637,
      "Iran": 0.76,
      "Iraq": 0.845,
      "Israel": 0.496,
      "Italy": 0.704,
      "Japan": 0.428,
      "Latvia": 0.704,
      "Lithuania": 0.744,
      "Morocco": 0.805,
      "Netherlands": 0.477,
      "New Zealand": 0.702,
      "North Korea": 0.742,
      "Norway": 0.689,
      "Pakistan": 0.72,
      "Poland": 0.704,
      "Russia": 0.649,
      "Singapore": 0.504,
      "South Africa": 0.8,
      "South Korea": 0.546,
      "Spain": 0.704,
      "Sweden": 0.744,
      "Turkey": 0.637,
      "UAE": 0.715,
      "UK": 0.294,
      "USA": 0.271,
      "Ukraine": 0.626
    },
    "Estonia": {
      "Algeria": 0.405,
      "Armenia": 0.526,
      "Australia": 0.859,
      "Azerbaijan": 0.514,
      "Belgium": 0.594,
      "Brazil": 0.617,
      "Bulgaria": 0.563,
      "Canada": 0.859,
      "China": 0.624,
      "Colombia": 0.535,
      "Croatia": 0.563,
      "Czechia": 0.757,
      "Denmark": 0.757,
      "Egypt": 0.477,
      "Estonia": 1.0,
      "Finland": 0.757,
      "France": 0.918,
      "Germany": 0.757,
      "Greece": 0.757,
      "Hungary": 0.717,
      "India": 0.682,
      "Iran": 0.5,
      "Iraq": 0.535,
      "Israel": 0.757,
      "Italy": 0.757,
      "Japan": 0.885,
      "Latvia": 0.757,
      "Lithuania": 0.717,
      "Morocco": 0.524,
      "Netherlands": 1.0,
      "New Zealand": 0.617,
      "North Korea": 0.428,
      "Norway": 0.74,
      "Pakistan": 0.524,
      "Poland": 0.757,
      "Russia": 0.624,
      "Singapore": 0.825,
      "South Africa": 0.384,
      "South Korea": 0.858,
      "Spain": 0.757,
      "Sweden": 0.717,
      "Turkey": 0.682,
      "UAE": 0.629,
      "UK": 0.8,
      "USA": 0.742,
      "Ukraine": 0.799
    },
    "Finland": {
      "Algeria": 0.614,
      "Armenia": 0.729,
      "Australia": 0.682,
      "Azerbaijan": 0.675,
      "Belgium": 0.784,
      "Brazil": 0.819,
      "Bulgaria": 0.797,
      "Canada": 0.777,
      "China": 0.742,
      "Colombia": 0.777,
      "Croatia": 0.797,
      "Czechia": 1.0,
      "Denmark": 1.0,
      "Egypt": 0.704,
      "Estonia": 0.757,
      "Finland": 1.0,
      "France": 0.709,
      "Germany": 0.885,
      "Greece": 1.0,
      "Hungary": 0.96,
      "India": 0.817,
      "Iran": 0.715,
      "Iraq": 0.777,
      "Israel": 0.742,
      "Italy": 1.0,
      "Japan": 0.695,
      "Latvia": 1.0,
      "Lithuania": 0.96,
      "Morocco": 0.755,
      "Netherlands": 0.757,
      "New Zealand": 0.777,
      "North Korea": 0.626,
      "Norway": 0.918,
      "Pakistan": 0.729,
      "Poland": 1.0,
      "Russia": 0.769,
      "Singapore": 0.784,
      "South Africa": 0.604,
      "South Korea": 0.837,
      "Spain": 1.0,
      "Sweden": 0.96,
      "Turkey": 0.817,
      "UAE": 0.797,
      "UK": 0.566,
      "USA": 0.532,
      "Ukraine": 0.885
    },
    "France": {
      "Algeria": 0.37,
      "Armenia": 0.484,
      "Australia": 0.885,
      "Azerbaijan": 0.504,
      "Belgium": 0.548,
      "Brazil": 0.584,
      "Bulgaria": 0.517,
      "Canada": 0.837,
      "China": 0.613,
      "Colombia": 0.492,
      "Croatia": 0.517,
      "Czechia": 0.709,
      "Denmark": 0.709,
      "Egypt": 0.436,
      "Estonia": 0.918,
      "Finland": 0.709,
      "France": 1.0,
      "Germany": 0.709,
      "Greece": 0.709,
      "Hungary": 0.669,
      "India": 0.669,
      "Iran": 0.476,
      "Iraq": 0.492,
      "Israel": 0.777,
      "Italy": 0.709,
      "Japan": 0.918,
      "Latvia": 0.709,
      "Lithuania": 0.669,
      "Morocco": 0.485,
      "Netherlands": 0.918,
      "New Zealand": 0.584,
      "North Korea": 0.405,
      "Norway": 0.695,
      "Pakistan": 0.485,
      "Poland": 0.709,
      "Russia": 0.613,
      "Singapore": 0.858,
      "South Africa": 0.35,
      "South Korea": 0.825,
      "Spain": 0.709,
      "Sweden": 0.669,
      "Turkey": 0.669,
      "UAE": 0.617,
      "UK": 0.817,
      "USA": 0.784,
      "Ukraine": 0.777
    },
    "Germany": {
      "Algeria": 0.593,
      "Armenia": 0.729,
      "Australia": 0.709,
      "Azerbaijan": 0.604,
      "Belgium": 0.817,
      "Brazil": 0.777,
      "Bulgaria": 0.729,
      "Canada": 0.825,
      "China": 0.673,
      "Colombia": 0.715,
      "Croatia": 0.729,
      "Czechia": 0.885,
      "Denmark": 0.885,
      "Egypt": 0.626,
      "Estonia": 0.757,
      "Finland": 0.885,
      "France": 0.709,
      "Germany": 1.0,
      "Greece": 0.885,
      "Hungary": 0.845,
      "India": 0.729,
      "Iran": 0.644,
      "Iraq": 0.715,
      "Israel": 0.694,
      "Italy": 0.885,
      "Japan": 0.724,
      "Latvia": 0.885,
      "Lithuania": 0.845,
      "Morocco": 0.706,
      "Netherlands": 0.757,
      "New Zealand": 0.819,
      "North Korea": 0.528,
      "Norway": 0.918,
      "Pakistan": 0.706,
      "Poland": 0.885,
      "Russia": 0.673,
      "Singapore": 0.784,
      "South Africa": 0.583,
      "South Korea": 0.837,
      "Spain": 0.885,
      "Sweden": 0.845,
      "Turkey": 0.729,
      "UAE": 0.702,
      "UK": 0.603,
      "USA": 0.516,
      "Ukraine": 0.837
    },
    "Greece": {
      "Algeria": 0.614,
      "Armenia": 0.729,
      "Australia": 0.682,
      "Azerbaijan": 0.675,
      "Belgium": 0.784,
      "Brazil": 0.819,
      "Bulgaria": 0.797,
      "Canada": 0.777,
      "China": 0.742,
      "Colombia": 0.777,
      "Croatia": 0.797,
      "Czechia": 1.0,
      "Denmark": 1.0,
      "Egypt": 0.704,
      "Estonia": 0.757,
      "Finland": 1.0,
      "France": 0.709,
      "Germany": 0.885,
      "Greece": 1.0,
      "Hungary": 0.96,
      "India": 0.817,
      "Iran": 0.715,
      "Iraq": 0.777,
      "Israel": 0.742,
      "Italy": 1.0,
      "Japan": 0.695,
      "Latvia": 1.0,
      "Lithuania": 0.96,
      "Morocco": 0.755,
      "Netherlands": 0.757,
      "New Zealand": 0.777,
      "North Korea": 0.626,
      "Norway": 0.918,
      "Pakistan": 0.729,
      "Poland": 1.0,
      "Russia": 0.769,
      "Singapore": 0.784,
      "South Africa": 0.604,
      "South Korea": 0.837,
      "Spain": 1.0,
      "Sweden": 0.96,
      "Turkey": 0.817,
      "UAE": 0.797,
      "UK": 0.566,
      "USA": 0.532,
      "Ukraine": 0.885
    },
    "Hungary": {
      "Algeria": 0.654,
      "Armenia": 0.769,
      "Australia": 0.642,
      "Azerbaijan": 0.715,
      "Belgium": 0.744,
      "Brazil": 0.859,
      "Bulgaria": 0.837,
      "Canada": 0.737,
      "China": 0.702,
      "Colombia": 0.817,
      "Croatia": 0.837,
      "Czechia": 0.96,
      "Denmark": 0.96,
      "Egypt": 0.744,
      "Estonia": 0.717,
      "Finland": 0.96,
      "France": 0.669,
      "Germany": 0.845,
      "Greece": 0.96,
      "Hungary": 1.0,
      "India": 0.777,
      "Iran": 0.755,
      "Iraq": 0.817,
      "Israel": 0.702,
      "Italy": 0.96,
      "Japan": 0.655,
      "Latvia": 0.96,
      "Lithuania": 1.0,
      "Morocco": 0.715,
      "Netherlands": 0.717,
      "New Zealand": 0.817,
      "North Korea": 0.666,
      "Norway": 0.878,
      "Pakistan": 0.689,
      "Poland": 0.96,
      "Russia": 0.729,
      "Singapore": 0.744,
      "South Africa": 0.644,
      "South Korea": 0.797,
      "Spain": 0.96,
      "Sweden": 1.0,
      "Turkey": 0.777,
      "UAE": 0.837,
      "UK": 0.526,
      "USA": 0.492,
      "Ukraine": 0.845
    },
    "India": {
      "Algeria": 0.512,
      "Armenia": 0.604,
      "Australia": 0.646,
      "Azerbaijan": 0.805,
      "Belgium": 0.635,
      "Brazil": 0.702,
      "Bulgaria": 0.689,
      "Canada": 0.669,
      "China": 0.859,
      "Colombia": 0.702,
      "Croatia": 0.689,
      "Czechia": 0.817,
      "Denmark": 0.817,
      "Egypt": 0.637,
      "Estonia": 0.682,
      "Finland": 0.817,
      "France": 0.669,
      "Germany": 0.729,
      "Greece": 0.817,
      "Hungary": 0.777,
      "India": 1.0,
      "Iran": 0.76,
      "Iraq": 0.702,
      "Israel": 0.817,
      "Italy": 0.817,
      "Japan": 0.634,
      "Latvia": 0.817,
      "Lithuania": 0.777,
      "Morocco": 0.694,
      "Netherlands": 0.682,
      "New Zealand": 0.633,
      "North Korea": 0.72,
      "Norway": 0.769,
      "Pakistan": 0.654,
      "Poland": 0.817,
      "Russia": 0.918,
      "Singapore": 0.769,
      "South Africa": 0.52,
      "South Korea": 0.784,
      "Spain": 0.817,
      "Sweden": 0.777,
      "Turkey": 1.0,
      "UAE": 0.878,
      "UK": 0.508,
      "USA": 0.557,
      "Ukraine": 0.859
    },
    "Iran": {
      "Algeria": 0.666,
      "Armenia": 0.729,
      "Australia": 0.46,
      "Azerbaijan": 0.797,
      "Belgium": 0.654,
      "Brazil": 0.769,
      "Bulgaria": 0.784,
      "Canada": 0.544,
      "China": 0.744,
      "Colombia": 0.837,
      "Croatia": 0.784,
      "Czechia": 0.715,
      "Denmark": 0.715,
      "Egypt": 0.76,
      "Estonia": 0.5,
      "Finland": 0.715,
      "France": 0.476,
      "Germany": 0.644,
      "Greece": 0.715,
      "Hungary": 0.755,
      "India": 0.76,
      "Iran": 1.0,
      "Iraq": 0.837,
      "Israel": 0.586,
      "Italy": 0.715,
      "Japan": 0.468,
      "Latvia": 0.715,
      "Lithuania": 0.755,
      "Morocco": 0.797,
      "Netherlands": 0.5,
      "New Zealand": 0.694,
      "North Korea": 0.797,
      "Norway": 0.702,
      "Pakistan": 0.729,
      "Poland": 0.715,
      "Russia": 0.777,
      "Singapore": 0.577,
      "South Africa": 0.702,
      "South Korea": 0.604,
      "Spain": 0.715,
      "Sweden": 0.755,
      "Turkey": 0.76,
      "UAE": 0.817,
      "UK": 0.323,
      "USA": 0.334,
      "Ukraine": 0.689
    },
    "Iraq": {
      "Algeria": 0.744,
      "Armenia": 0.817,
      "Australia": 0.476,
      "Azerbaijan": 0.702,
      "Belgium": 0.76,
      "Brazil": 0.837,
      "Bulgaria": 0.918,
      "Canada": 0.584,
      "China": 0.644,
      "Colombia": 1.0,
      "Croatia": 0.918,
      "Czechia": 0.777,
      "Denmark": 0.777,
      "Egypt": 0.845,
      "Estonia": 0.535,
      "Finland": 0.777,
      "France": 0.492,
      "Germany": 0.715,
      "Greece": 0.777,
      "Hungary": 0.817,
      "India": 0.702,
      "Iran": 0.837,
      "Iraq": 1.0,
      "Israel": 0.552,
      "Italy": 0.777,
      "Japan": 0.484,
      "Latvia": 0.777,
      "Lithuania": 0.817,
      "Morocco": 0.845,
      "Netherlands": 0.535,
      "New Zealand": 0.769,
      "North Korea": 0.729,
      "Norway": 0.76,
      "Pakistan": 0.76,
      "Poland": 0.777,
      "Russia": 0.689,
      "Singapore": 0.577,
      "South Africa": 0.76,
      "South Korea": 0.623,
      "Spain": 0.777,
      "Sweden": 0.817,
      "Turkey": 0.702,
      "UAE": 0.784,
      "UK": 0.346,
      "USA": 0.323,
      "Ukraine": 0.689
    },
    "Israel": {
      "Algeria": 0.391,
      "Armenia": 0.498,
      "Australia": 0.74,
      "Azerbaijan": 0.649,
      "Belgium": 0.545,
      "Brazil": 0.604,
      "Bulgaria": 0.56,
      "Canada": 0.682,
      "China": 0.769,
      "Colombia": 0.552,
      "Croatia": 0.56,
      "Czechia": 0.742,
      "Denmark": 0.742,
      "Egypt": 0.496,
      "Estonia": 0.757,
      "Finland": 0.742,
      "France": 0.777,
      "Germany": 0.694,
      "Greece": 0.742,
      "Hungary": 0.702,
      "India": 0.817,
      "Iran": 0.586,
      "Iraq": 0.552,
      "Israel": 1.0,
      "Italy": 0.742,
      "Japan": 0.724,
      "Latvia": 0.742,
      "Lithuania": 0.702,
      "Morocco": 0.545,
      "Netherlands": 0.757,
      "New Zealand": 0.568,
      "North Korea": 0.546,
      "Norway": 0.706,
      "Pakistan": 0.531,
      "Poland": 0.742,
      "Russia": 0.769,
      "Singapore": 0.859,
      "South Africa": 0.385,
      "South Korea": 0.837,
      "Spain": 0.742,
      "Sweden": 0.702,
      "Turkey": 0.817,
      "UAE": 0.729,
      "UK": 0.646,
      "USA": 0.724,
      "Ukraine": 0.837
    },
    "Italy": {
      "Algeria": 0.614,
      "Armenia": 0.729,
      "Australia": 0.682,
      "Azerbaijan": 0.675,
      "Belgium": 0.784,
      "Brazil": 0.819,
      "Bulgaria": 0.797,
      "Canada": 0.777,
      "China": 0.742,
      "Colombia": 0.777,
      "Croatia": 0.797,
      "Czechia": 1.0,
      "Denmark": 1.0,
      "Egypt": 0.704,
      "Estonia": 0.757,
      "Finland": 1.0,
      "France": 0.709,
      "Germany": 0.885,
      "Greece": 1.0,
      "Hungary": 0.96,
      "India": 0.817,
      "Iran": 0.715,
      "Iraq": 0.777,
      "Israel": 0.742,
      "Italy": 1.0,
      "Japan": 0.695,
      "Latvia": 1.0,
      "Lithuania": 0.96,
      "Morocco": 0.755,
      "Netherlands": 0.757,
      "New Zealand": 0.777,
      "North Korea": 0.626,
      "Norway": 0.918,
      "Pakistan": 0.729,
      "Poland": 1.0,
      "Russia": 0.769,
      "Singapore": 0.784,
      "South Africa": 0.604,
      "South Korea": 0.837,
      "Spain": 1.0,
      "Sweden": 0.96,
      "Turkey": 0.817,
      "UAE": 0.797,
      "UK": 0.566,
      "USA": 0.532,
      "Ukraine": 0.885
    },
    "Japan": {
      "Algeria": 0.391,
      "Armenia": 0.508,
      "Australia": 0.859,
      "Azerbaijan": 0.477,
      "Belgium": 0.575,
      "Brazil": 0.594,
      "Bulgaria": 0.508,
      "Canada": 0.859,
      "China": 0.603,
      "Colombia": 0.484,
      "Croatia": 0.508,
      "Czechia": 0.695,
      "Denmark": 0.695,
      "Egypt": 0.428,
      "Estonia": 0.885,
      "Finland": 0.695,
      "France": 0.918,
      "Germany": 0.724,
      "Greece": 0.695,
      "Hungary": 0.655,
      "India": 0.634,
      "Iran": 0.468,
      "Iraq": 0.484,
      "Israel": 0.724,
      "Italy": 0.695,
      "Japan": 1.0,
      "Latvia": 0.695,
      "Lithuania": 0.655,
      "Morocco": 0.493,
      "Netherlands": 0.885,
      "New Zealand": 0.617,
      "North Korea": 0.37,
      "Norway": 0.709,
      "Pakistan": 0.508,
      "Poland": 0.695,
      "Russia": 0.584,
      "Singapore": 0.825,
      "South Africa": 0.37,
      "South Korea": 0.799,
      "Spain": 0.695,
      "Sweden": 0.655,
      "Turkey": 0.634,
      "UAE": 0.584,
      "UK": 0.837,
      "USA": 0.742,
      "Ukraine": 0.757
    },
    "Latvia": {
      "Algeria": 0.614,
      "Armenia": 0.729,
      "Australia": 0.682,
      "Azerbaijan": 0.675,
      "Belgium": 0.784,
      "Brazil": 0.819,
      "Bulgaria": 0.797,
      "Canada": 0.777,
      "China": 0.742,
      "Colombia": 0.777,
      "Croatia": 0.797,
      "Czechia": 1.0,
      "Denmark": 1.0,
      "Egypt": 0.704,
      "Estonia": 0.757,
      "Finland": 1.0,
      "France": 0.709,
      "Germany": 0.885,
      "Greece": 1.0,
      "Hungary": 0.96,
      "India": 0.817,
      "Iran": 0.715,
      "Iraq": 0.777,
      "Israel": 0.742,
      "Italy": 1.0,
      "Japan": 0.695,
      "Latvia": 1.0,
      "Lithuania": 0.96,
      "Morocco": 0.755,
      "Netherlands": 0.757,
      "New Zealand": 0.777,
      "North Korea": 0.626,
      "Norway": 0.918,
      "Pakistan": 0.729,
      "Poland": 1.0,
      "Russia": 0.769,
      "Singapore": 0.784,
      "South Africa": 0.604,
      "South Korea": 0.837,
      "Spain": 1.0,
      "Sweden": 0.96,
      "Turkey": 0.817,
      "UAE": 0.797,
      "UK": 0.566,
      "USA": 0.532,
      "Ukraine": 0.885
    },
    "Lithuania": {
      "Algeria": 0.654,
      "Armenia": 0.769,
      "Australia": 0.642,
      "Azerbaijan": 0.715,
      "Belgium": 0.744,
      "Brazil": 0.859,
      "Bulgaria": 0.837,
      "Canada": 0.737,
      "China": 0.702,
      "Colombia": 0.817,
      "Croatia": 0.837,
      "Czechia": 0.96,
      "Denmark": 0.96,
      "Egypt": 0.744,
      "Estonia": 0.717,
      "Finland": 0.96,
      "France": 0.669,
      "Germany": 0.845,
      "Greece": 0.96,
      "Hungary": 1.0,
      "India": 0.777,
      "Iran": 0.755,
      "Iraq": 0.817,
      "Israel": 0.702,
      "Italy": 0.96,
      "Japan": 0.655,
      "Latvia": 0.96,
      "Lithuania": 1.0,
      "Morocco": 0.715,
      "Netherlands": 0.717,
      "New Zealand": 0.817,
      "North Korea": 0.666,
      "Norway": 0.878,
      "Pakistan": 0.689,
      "Poland": 0.96,
      "Russia": 0.729,
      "Singapore": 0.744,
      "South Africa": 0.644,
      "South Korea": 0.797,
      "Spain": 0.96,
      "Sweden": 1.0,
      "Turkey": 0.777,
      "UAE": 0.837,
      "UK": 0.526,
      "USA": 0.492,
      "Ukraine": 0.845
    },
    "Morocco": {
      "Algeria": 0.779,
      "Armenia": 0.819,
      "Australia": 0.457,
      "Azerbaijan": 0.614,
      "Belgium": 0.8,
      "Brazil": 0.797,
      "Bulgaria": 0.819,
      "Canada": 0.584,
      "China": 0.684,
      "Colombia": 0.845,
      "Croatia": 0.819,
      "Czechia": 0.755,
      "Denmark": 0.755,
      "Egypt": 0.805,
      "Estonia": 0.524,
      "Finland": 0.755,
      "France": 0.485,
      "Germany": 0.706,
      "Greece": 0.755,
      "Hungary": 0.715,
      "India": 0.694,
      "Iran": 0.797,
      "Iraq": 0.845,
      "Israel": 0.545,
      "Italy": 0.755,
      "Japan": 0.493,
      "Latvia": 0.755,
      "Lithuania": 0.715,
      "Morocco": 1.0,
      "Netherlands": 0.524,
      "New Zealand": 0.729,
      "North Korea": 0.637,
      "Norway": 0.769,
      "Pakistan": 0.885,
      "Poland": 0.755,
      "Russia": 0.706,
      "Singapore": 0.568,
      "South Africa": 0.805,
      "South Korea": 0.608,
      "Spain": 0.755,
      "Sweden": 0.715,
      "Turkey": 0.694,
      "UAE": 0.689,
      "UK": 0.351,
      "USA": 0.318,
      "Ukraine": 0.684
    },
    "Netherlands": {
      "Algeria": 0.405,
      "Armenia": 0.526,
      "Australia": 0.859,
      "Azerbaijan": 0.514,
      "Belgium": 0.594,
      "Brazil": 0.617,
      "Bulgaria": 0.563,
      "Canada": 0.859,
      "China": 0.624,
      "Colombia": 0.535,
      "Croatia": 0.563,
      "Czechia": 0.757,
      "Denmark": 0.757,
      "Egypt": 0.477,
      "Estonia": 1.0,
      "Finland": 0.757,
      "France": 0.918,
      "Germany": 0.757,
      "Greece": 0.757,
      "Hungary": 0.717,
      "India": 0.682,
      "Iran": 0.5,
      "Iraq": 0.535,
      "Israel": 0.757,
      "Italy": 0.757,
      "Japan": 0.885,
      "Latvia": 0.757,
      "Lithuania": 0.717,
      "Morocco": 0.524,
      "Netherlands": 1.0,
      "New Zealand": 0.617,
      "North Korea": 0.428,
      "Norway": 0.74,
      "Pakistan": 0.524,
      "Poland": 0.757,
      "Russia": 0.624,
      "Singapore": 0.825,
      "South Africa": 0.384,
      "South Korea": 0.858,
      "Spain": 0.757,
      "Sweden": 0.717,
      "Turkey": 0.682,
      "UAE": 0.629,
      "UK": 0.8,
      "USA": 0.742,
      "Ukraine": 0.799
    },
    "New Zealand": {
      "Algeria": 0.744,
      "Armenia": 0.859,
      "Australia": 0.563,
      "Azerbaijan": 0.595,
      "Belgium": 0.845,
      "Brazil": 0.885,
      "Bulgaria": 0.784,
      "Canada": 0.717,
      "China": 0.604,
      "Colombia": 0.769,
      "Croatia": 0.784,
      "Czechia": 0.777,
      "Denmark": 0.777,
      "Egypt": 0.702,
      "Estonia": 0.617,
      "Finland": 0.777,
      "France": 0.584,
      "Germany": 0.819,
      "Greece": 0.777,
      "Hungary": 0.817,
      "India": 0.633,
      "Iran": 0.694,
      "Iraq": 0.769,
      "Israel": 0.568,
      "Italy": 0.777,
      "Japan": 0.617,
      "Latvia": 0.777,
      "Lithuania": 0.817,
      "Morocco": 0.729,
      "Netherlands": 0.617,
      "New Zealand": 1.0,
      "North Korea": 0.544,
      "Norway": 0.845,
      "Pakistan": 0.76,
      "Poland": 0.777,
      "Russia": 0.604,
      "Singapore": 0.654,
      "South Africa": 0.729,
      "South Korea": 0.689,
      "Spain": 0.777,
      "Sweden": 0.817,
      "Turkey": 0.633,
      "UAE": 0.706,
      "UK": 0.484,
      "USA": 0.397,
      "Ukraine": 0.715
    },
    "North Korea": {
      "Algeria": 0.592,
      "Armenia": 0.568,
      "Australia": 0.391,
      "Azerbaijan": 0.837,
      "Belgium": 0.504,
      "Brazil": 0.633,
      "Bulgaria": 0.689,
      "Canada": 0.436,
      "China": 0.649,
      "Colombia": 0.729,
      "Croatia": 0.689,
      "Czechia": 0.626,
      "Denmark": 0.626,
      "Egypt": 0.742,
      "Estonia": 0.428,
      "Finland": 0.626,
      "France": 0.405,
      "Germany": 0.528,
      "Greece": 0.626,
      "Hungary": 0.666,
      "India": 0.72,
      "Iran": 0.797,
      "Iraq": 0.729,
      "Israel": 0.546,
      "Italy": 0.626,
      "Japan": 0.37,
      "Latvia": 0.626,
      "Lithuania": 0.666,
      "Morocco": 0.637,
      "Netherlands": 0.428,
      "New Zealand": 0.544,
      "North Korea": 1.0,
      "Norway": 0.574,
      "Pakistan": 0.555,
      "Poland": 0.626,
      "Russia": 0.737,
      "Singapore": 0.504,
      "South Africa": 0.617,
      "South Korea": 0.528,
      "Spain": 0.626,
      "Sweden": 0.666,
      "Turkey": 0.72,
      "UAE": 0.777,
      "UK": 0.238,
      "USA": 0.294,
      "Ukraine": 0.604
    },
    "Norway": {
      "Algeria": 0.649,
      "Armenia": 0.777,
      "Australia": 0.669,
      "Azerbaijan": 0.637,
      "Belgium": 0.837,
      "Brazil": 0.845,
      "Bulgaria": 0.777,
      "Canada": 0.799,
      "China": 0.729,
      "Colombia": 0.76,
      "Croatia": 0.777,
      "Czechia": 0.918,
      "Denmark": 0.918,
      "Egypt": 0.689,
      "Estonia": 0.74,
      "Finland": 0.918,
      "France": 0.695,
      "Germany": 0.918,
      "Greece": 0.918,
      "Hungary": 0.878,
      "India": 0.769,
      "Iran": 0.702,
      "Iraq": 0.76,
      "Israel": 0.706,
      "Italy": 0.918,
      "Japan": 0.709,
      "Latvia": 0.918,
      "Lithuania": 0.878,
      "Morocco": 0.769,
      "Netherlands": 0.74,
      "New Zealand": 0.845,
      "North Korea": 0.574,
      "Norway": 1.0,
      "Pakistan": 0.769,
      "Poland": 0.918,
      "Russia": 0.729,
      "Singapore": 0.769,
      "South Africa": 0.637,
      "South Korea": 0.817,
      "Spain": 0.918,
      "Sweden": 0.878,
      "Turkey": 0.769,
      "UAE": 0.744,
      "UK": 0.575,
      "USA": 0.508,
      "Ukraine": 0.859
    },
    "Pakistan": {
      "Algeria": 0.779,
      "Armenia": 0.819,
      "Australia": 0.457,
      "Azerbaijan": 0.555,
      "Belgium": 0.8,
      "Brazil": 0.797,
      "Bulgaria": 0.744,
      "Canada": 0.603,
      "China": 0.663,
      "Colombia": 0.76,
      "Croatia": 0.744,
      "Czechia": 0.729,
      "Denmark": 0.729,
      "Egypt": 0.72,
      "Estonia": 0.524,
      "Finland": 0.729,
      "France": 0.485,
      "Germany": 0.706,
      "Greece": 0.729,
      "Hungary": 0.689,
      "India": 0.654,
      "Iran": 0.729,
      "Iraq": 0.76,
      "Israel": 0.531,
      "Italy": 0.729,
      "Japan": 0.508,
      "Latvia": 0.729,
      "Lithuania": 0.689,
      "Morocco": 0.885,
      "Netherlands": 0.524,
      "New Zealand": 0.76,
      "North Korea": 0.555,
      "Norway": 0.769,
      "Pakistan": 1.0,
      "Poland": 0.729,
      "Russia": 0.663,
      "Singapore": 0.568,
      "South Africa": 0.805,
      "South Korea": 0.608,
      "Spain": 0.729,
      "Sweden": 0.689,
      "Turkey": 0.654,
      "UAE": 0.644,
      "UK": 0.374,
      "USA": 0.329,
      "Ukraine": 0.663
    },
    "Poland": {
      "Algeria": 0.614,
      "Armenia": 0.729,
      "Australia": 0.682,
      "Azerbaijan": 0.675,
      "Belgium": 0.784,
      "Brazil": 0.819,
      "Bulgaria": 0.797,
      "Canada": 0.777,
      "China": 0.742,
      "Colombia": 0.777,
      "Croatia": 0.797,
      "Czechia": 1.0,
      "Denmark": 1.0,
      "Egypt": 0.704,
      "Estonia": 0.757,
      "Finland": 1.0,
      "France": 0.709,
      "Germany": 0.885,
      "Greece": 1.0,
      "Hungary": 0.96,
      "India": 0.817,
      "Iran": 0.715,
      "Iraq": 0.777,
      "Israel": 0.742,
      "Italy": 1.0,
      "Japan": 0.695,
      "Latvia": 1.0,
      "Lithuania": 0.96,
      "Morocco": 0.755,
      "Netherlands": 0.757,
      "New Zealand": 0.777,
      "North Korea": 0.626,
      "Norway": 0.918,
      "Pakistan": 0.729,
      "Poland": 1.0,
      "Russia": 0.769,
      "Singapore": 0.784,
      "South Africa": 0.604,
      "South Korea": 0.837,
      "Spain": 1.0,
      "Sweden": 0.96,
      "Turkey": 0.817,
      "UAE": 0.797,
      "UK": 0.566,
      "USA": 0.532,
      "Ukraine": 0.885
    },
    "Russia": {
      "Algeria": 0.52,
      "Armenia": 0.595,
      "Australia": 0.575,
      "Azerbaijan": 0.779,
      "Belgium": 0.608,
      "Brazil": 0.689,
      "Bulgaria": 0.677,
      "Canada": 0.613,
      "China": 0.885,
      "Colombia": 0.689,
      "Croatia": 0.677,
      "Czechia": 0.769,
      "Denmark": 0.769,
      "Egypt": 0.649,
      "Estonia": 0.624,
      "Finland": 0.769,
      "France": 0.613,
      "Germany": 0.673,
      "Greece": 0.769,
      "Hungary": 0.729,
      "India": 0.918,
      "Iran": 0.777,
      "Iraq": 0.689,
      "Israel": 0.769,
      "Italy": 0.769,
      "Japan": 0.584,
      "Latvia": 0.769,
      "Lithuania": 0.729,
      "Morocco": 0.706,
      "Netherlands": 0.624,
      "New Zealand": 0.604,
      "North Korea": 0.737,
      "Norway": 0.729,
      "Pakistan": 0.663,
      "Poland": 0.769,
      "Russia": 1.0,
      "Singapore": 0.706,
      "South Africa": 0.528,
      "South Korea": 0.717,
      "Spain": 0.769,
      "Sweden": 0.729,
      "Turkey": 0.918,
      "UAE": 0.845,
      "UK": 0.457,
      "USA": 0.516,
      "Ukraine": 0.8
    },
    "Singapore": {
      "Algeria": 0.437,
      "Armenia": 0.552,
      "Australia": 0.858,
      "Azerbaijan": 0.614,
      "Belgium": 0.617,
      "Brazil": 0.654,
      "Bulgaria": 0.586,
      "Canada": 0.799,
      "China": 0.706,
      "Colombia": 0.577,
      "Croatia": 0.586,
      "Czechia": 0.784,
      "Denmark": 0.784,
      "Egypt": 0.504,
      "Estonia": 0.825,
      "Finland": 0.784,
      "France": 0.858,
      "Germany": 0.784,
      "Greece": 0.784,
      "Hungary": 0.744,
      "India": 0.769,
      "Iran": 0.577,
      "Iraq": 0.577,
      "Israel": 0.859,
      "Italy": 0.784,
      "Japan": 0.825,
      "Latvia": 0.784,
      "Lithuania": 0.744,
      "Morocco": 0.568,
      "Netherlands": 0.825,
      "New Zealand": 0.654,
      "North Korea": 0.504,
      "Norway": 0.769,
      "Pakistan": 0.568,
      "Poland": 0.784,
      "Russia": 0.706,
      "Singapore": 1.0,
      "South Africa": 0.43,
      "South Korea": 0.918,
      "Spain": 0.784,
      "Sweden": 0.744,
      "Turkey": 0.769,
      "UAE": 0.715,
      "UK": 0.709,
      "USA": 0.709,
      "Ukraine": 0.859
    },
    "South Africa": {
      "Algeria": 0.918,
      "Armenia": 0.819,
      "Australia": 0.325,
      "Azerbaijan": 0.6,
      "Belgium": 0.72,
      "Brazil": 0.76,
      "Bulgaria": 0.744,
      "Canada": 0.468,
      "China": 0.512,
      "Colombia": 0.76,
      "Croatia": 0.744,
      "Czechia": 0.604,
      "Denmark": 0.604,
      "Egypt": 0.8,
      "Estonia": 0.384,
      "Finland": 0.604,
      "France": 0.35,
      "Germany": 0.583,
      "Greece": 0.604,
      "Hungary": 0.644,
      "India": 0.52,
      "Iran": 0.702,
      "Iraq": 0.76,
      "Israel": 0.385,
      "Italy": 0.604,
      "Japan": 0.37,
      "Latvia": 0.604,
      "Lithuania": 0.644,
      "Morocco": 0.805,
      "Netherlands": 0.384,
      "New Zealand": 0.729,
      "North Korea": 0.617,
      "Norway": 0.637,
      "Pakistan": 0.805,
      "Poland": 0.604,
      "Russia": 0.528,
      "Singapore": 0.43,
      "South Africa": 1.0,
      "South Korea": 0.465,
      "Spain": 0.604,
      "Sweden": 0.644,
      "Turkey": 0.52,
      "UAE": 0.604,
      "UK": 0.228,
      "USA": 0.177,
      "Ukraine": 0.528
    },
    "South Korea": {
      "Algeria": 0.473,
      "Armenia": 0.595,
      "Australia": 0.825,
      "Azerbaijan": 0.626,
      "Belgium": 0.663,
      "Brazil": 0.689,
      "Bulgaria": 0.633,
      "Canada": 0.825,
      "China": 0.717,
      "Colombia": 0.623,
      "Croatia": 0.633,
      "Czechia": 0.837,
      "Denmark": 0.837,
      "Egypt": 0.546,
      "Estonia": 0.858,
      "Finland": 0.837,
      "France": 0.825,
      "Germany": 0.837,
      "Greece": 0.837,
      "Hungary": 0.797,
      "India": 0.784,
      "Iran": 0.604,
      "Iraq": 0.623,
      "Israel": 0.837,
      "Italy": 0.837,
      "Japan": 0.799,
      "Latvia": 0.837,
      "Lithuania": 0.797,
      "Morocco": 0.608,
      "Netherlands": 0.858,
      "New Zealand": 0.689,
      "North Korea": 0.528,
      "Norway": 0.817,
      "Pakistan": 0.608,
      "Poland": 0.837,
      "Russia": 0.717,
      "Singapore": 0.918,
      "South Africa": 0.465,
      "South Korea": 1.0,
      "Spain": 0.837,
      "Sweden": 0.797,
      "Turkey": 0.784,
      "UAE": 0.729,
      "UK": 0.695,
      "USA": 0.669,
      "Ukraine": 0.885
    },
    "Spain": {
      "Algeria": 0.614,
      "Armenia": 0.729,
      "Australia": 0.682,
      "Azerbaijan": 0.675,
      "Belgium": 0.784,
      "Brazil": 0.819,
      "Bulgaria": 0.797,
      "Canada": 0.777,
      "China": 0.742,
      "Colombia": 0.777,
      "Croatia": 0.797,
      "Czechia": 1.0,
      "Denmark": 1.0,
      "Egypt": 0.704,
      "Estonia": 0.757,
      "Finland": 1.0,
      "France": 0.709,
      "Germany": 0.885,
      "Greece": 1.0,
      "Hungary": 0.96,
      "India": 0.817,
      "Iran": 0.715,
      "Iraq": 0.777,
      "Israel": 0.742,
      "Italy": 1.0,
      "Japan": 0.695,
      "Latvia": 1.0,
      "Lithuania": 0.96,
      "Morocco": 0.755,
      "Netherlands": 0.757,
      "New Zealand": 0.777,
      "North Korea": 0.626,
      "Norway": 0.918,
      "Pakistan": 0.729,
      "Poland": 1.0,
      "Russia": 0.769,
      "Singapore": 0.784,
      "South Africa": 0.604,
      "South Korea": 0.837,
      "Spain": 1.0,
      "Sweden": 0.96,
      "Turkey": 0.817,
      "UAE": 0.797,
      "UK": 0.566,
      "USA": 0.532,
      "Ukraine": 0.885
    },
    "Sweden": {
      "Algeria": 0.654,
      "Armenia": 0.769,
      "Australia": 0.642,
      "Azerbaijan": 0.715,
      "Belgium": 0.744,
      "Brazil": 0.859,
      "Bulgaria": 0.837,
      "Canada": 0.737,
      "China": 0.702,
      "Colombia": 0.817,
      "Croatia": 0.837,
      "Czechia": 0.96,
      "Denmark": 0.96,
      "Egypt": 0.744,
      "Estonia": 0.717,
      "Finland": 0.96,
      "France": 0.669,
      "Germany": 0.845,
      "Greece": 0.96,
      "Hungary": 1.0,
      "India": 0.777,
      "Iran": 0.755,
      "Iraq": 0.817,
      "Israel": 0.702,
      "Italy": 0.96,
      "Japan": 0.655,
      "Latvia": 0.96,
      "Lithuania": 1.0,
      "Morocco": 0.715,
      "Netherlands": 0.717,
      "New Zealand": 0.817,
      "North Korea": 0.666,
      "Norway": 0.878,
      "Pakistan": 0.689,
      "Poland": 0.96,
      "Russia": 0.729,
      "Singapore": 0.744,
      "South Africa": 0.644,
      "South Korea": 0.797,
      "Spain": 0.96,
      "Sweden": 1.0,
      "Turkey": 0.777,
      "UAE": 0.837,
      "UK": 0.526,
      "USA": 0.492,
      "Ukraine": 0.845
    },
    "Turkey": {
      "Algeria": 0.512,
      "Armenia": 0.604,
      "Australia": 0.646,
      "Azerbaijan": 0.805,
      "Belgium": 0.635,
      "Brazil": 0.702,
      "Bulgaria": 0.689,
      "Canada": 0.669,
      "China": 0.859,
      "Colombia": 0.702,
      "Croatia": 0.689,
      "Czechia": 0.817,
      "Denmark": 0.817,
      "Egypt": 0.637,
      "Estonia": 0.682,
      "Finland": 0.817,
      "France": 0.669,
      "Germany": 0.729,
      "Greece": 0.817,
      "Hungary": 0.777,
      "India": 1.0,
      "Iran": 0.76,
      "Iraq": 0.702,
      "Israel": 0.817,
      "Italy": 0.817,
      "Japan": 0.634,
      "Latvia": 0.817,
      "Lithuania": 0.777,
      "Morocco": 0.694,
      "Netherlands": 0.682,
      "New Zealand": 0.633,
      "North Korea": 0.72,
      "Norway": 0.769,
      "Pakistan": 0.654,
      "Poland": 0.817,
      "Russia": 0.918,
      "Singapore": 0.769,
      "South Africa": 0.52,
      "South Korea": 0.784,
      "Spain": 0.817,
      "Sweden": 0.777,
      "Turkey": 1.0,
      "UAE": 0.878,
      "UK": 0.508,
      "USA": 0.557,
      "Ukraine": 0.859
    },
    "UAE": {
      "Algeria": 0.595,
      "Armenia": 0.673,
      "Australia": 0.594,
      "Azerbaijan": 0.819,
      "Belgium": 0.623,
      "Brazil": 0.784,
      "Bulgaria": 0.769,
      "Canada": 0.642,
      "China": 0.76,
      "Colombia": 0.784,
      "Croatia": 0.769,
      "Czechia": 0.797,
      "Denmark": 0.797,
      "Egypt": 0.715,
      "Estonia": 0.629,
      "Finland": 0.797,
      "France": 0.617,
      "Germany": 0.702,
      "Greece": 0.797,
      "Hungary": 0.837,
      "India": 0.878,
      "Iran": 0.817,
      "Iraq": 0.784,
      "Israel": 0.729,
      "Italy": 0.797,
      "Japan": 0.584,
      "Latvia": 0.797,
      "Lithuania": 0.837,
      "Morocco": 0.689,
      "Netherlands": 0.629,
      "New Zealand": 0.706,
      "North Korea": 0.777,
      "Norway": 0.744,
      "Pakistan": 0.644,
      "Poland": 0.797,
      "Russia": 0.845,
      "Singapore": 0.715,
      "South Africa": 0.604,
      "South Korea": 0.729,
      "Spain": 0.797,
      "Sweden": 0.837,
      "Turkey": 0.878,
      "UAE": 1.0,
      "UK": 0.445,
      "USA": 0.492,
      "Ukraine": 0.797
    },
    "UK": {
      "Algeria": 0.254,
      "Armenia": 0.377,
      "Australia": 0.784,
      "Azerbaijan": 0.344,
      "Belgium": 0.45,
      "Brazil": 0.453,
      "Bulgaria": 0.377,
      "Canada": 0.729,
      "China": 0.485,
      "Colombia": 0.346,
      "Croatia": 0.377,
      "Czechia": 0.566,
      "Denmark": 0.566,
      "Egypt": 0.294,
      "Estonia": 0.8,
      "Finland": 0.566,
      "France": 0.817,
      "Germany": 0.603,
      "Greece": 0.566,
      "Hungary": 0.526,
      "India": 0.508,
      "Iran": 0.323,
      "Iraq": 0.346,
      "Israel": 0.646,
      "Italy": 0.566,
      "Japan": 0.837,
      "Latvia": 0.566,
      "Lithuania": 0.526,
      "Morocco": 0.351,
      "Netherlands": 0.8,
      "New Zealand": 0.484,
      "North Korea": 0.238,
      "Norway": 0.575,
      "Pakistan": 0.374,
      "Poland": 0.566,
      "Russia": 0.457,
      "Singapore": 0.709,
      "South Africa": 0.228,
      "South Korea": 0.695,
      "Spain": 0.566,
      "Sweden": 0.526,
      "Turkey": 0.508,
      "UAE": 0.445,
      "UK": 1.0,
      "USA": 0.769,
      "Ukraine": 0.624
    },
    "USA": {
      "Algeria": 0.192,
      "Armenia": 0.294,
      "Australia": 0.755,
      "Azerbaijan": 0.384,
      "Belgium": 0.351,
      "Brazil": 0.41,
      "Bulgaria": 0.34,
      "Canada": 0.663,
      "China": 0.516,
      "Colombia": 0.323,
      "Croatia": 0.34,
      "Czechia": 0.532,
      "Denmark": 0.532,
      "Egypt": 0.271,
      "Estonia": 0.742,
      "Finland": 0.532,
      "France": 0.784,
      "Germany": 0.516,
      "Greece": 0.532,
      "Hungary": 0.492,
      "India": 0.557,
      "Iran": 0.334,
      "Iraq": 0.323,
      "Israel": 0.724,
      "Italy": 0.532,
      "Japan": 0.742,
      "Latvia": 0.532,
      "Lithuania": 0.492,
      "Morocco": 0.318,
      "Netherlands": 0.742,
      "New Zealand": 0.397,
      "North Korea": 0.294,
      "Norway": 0.508,
      "Pakistan": 0.329,
      "Poland": 0.532,
      "Russia": 0.516,
      "Singapore": 0.709,
      "South Africa": 0.177,
      "South Korea": 0.669,
      "Spain": 0.532,
      "Sweden": 0.492,
      "Turkey": 0.557,
      "UAE": 0.492,
      "UK": 0.769,
      "USA": 1.0,
      "Ukraine": 0.603
    },
    "Ukraine": {
      "Algeria": 0.537,
      "Armenia": 0.654,
      "Australia": 0.74,
      "Azerbaijan": 0.704,
      "Belgium": 0.706,
      "Brazil": 0.744,
      "Bulgaria": 0.702,
      "Canada": 0.777,
      "China": 0.8,
      "Colombia": 0.689,
      "Croatia": 0.702,
      "Czechia": 0.885,
      "Denmark": 0.885,
      "Egypt": 0.626,
      "Estonia": 0.799,
      "Finland": 0.885,
      "France": 0.777,
      "Germany": 0.837,
      "Greece": 0.885,
      "Hungary": 0.845,
      "India": 0.859,
      "Iran": 0.689,
      "Iraq": 0.689,
      "Israel": 0.837,
      "Italy": 0.885,
      "Japan": 0.757,
      "Latvia": 0.885,
      "Lithuania": 0.845,
      "Morocco": 0.684,
      "Netherlands": 0.799,
      "New Zealand": 0.715,
      "North Korea": 0.604,
      "Norway": 0.859,
      "Pakistan": 0.663,
      "Poland": 0.885,
      "Russia": 0.8,
      "Singapore": 0.859,
      "South Africa": 0.528,
      "South Korea": 0.885,
      "Spain": 0.885,
      "Sweden": 0.845,
      "Turkey": 0.859,
      "UAE": 0.797,
      "UK": 0.624,
      "USA": 0.603,
      "Ukraine": 1.0
    }
  },
  "directionalCoding": {
    "USA": {
      "LAWS": 1,
      "Adoption": 4,
      "Procurement": 4,
      "Safety": 4,
      "Ethics": 3,
      "Interoperability": 3
    },
    "China": {
      "LAWS": 2,
      "Adoption": 4,
      "Procurement": 2,
      "Safety": 1,
      "Ethics": 1,
      "Interoperability": 0
    },
    "Russia": {
      "LAWS": 1,
      "Adoption": 3,
      "Procurement": 2,
      "Safety": 1,
      "Ethics": 1,
      "Interoperability": 0
    },
    "UK": {
      "LAWS": 3,
      "Adoption": 4,
      "Procurement": 3,
      "Safety": 3,
      "Ethics": 4,
      "Interoperability": 4
    },
    "Australia": {
      "LAWS": 2,
      "Adoption": 3,
      "Procurement": 3,
      "Safety": 2,
      "Ethics": 2,
      "Interoperability": 4
    },
    "Canada": {
      "LAWS": 3,
      "Adoption": 2,
      "Procurement": 2,
      "Safety": 2,
      "Ethics": 2,
      "Interoperability": 3
    },
    "New Zealand": {
      "LAWS": 4,
      "Adoption": 1,
      "Procurement": 1,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 2
    },
    "France": {
      "LAWS": 2,
      "Adoption": 3,
      "Procurement": 3,
      "Safety": 2,
      "Ethics": 3,
      "Interoperability": 3
    },
    "Germany": {
      "LAWS": 3,
      "Adoption": 2,
      "Procurement": 1,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 3
    },
    "Italy": {
      "LAWS": 2,
      "Adoption": 2,
      "Procurement": 1,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 2
    },
    "Netherlands": {
      "LAWS": 2,
      "Adoption": 3,
      "Procurement": 2,
      "Safety": 2,
      "Ethics": 3,
      "Interoperability": 3
    },
    "Spain": {
      "LAWS": 2,
      "Adoption": 2,
      "Procurement": 1,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 2
    },
    "Poland": {
      "LAWS": 2,
      "Adoption": 2,
      "Procurement": 1,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 2
    },
    "Norway": {
      "LAWS": 3,
      "Adoption": 2,
      "Procurement": 1,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 2
    },
    "Denmark": {
      "LAWS": 2,
      "Adoption": 2,
      "Procurement": 1,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 2
    },
    "Sweden": {
      "LAWS": 2,
      "Adoption": 2,
      "Procurement": 1,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 2
    },
    "Finland": {
      "LAWS": 2,
      "Adoption": 2,
      "Procurement": 1,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 2
    },
    "Estonia": {
      "LAWS": 2,
      "Adoption": 3,
      "Procurement": 2,
      "Safety": 2,
      "Ethics": 3,
      "Interoperability": 3
    },
    "Latvia": {
      "LAWS": 2,
      "Adoption": 2,
      "Procurement": 1,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 2
    },
    "Lithuania": {
      "LAWS": 2,
      "Adoption": 2,
      "Procurement": 1,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 2
    },
    "Greece": {
      "LAWS": 2,
      "Adoption": 2,
      "Procurement": 1,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 2
    },
    "Hungary": {
      "LAWS": 2,
      "Adoption": 2,
      "Procurement": 1,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 2
    },
    "Czechia": {
      "LAWS": 2,
      "Adoption": 2,
      "Procurement": 1,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 2
    },
    "Croatia": {
      "LAWS": 2,
      "Adoption": 1,
      "Procurement": 0,
      "Safety": 0,
      "Ethics": 2,
      "Interoperability": 1
    },
    "Bulgaria": {
      "LAWS": 2,
      "Adoption": 1,
      "Procurement": 0,
      "Safety": 0,
      "Ethics": 2,
      "Interoperability": 1
    },
    "Belgium": {
      "LAWS": 4,
      "Adoption": 1,
      "Procurement": 0,
      "Safety": 0,
      "Ethics": 2,
      "Interoperability": 2
    },
    "Turkey": {
      "LAWS": 1,
      "Adoption": 3,
      "Procurement": 2,
      "Safety": 1,
      "Ethics": 1,
      "Interoperability": 1
    },
    "Japan": {
      "LAWS": 3,
      "Adoption": 3,
      "Procurement": 3,
      "Safety": 2,
      "Ethics": 3,
      "Interoperability": 3
    },
    "South Korea": {
      "LAWS": 2,
      "Adoption": 3,
      "Procurement": 2,
      "Safety": 2,
      "Ethics": 2,
      "Interoperability": 3
    },
    "India": {
      "LAWS": 1,
      "Adoption": 3,
      "Procurement": 2,
      "Safety": 1,
      "Ethics": 1,
      "Interoperability": 1
    },
    "Singapore": {
      "LAWS": 2,
      "Adoption": 3,
      "Procurement": 3,
      "Safety": 2,
      "Ethics": 2,
      "Interoperability": 3
    },
    "Israel": {
      "LAWS": 1,
      "Adoption": 4,
      "Procurement": 3,
      "Safety": 2,
      "Ethics": 2,
      "Interoperability": 2
    },
    "Ukraine": {
      "LAWS": 2,
      "Adoption": 3,
      "Procurement": 2,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 2
    },
    "Brazil": {
      "LAWS": 3,
      "Adoption": 1,
      "Procurement": 1,
      "Safety": 1,
      "Ethics": 2,
      "Interoperability": 1
    },
    "Colombia": {
      "LAWS": 2,
      "Adoption": 1,
      "Procurement": 0,
      "Safety": 0,
      "Ethics": 1,
      "Interoperability": 1
    },
    "UAE": {
      "LAWS": 1,
      "Adoption": 2,
      "Procurement": 2,
      "Safety": 1,
      "Ethics": 1,
      "Interoperability": 1
    },
    "Egypt": {
      "LAWS": 2,
      "Adoption": 1,
      "Procurement": 0,
      "Safety": 0,
      "Ethics": 2,
      "Interoperability": 0
    },
    "Algeria": {
      "LAWS": 4,
      "Adoption": 0,
      "Procurement": 0,
      "Safety": 0,
      "Ethics": 2,
      "Interoperability": 0
    },
    "Morocco": {
      "LAWS": 3,
      "Adoption": 1,
      "Procurement": 0,
      "Safety": 0,
      "Ethics": 1,
      "Interoperability": 0
    },
    "South Africa": {
      "LAWS": 4,
      "Adoption": 0,
      "Procurement": 0,
      "Safety": 0,
      "Ethics": 1,
      "Interoperability": 0
    },
    "Pakistan": {
      "LAWS": 4,
      "Adoption": 1,
      "Procurement": 0,
      "Safety": 1,
      "Ethics": 1,
      "Interoperability": 0
    },
    "Iran": {
      "LAWS": 2,
      "Adoption": 2,
      "Procurement": 1,
      "Safety": 0,
      "Ethics": 0,
      "Interoperability": 0
    },
    "Iraq": {
      "LAWS": 2,
      "Adoption": 1,
      "Procurement": 0,
      "Safety": 0,
      "Ethics": 1,
      "Interoperability": 1
    },
    "Armenia": {
      "LAWS": 4,
      "Adoption": 1,
      "Procurement": 0,
      "Safety": 0,
      "Ethics": 2,
      "Interoperability": 1
    },
    "Azerbaijan": {
      "LAWS": 1,
      "Adoption": 3,
      "Procurement": 2,
      "Safety": 0,
      "Ethics": 0,
      "Interoperability": 1
    },
    "North Korea": {
      "LAWS": 0,
      "Adoption": 2,
      "Procurement": 1,
      "Safety": 0,
      "Ethics": 0,
      "Interoperability": 0
    }
  },
  "allianceConvergence": {},
  "yearlyScores": {
    "USA": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": 1,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": 3,
        "Ethics": 3,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": 3,
        "Ethics": 3,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 1,
        "Adoption": 4,
        "Procurement": 3,
        "Safety": 3,
        "Ethics": 3,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 1,
        "Adoption": 4,
        "Procurement": 4,
        "Safety": 4,
        "Ethics": 3,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 1,
        "Adoption": 4,
        "Procurement": 4,
        "Safety": 4,
        "Ethics": 3,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 1,
        "Adoption": 4,
        "Procurement": 4,
        "Safety": 4,
        "Ethics": 3,
        "Interoperability": 3
      }
    },
    "China": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": 4,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": 4,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": 4,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": 4,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": 4,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": 4,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 4,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 4,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": null
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 4,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": null
      }
    },
    "UK": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 3,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 3,
        "Adoption": 4,
        "Procurement": 3,
        "Safety": 3,
        "Ethics": 4,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 3,
        "Adoption": 4,
        "Procurement": 3,
        "Safety": 3,
        "Ethics": 4,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 3,
        "Adoption": 4,
        "Procurement": 3,
        "Safety": 3,
        "Ethics": 4,
        "Interoperability": 4
      },
      "2025": {
        "LAWS": 3,
        "Adoption": 4,
        "Procurement": 3,
        "Safety": 3,
        "Ethics": 4,
        "Interoperability": 4
      }
    },
    "Russia": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": null
      },
      "2025": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": null
      }
    },
    "France": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": 2,
        "Ethics": 2,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": 2,
        "Ethics": 2,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": 2,
        "Ethics": 3,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": 2,
        "Ethics": 3,
        "Interoperability": 3
      }
    },
    "Australia": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": 3
      },
      "2022": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": 3
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 3
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 4
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": 2,
        "Ethics": 2,
        "Interoperability": 4
      }
    },
    "Canada": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": 3,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 3,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 3,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 3,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 3,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 3,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": 2,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 3,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": 2,
        "Interoperability": 3
      }
    },
    "New Zealand": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 4,
        "Adoption": 1,
        "Procurement": 1,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 2
      },
      "2025": {
        "LAWS": 4,
        "Adoption": 1,
        "Procurement": 1,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 2
      }
    },
    "Japan": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": null,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 3,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": null,
        "Ethics": null,
        "Interoperability": 3
      },
      "2024": {
        "LAWS": 3,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": 2,
        "Ethics": 3,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 3,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": 2,
        "Ethics": 3,
        "Interoperability": 3
      }
    },
    "South Korea": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": 2,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": 2,
        "Interoperability": 3
      }
    },
    "India": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": 1
      },
      "2025": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": 1
      }
    },
    "Singapore": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": 2,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": 2,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": 2,
        "Ethics": 2,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 3,
        "Safety": 2,
        "Ethics": 2,
        "Interoperability": 3
      }
    },
    "Israel": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 1,
        "Adoption": 4,
        "Procurement": 3,
        "Safety": 2,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 1,
        "Adoption": 4,
        "Procurement": 3,
        "Safety": 2,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 1,
        "Adoption": 4,
        "Procurement": 3,
        "Safety": 2,
        "Ethics": 2,
        "Interoperability": 2
      },
      "2025": {
        "LAWS": 1,
        "Adoption": 4,
        "Procurement": 3,
        "Safety": 2,
        "Ethics": 2,
        "Interoperability": 2
      }
    },
    "Turkey": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": 1
      },
      "2025": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": 1
      }
    },
    "UAE": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 1,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 1,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 1,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 1,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 1,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 1
      },
      "2025": {
        "LAWS": 1,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 1
      }
    },
    "Iran": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 1,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 1,
        "Interoperability": null
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 1,
        "Interoperability": null
      }
    },
    "Iraq": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": 1,
        "Interoperability": null
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": 1,
        "Interoperability": null
      }
    },
    "Germany": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": 3,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 3,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 3,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 3,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 3,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 3,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 3,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 3
      }
    },
    "Netherlands": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": 3,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": 3,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": 3,
        "Interoperability": 3
      }
    },
    "Belgium": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 4,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 2
      },
      "2025": {
        "LAWS": 4,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 2
      }
    },
    "Poland": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 3
      }
    },
    "Norway": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": 3,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": 3,
        "Interoperability": 3
      }
    },
    "Estonia": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": 3,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": 3,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 2,
        "Ethics": 3,
        "Interoperability": 3
      }
    },
    "Italy": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 3
      }
    },
    "Spain": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 3
      }
    },
    "Sweden": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 3
      }
    },
    "Finland": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 3
      }
    },
    "Denmark": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 3
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 3
      }
    },
    "Greece": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 2
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 2
      }
    },
    "Czechia": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 2
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 2
      }
    },
    "Hungary": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 2
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 2
      }
    },
    "Latvia": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 2
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 2
      }
    },
    "Lithuania": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 2
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 2
      }
    },
    "Croatia": {
      "2016": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 2
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 2
      }
    },
    "Bulgaria": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 2
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 2
      }
    },
    "Ukraine": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 2
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": 1,
        "Ethics": 2,
        "Interoperability": 2
      }
    },
    "Brazil": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 1
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 1
      }
    },
    "Colombia": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 1,
        "Interoperability": 1
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 1,
        "Interoperability": 1
      }
    },
    "Algeria": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": null
      },
      "2025": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": null
      }
    },
    "Morocco": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": 1,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 1
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": 1,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 1
      }
    },
    "Egypt": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 2,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": 1,
        "Interoperability": null
      },
      "2025": {
        "LAWS": 2,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": 1,
        "Interoperability": null
      }
    },
    "South Africa": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": 1,
        "Interoperability": null
      },
      "2025": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": 1,
        "Interoperability": null
      }
    },
    "Armenia": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 4,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": null
      },
      "2025": {
        "LAWS": 4,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": 2,
        "Interoperability": 1
      }
    },
    "Azerbaijan": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": 1
      },
      "2025": {
        "LAWS": 1,
        "Adoption": 3,
        "Procurement": 2,
        "Safety": null,
        "Ethics": null,
        "Interoperability": 1
      }
    },
    "Pakistan": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": 4,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": 4,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": 4,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": 4,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": 4,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 4,
        "Adoption": 1,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 4,
        "Adoption": 1,
        "Procurement": null,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": null
      },
      "2025": {
        "LAWS": 4,
        "Adoption": 1,
        "Procurement": null,
        "Safety": 1,
        "Ethics": 1,
        "Interoperability": null
      }
    },
    "North Korea": {
      "2016": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2017": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2018": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2019": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2020": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2021": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2022": {
        "LAWS": null,
        "Adoption": null,
        "Procurement": null,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2023": {
        "LAWS": 0,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2024": {
        "LAWS": 0,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      },
      "2025": {
        "LAWS": 0,
        "Adoption": 2,
        "Procurement": 1,
        "Safety": null,
        "Ethics": null,
        "Interoperability": null
      }
    }
  }
}
